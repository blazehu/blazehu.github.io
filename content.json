{"meta":{"title":"小千世界","subtitle":"","description":"","author":"BlazeHu","url":"https://blazehu.github.io","root":"/"},"pages":[{"title":"书单","date":"2025-01-24T04:48:06.206Z","updated":"2022-06-21T06:59:55.000Z","comments":false,"path":"books/index.html","permalink":"https://blazehu.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2025-01-24T04:48:06.208Z","updated":"2022-06-21T06:59:55.000Z","comments":false,"path":"categories/index.html","permalink":"https://blazehu.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2025-01-24T04:48:06.207Z","updated":"2022-06-21T06:59:55.000Z","comments":false,"path":"tags/index.html","permalink":"https://blazehu.github.io/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2025-01-24T04:48:06.207Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"links/index.html","permalink":"https://blazehu.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2025-01-24T04:48:06.160Z","updated":"2022-06-21T06:59:55.000Z","comments":false,"path":"repository/index.html","permalink":"https://blazehu.github.io/repository/index.html","excerpt":"","text":""},{"title":"关于","date":"2025-01-24T04:48:06.206Z","updated":"2023-07-11T08:38:50.000Z","comments":false,"path":"about/index.html","permalink":"https://blazehu.github.io/about/index.html","excerpt":"","text":"Working ExperienceTencent (2020-), Senior Software EngineerTrip.com (2018-2020), Senior Software EngineerFocus &amp; InterestsCloudNativeDevOpsSRE"}],"posts":[{"title":"HTTP/2 多路复用踩坑记：gRPC 负载均衡方案对比","slug":"backend/golang/golang_grpc","date":"2025-11-09T16:00:00.000Z","updated":"2025-11-13T04:08:46.129Z","comments":true,"path":"2025/11/10/backend/golang/golang_grpc/","link":"","permalink":"https://blazehu.github.io/2025/11/10/backend/golang/golang_grpc/","excerpt":"在 Kubernetes 环境中部署 gRPC 服务时，发现明明有多个服务端 Pod，但所有请求都只打到了其中一个 Pod，导致负载严重不均。本文将分析这个问题的根本原因，并介绍几种主流解决方案，结合实际代码演示，帮助你在不同场景下做出最佳选择。","text":"在 Kubernetes 环境中部署 gRPC 服务时，发现明明有多个服务端 Pod，但所有请求都只打到了其中一个 Pod，导致负载严重不均。本文将分析这个问题的根本原因，并介绍几种主流解决方案，结合实际代码演示，帮助你在不同场景下做出最佳选择。一、背景在 Kubernetes 集群中部署了一个 gRPC 服务，配置如下：服务端：3 个 Pod 副本（grpc-server-0, grpc-server-1, grpc-server-2）客户端：1 个 Pod，持续发送请求Service：使用默认的 ClusterIP Service观察结果：所有请求都路由到了 grpc-server-0，其他两个 Pod 完全没有流量，这样会导致以下问题：资源浪费：其他 Pod 闲置，无法充分利用集群资源性能瓶颈：单个 Pod 过载，响应延迟增加可用性风险：如果该 Pod 故障，所有流量中断二、根因分析gRPC 基于 HTTP/2 多路复用：同一 TCP 连接可并行承载多个请求，连接一旦建立即持续复用。Kubernetes Service 的 kube-proxy 仅在连接建立时执行一次 L4 负载均衡，后续所有请求均沿该连接转发，不再重新选择后端，因而无法实现请求级分摊，导致流量集中于单个 Pod。三、解决方案方案一：gRPC 内置 Round-Robin 负载均衡3.1.1 核心原理将客户端的 LoadBalancingPolicy 从默认的 pick_first 改为 round_robin。关键变化：gRPC 会为每个后端地址创建独立的 Sub-Connection请求在这些子连接间轮询发送等于”单 client 同时保持 N 条 HTTP/2 连接”天然打散到 N 个 Pod3.1.2 代码实现参考：client.go// 方案 1：Round-Robinopts := []grpc.DialOption&#123; grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithDefaultServiceConfig(`&#123;\"loadBalancingPolicy\":\"round_robin\"&#125;`),&#125;// 使用 Headless Service（返回所有 Pod IP）conn, err := grpc.Dial(\"dns:///grpc-server-headless:8000\", opts...)关键点：必须使用 Headless Service（clusterIP: None）Headless Service 在 DNS 查询时返回所有 Pod IP使用 dns:/// resolver 让 gRPC 获取所有地址3.1.3 Kubernetes 配置# Headless ServiceapiVersion: v1kind: Servicemetadata: name: grpc-server-headless namespace: blazehu labels: app: grpc-serverspec: type: ClusterIP clusterIP: None # Headless Service - 返回所有 Pod IP ports: - port: 8000 targetPort: 8000 protocol: TCP name: grpc selector: app: grpc-server3.1.4 特点分析维度说明核心原理客户端为每个 Pod 创建独立连接，请求轮询分发适用场景Kubernetes 环境，需要简单快速的解决方案部署成本极低：一行代码配置改造成本极低：只需修改客户端连接配置性能损失几乎为 0（相对直连 100% QPS）优点简单、高效、无需额外组件缺点需要 Headless Service，不支持高级路由（权重、灰度）方案二：gRPC xDS 直连（Proxyless）3.2.1 核心原理仍然使用 gRPC 自己的负载均衡，但把”后端列表”来源从 DNS 换成 xDS 协议。工作流程：Istio/Pilot 以 LDS/RDS/CDS/EDS 形式把 Pod IP 列表推给 gRPC 客户端客户端在本地做请求级 RR/wRR（加权轮询）不再依赖长连接，而是”每次 pick 一个 Sub-Connection“3.2.2 代码实现参考：client_xds.go// 方案 2：Proxyless xDSimport _ \"google.golang.org/grpc/xds\" // 启用 xDS resolver// 设置 bootstrap 文件路径（由 grpc-agent 生成）os.Setenv(\"GRPC_XDS_BOOTSTRAP\", \"/etc/istio/proxy/grpc-bootstrap.json\")opts := []grpc.DialOption&#123; grpc.WithTransportCredentials(insecure.NewCredentials()),&#125;// 使用 xds:// schemeconn, err := grpc.Dial(\"xds:///grpc-server.blazehu.svc.cluster.local:8000\", opts...)关键点：使用 xds:/// scheme 启用 xDS resolver需要 Istio grpc-agent 生成 bootstrap.json支持高级路由：权重、子集（灰度标签）3.2.3 Kubernetes 配置# Deployment 配置apiVersion: apps/v1kind: Deploymentmetadata: name: grpc-clientspec: template: metadata: annotations: sidecar.istio.io/inject: 'true' inject.istio.io/templates: 'grpc-agent' # 注入 grpc-agent spec: containers: - name: grpc-client env: - name: GRPC_XDS_BOOTSTRAP value: /etc/istio/proxy/grpc-bootstrap.jsongrpc-agent 的作用：自动生成符合 Istio 要求的 bootstrap.json提供 SDS（Secret Discovery Service）证书维护正确的 node.id 格式为快速验证 xDS 通路，手动将 bootstrap.json 以 ConfigMap 挂载到客户端 Pod，未注入 grpc-agent；只要 node.id 格式正确且 URI 与后端服务匹配，istiod 即会返回 xDS 响应。3.2.4 特点分析维度说明核心原理xDS 协议直接下发后端列表，客户端本地负载均衡适用场景已使用 Istio 服务网格，需要高级流量管理部署成本中等：需要 Istio 控制平面改造成本中等：需要配置 xDS bootstrap性能损失几乎为 0（无代理开销）优点支持权重、灰度、子集路由，无 Sidecar 延迟缺点依赖 Istio，需要 grpc-agent 支持方案三：Sidecar（Envoy）HTTP/2 七层负载均衡3.3.1 核心原理在 client Pod 内注入 Envoy Sidecar。工作流程：客户端建立 1 条 HTTP/2 连接到 SidecarEnvoy 把”单条 HTTP/2 连接”拆成逻辑 Stream按配置的负载均衡算法（RR、Least Request、Maglev…）挑选 upstream Pod对 client 而言仍是 1 条连接，但 Envoy 内部做了”单连接 → 多 Pod“的映射Sidecar（Envoy）主要在“客户端侧”负责把单条 HTTP/2 连接的 stream 逐条分发到后端上游（即实现请求级的负载均衡）。因此，为了实现请求级分摊，只在 client Pod 注入 sidecar 即可达到目的，server Pod 是否注入 sidecar 并非必须。3.3.2 配置示例# 默认注入 Envoy Sidecar（不指定模板）apiVersion: apps/v1kind: Deploymentmetadata: name: grpc-clientspec: template: metadata: annotations: sidecar.istio.io/inject: 'true' # 默认注入 Envoy spec: containers: - name: grpc-client # 客户端直接连接 Service，Envoy 自动拦截3.3.3 特点分析维度说明核心原理Envoy Sidecar 在七层做请求级负载均衡适用场景已使用服务网格，需要统一的流量管理策略部署成本中等：需要 Sidecar，增加资源消耗改造成本低：对客户端透明，无需代码修改性能损失5-10%（Sidecar 代理开销）优点对客户端透明，支持多种 LB 算法，统一管理缺点需要 Sidecar，增加延迟和资源消耗方案四：Istio Gateway（Ingress/Gateway-API）3.4.1 核心原理把流量先打到 Ingress Gateway。工作流程：Gateway 本身就是 Envoy，但只经过一次代理Gateway 同样能把 HTTP/2 stream 打散到 N 个 Podclient → Gateway（1 条 HTTP/2）→ 多 Pod3.4.2 配置示例# GatewayapiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata: name: grpc-gatewayspec: selector: istio: ingressgateway servers: - port: number: 80 name: grpc protocol: HTTP2 hosts: - grpc-server.example.com# VirtualServiceapiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: grpc-serverspec: hosts: - grpc-server.example.com gateways: - grpc-gateway http: - match: - uri: prefix: / route: - destination: host: grpc-server port: number: 80003.4.3 特点分析维度说明核心原理Gateway 在入口做七层负载均衡适用场景需要统一入口管理，外部流量接入部署成本中等：需要 Gateway 组件改造成本低：只需配置 Gateway 和 VirtualService性能损失3-5%（单跳代理）优点集中式流量管理，支持 TLS 终止缺点需要 Gateway，只适用于入口流量四、方案对比与选型4.1 对比矩阵方案性能损失改造成本适用场景高级功能Round-Robin~0%极低Kubernetes❌xDS Proxyless~0%中Istio 网格✅ 权重/灰度Envoy Sidecar5-10%低服务网格✅ 多种算法Gateway3-5%低入口流量✅ TLS/路由4.2 选型建议简单 K8s 用客户端 Round-Robin；已落地 Istio 选 xDS Proxyless，享网格级路由与无 Sidecar 延迟；需统一治理则注入 Envoy Sidecar，策略对应用透明；外部入口统一用 Gateway，集中 TLS 与流量调度，单跳即达后端。五、方案验证5.1 演示环境简单实现了一个完整的验证项目，包含：服务端：3 个 Pod 副本，每个返回自己的 Pod 名称客户端：支持 3 种模式（pick_first、round_robin、xds）Kubernetes 配置：完整的 Deployment、Service、Job 配置5.2 测试结果测试结果符合预期，相关测试结果如下：# pick_first(default) 默认会负载不均./grpc_demo client --server-address=grpc-server:8000 --lb-policy pick_first --requests 10000 --concurrent 1000=== Results ===Total: 10000Requests per Server: grpc-server-7496b78c84-z65dw: 10000 (100.0%)✓ All requests went to single server (expected for pick_first)# round_robin./grpc_demo client --server-address=dns:///grpc-server-headless:8000 --lb-policy=round_robin --requests 10000 --concurrent 1000=== Results ===Total: 10000Requests per Server: grpc-server-7496b78c84-nt8g4: 3333 (33.3%) grpc-server-7496b78c84-zcsq5: 3334 (33.3%) grpc-server-7496b78c84-z65dw: 3333 (33.3%)✓ Requests distributed across 3 servers (expected for round_robin)# xds（proxyless）./grpc_demo client-xds --target=xds:///grpc-server.blazehu.svc.cluster.local:8000 --requests 10000 --concurrent 1000=== Results ===Total: 10000Requests per Server (pod): grpc-server-7496b78c84-z65dw: 3327 (33.3%) grpc-server-7496b78c84-nt8g4: 3345 (33.5%) grpc-server-7496b78c84-zcsq5: 3328 (33.3%)# sidecar (测试时修改 client workload 注解，用于注入sidecar)./grpc_demo client --server-address=grpc-server:8000 --lb-policy pick_first --requests 10000 --concurrent 1000=== Results ===Total: 10000Requests per Server: grpc-server-7496b78c84-zcsq5: 3344 (33.4%) grpc-server-7496b78c84-nt8g4: 3314 (33.1%) grpc-server-7496b78c84-z65dw: 3342 (33.4%)# istio gateway./grpc_demo client --server-address grpc-server.example.com:80 --lb-policy pick_first --requests 10000 --concurrent 1000=== Results ===Total: 10000Requests per Server: grpc-server-7496b78c84-z65dw: 3339 (33.4%) grpc-server-7496b78c84-zcsq5: 3323 (33.2%) grpc-server-7496b78c84-nt8g4: 3338 (33.4%)注意：gateway 测试时修改 client-deployment 容器的 /etc/hosts ，将 grpc-server.example.com 域名解析到 istio-ingressgateway svc 的 clusterIP 地址。六、总结gRPC HTTP/2 多路复用导致“长连接 = 单 Pod”的根因是：“连接级负载均衡” vs “请求级负载均衡”。只要让“选 Pod”的决策点从『TCP 建连时』延后到『每个 Stream/请求时』，问题就解决了——以上方案只是实现“延后决策”的不同姿势。七、参考资料gRPC Load BalancingIstio Traffic ManagementKubernetes ServicesHeadless Services","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"},{"name":"grpc","slug":"grpc","permalink":"https://blazehu.github.io/tags/grpc/"}]},{"title":"蓝盾 Agent 安装流程","slug":"devops/landun_agent","date":"2025-10-08T16:00:00.000Z","updated":"2025-10-17T07:18:46.431Z","comments":true,"path":"2025/10/09/devops/landun_agent/","link":"","permalink":"https://blazehu.github.io/2025/10/09/devops/landun_agent/","excerpt":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文会介绍蓝盾 Agent 安装的整体流程。","text":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文会介绍蓝盾 Agent 安装的整体流程。1. 背景在蓝盾中，构建机 Agent 是执行具体构建任务的核心组件。本文以蓝盾社区版 7.1 为例，详细梳理 Agent 的安装流程。2. 手动安装流程按照官方文档的说明，手动安装 Agent 的步骤如下：进入蓝盾页面：服务 -&gt; 环境管理 -&gt; 节点点击右上角的”导入私有构建机”按钮在弹窗中选择目标机器的操作系统（支持 Linux/Windows/MacOS）复制安装命令到目标机器执行安装完成后点击刷新，确认节点状态点击导入完成节点接入3. 自动化安装方案除了手动操作外，我们也可以通过调用接口实现 Agent 的自动化安装。主要涉及以下步骤：3.1. 生成安装命令GET /ms/environment/api/user/environment/thirdPartyAgent/projects/$&#123;projectId&#125;/os/$&#123;os&#125;/generateLink请求示例:curl -X GET \\ 'https://devops.example.com/ms/environment/api/user/environment/thirdPartyAgent/projects/demo/os/LINUX/generateLink' \\ -H 'X-DEVOPS-UID: admin'返回结果:&#123; \"status\": 0, \"data\": &#123; \"agentId\": \"njmkqvml\", \"link\": \"curl -H \\\"X-DEVOPS-PROJECT-ID: demo\\\" https://devops.example.com/environment/api/external/thirdPartyAgent/njmkqvml/install | bash\" &#125;&#125;3.2. 执行安装并查询状态在目标机器执行安装命令:curl -H \\\"X-DEVOPS-PROJECT-ID: demo\\\" https://devops.example.com/environment/api/external/thirdPartyAgent/njmkqvml/install | bash查询 Agent 状态:GET /ms/environment/api/user/environment/thirdPartyAgent/projects/$&#123;projectId&#125;/agents/$&#123;agentId&#125;/status导入节点:POST /ms/environment/api/user/environment/thirdPartyAgent/projects/$&#123;projectId&#125;/agents/$&#123;agentId&#125;/import4. Agent 安装实现分析4.1. 生成安装命令(generateLink)生成安装命令的实现主要分为三层:API层 - 接口定义:@ApiOperation(\"生成链接\")@GET@Path(\"/projects/&#123;projectId&#125;/os/&#123;os&#125;/generateLink\")fun generateLink( @HeaderParam(AUTH_HEADER_USER_ID) userId: String, @PathParam(\"projectId\") projectId: String, @PathParam(\"os\") os: OS, @QueryParam(\"zoneName\") zoneName: String?): Result&lt;ThirdPartyAgentLink&gt;Service层 - 参数校验:override fun generateLink(userId: String, projectId: String, os: OS, zoneName: String?): Result&lt;ThirdPartyAgentLink&gt; &#123; checkUserId(userId) checkProjectId(projectId) return Result(thirdPartyAgentService.generateAgent(userId, projectId, os, zoneName))&#125;具体实现 - 核心逻辑:fun generateAgent(userId: String, projectId: String, os: OS, zoneName: String?): ThirdPartyAgentLink &#123; // 1. 获取网关信息 val gateway = slaveGatewayService.getGateway(zoneName) // 2. 检查未导入的agent val unimportAgent = thirdPartyAgentDao.listUnimportAgent( dslContext = dslContext, projectId = projectId, userId = userId, os = os ) // 3. 生成或复用agent记录 val agentRecord = if (unimportAgent.isEmpty()) &#123; // 生成新agent val secretKey = generateSecretKey() val id = thirdPartyAgentDao.add(...) thirdPartyAgentDao.getAgent(dslContext, id)!! &#125; else &#123; // 复用已有agent unimportAgent[0] &#125; // 4. 根据操作系统生成安装命令 return if (os == OS.WINDOWS) &#123; ThirdPartyAgentLink( agentId = agentHashId, link = agentUrlService.genAgentUrl(agentRecord) ) &#125; else &#123; ThirdPartyAgentLink( agentId = agentHashId, link = agentUrlService.genAgentInstallScript(agentRecord) ) &#125;&#125;4.2. 获取安装脚本蓝盾通过模板渲染的方式生成不同操作系统的安装脚本。主要流程:API接口定义:@ApiOperation(\"下载agent安装脚本\")@GET@Path(\"/&#123;agentId&#125;/install\")@Produces(MediaType.APPLICATION_OCTET_STREAM)fun downloadAgentInstallScript( @ApiParam(\"Agent ID\", required = true) @PathParam(\"agentId\") agentId: String): Response核心实现:fun downloadInstallScript(agentId: String): Response &#123; // 1. 获取Agent记录 val agentRecord = getAgentRecord(agentId) // 2. 根据OS选择安装脚本模板 val fileName = if (agentRecord.os == OS.WINDOWS.name) &#123; \"install.bat\" &#125; else &#123; \"install.sh\" &#125; val scriptFile = File(agentPackage, \"script/$&#123;agentRecord.os.toLowerCase()&#125;/$fileName\") // 3. 替换模板变量 val map = getAgentReplaceProperties(agentRecord) // 获取替换变量 var result = scriptFile.readText(Charset.forName(\"UTF-8\")) map.forEach &#123; (t, u) -&gt; result = result.replace(\"##$t##\", u) &#125; // 4. 返回生成的脚本 return Response.ok(StreamingOutput &#123; output -&gt; output.write(result.toByteArray()) output.flush() &#125;, MediaType.APPLICATION_OCTET_STREAM_TYPE) .header(\"content-disposition\", \"attachment; filename = $fileName\") .build()&#125;安装脚本目录结构:script/├── linux/│ ├── install.sh # Linux安装脚本模板│ ├── start.sh # 启动脚本│ ├── stop.sh # 停止脚本│ └── uninstall.sh # 卸载脚本├── macos/│ ├── install.sh # MacOS安装脚本模板│ └── ...└── windows/ ├── install.bat # Windows安装脚本模板 ├── devopsctl.vbs # VBS控制脚本 └── ...模板变量说明:##agent_url## - Agent包下载地址##projectId## - 项目ID##agentId## - AgentID##agentSecretKey## - Agent密钥##gateWay## - 网关地址##fileGateway## - 文件网关地址4.3. Linux安装脚本实现install.sh脚本是Agent安装的核心,主要实现以下功能:4.3.1. 初始化环境workspace=`pwd` # 工作目录user=$&#123;USER&#125; # 当前用户agent_id='##agentId##' # Agent ID(模板变量)# 检测系统架构function initArch() &#123; ARCH=$(uname -m) case $ARCH in aarch64) ARCH=\"arm64\";; arm64) ARCH=\"arm64\";; mips64) ARCH=\"mips64\";; *) ARCH=\"\";; esac&#125;4.3.2. 下载并解压Agent包function download_agent() &#123; if [[ -f \"agent.zip\" ]]; then echo \"agent.zip already exist, skip download\" return fi # 优先使用curl,失败则尝试wget if exists curl; then curl -H \"X-DEVOPS-PROJECT-ID: ##projectId##\" -o agent.zip \"##agent_url##\" if [[ $? -ne 0 ]]; then wget --header=\"X-DEVOPS-PROJECT-ID: ##projectId##\" -O agent.zip \"##agent_url##\" fi elif exists wget; then wget --header=\"X-DEVOPS-PROJECT-ID: ##projectId##\" -O agent.zip \"##agent_url##\" else echo \"Curl &amp; wget command don't exist, download fail\" exit 1 fi&#125;# 解压JDKfunction unzip_jdk() &#123; if [[ ! -d \"jdk\" ]]; then unzip -q -o jre.zip -d jdk fi&#125;4.3.3. Agent包下载实现Agent包下载接口:@ApiOperation(\"下载agent.zip\")@GET@Path(\"/&#123;agentId&#125;/agent\")fun downloadAgent( @PathParam(\"agentId\") agentId: String, @QueryParam(\"eTag\") eTag: String?, @QueryParam(\"arch\") arch: String?): Response主要实现步骤:根据操作系统准备文件:JAR包: worker-agent.jarJRE: 对应系统的jre.zip二进制文件: devopsAgent、devopsDaemon等安装脚本: install.sh/bat等配置文件打包成agent.zip返回注意：macOS JDK 必须带 Contents/Home 结构。若 Intel 版 jre.zip 缺失该路径，临时可以执行命令 mkdir -p Contents/Home &amp;&amp; unzip -d Contents/Home jre.zip &amp;&amp; zip -r jre.zip Contents 修正；后续需更新 environment 模块中的 jre.zip，并制作新的镜像。4.3.4. 各系统服务注册实现Linux (通过 rc.local)function installAgentService() &#123; # 添加到rc.local实现开机自启 echo \"cd $&#123;workspace&#125; &amp;&amp; ./devopsDaemon &amp; # $&#123;service_name&#125;\" &gt;&gt; /etc/rc.d/rc.local $&#123;workspace&#125;/start.sh&#125;MacOS (通过 launchd)&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;&lt;plist version=\"1.0\"&gt;&lt;dict&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;$(getServiceName)&lt;/string&gt; &lt;key&gt;Program&lt;/key&gt; &lt;string&gt;$&#123;workspace&#125;/devopsDaemon&lt;/string&gt; &lt;key&gt;RunAtLoad&lt;/key&gt; &lt;true/&gt; &lt;key&gt;WorkingDirectory&lt;/key&gt; &lt;string&gt;$&#123;workspace&#125;&lt;/string&gt; &lt;key&gt;KeepAlive&lt;/key&gt; &lt;false/&gt;&lt;/dict&gt;&lt;/plist&gt;Windows (通过 Windows Service)sc create %service_name% binPath&#x3D; &quot;%work_dir%\\devopsDaemon.exe&quot; start&#x3D; autosc start %service_name%4.3.5. Agent进程启动主要通过start.sh/bat脚本实现:创建工作目录解压配置JDK环境启动devopsDaemon守护进程写入pid文件检查进程状态核心启动代码:function start() &#123; # 创建必要目录 mkdir -p $&#123;workspace&#125;/workspace mkdir -p $&#123;workspace&#125;/logs # 启动守护进程 nohup $&#123;workspace&#125;/devopsDaemon &gt; /dev/null 2&gt;&amp;1 &amp; # 检查进程状态 pid=`cat $&#123;workspace&#125;/runtime/daemon.pid` if isPidExists $&#123;pid&#125;; then echo \"agent daemon is running, pid: $pid\" fi&#125;5. 总结蓝盾 Agent 安装方式:手动安装：通过 Web 界面操作，适合少量节点自动化安装：通过 API 接口，适合批量部署了解底层实现原理后，我们可以根据实际需求选择合适的安装方式，并进行二次开发和流程优化。6. 参考蓝盾官方文档 - 私有构建机蓝盾开源项目","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾流水线中的 Kubernetes 调度优化","slug":"devops/landun_dispatch_scheduler","date":"2025-07-29T16:00:00.000Z","updated":"2025-07-30T04:20:33.463Z","comments":true,"path":"2025/07/30/devops/landun_dispatch_scheduler/","link":"","permalink":"https://blazehu.github.io/2025/07/30/devops/landun_dispatch_scheduler/","excerpt":"在大量使用蓝盾「Docker公共构建机」来跑构建任务后，我们发现拉起的构建 Pod 通过 hostPath 挂载工作目录做缓存，当同一流水线任务重复执行时能够加速，本文介绍蓝盾调度器如何进行调度到有缓存的节点。","text":"在大量使用蓝盾「Docker公共构建机」来跑构建任务后，我们发现拉起的构建 Pod 通过 hostPath 挂载工作目录做缓存，当同一流水线任务重复执行时能够加速，本文介绍蓝盾调度器如何进行调度到有缓存的节点。1. 背景在前文蓝盾「Docker公共构建机」缓存清理中我们通过分析源码，知道拉起的构建 Pod 通过 hostPath 挂载工作目录做缓存。我们接下来进一步分析创建 Pod 的流程。2. 部署配置dispatch-k8s-manager/resources/config.yamldispatch: # 调度需要使用到的label，确定构建机唯一性 label: bkci.dispatch.kubenetes/core # 通过k8s watch来观察构建机状态 watch: task: label: bkci.dispatch.kubenetes/watch-task builder: # 将构建机调度到指定标签节点的配置，不填写则在集群内都可以调度，优先级小于专机和特殊机器 nodeSelector: label: value: # 构建机曾经调度过的节点名称列表 nodesAnnotation: bkci.dispatch.kubenetes/builder-history-nodes # 容器历史资源使用相关 realResource: # 监控构建机容器资源使用的 prometheus api地址， 字段为空则不开启realResource优化 # 注：集群内为 集群内为 &lt;service&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;port&gt; prometheusUrl: realResourceAnnotation: bkci.dispatch.kubenetes/builder-real-resources # 一些具有特定属性的机器，例如独特的网络策略 specialMachine: label: bkci.dispatch.kubenetes/special-builder # 只给特定用户使用的专机 privateMachine: label: bkci.dispatch.kubenetes/private-builder通过 dispatch-k8s-manager 模块的配置文件，我们发现可以通过 nodeSelector、 nodesAnnotation 、realResource 等配置来设置调度策略。3. 源码分析3.1 亲和性和污点容忍dispatch-k8s-manager/pkg/apiserver/service/builder_start.gofunc CreateBuilder(builder *Builder) (taskId string, err error) &#123; volumes, volumeMounts := getBuilderVolumeAndMount(builder.Name, builder.NFSs) var replicas int32 = 1 tolers, nodeMatches := buildDedicatedBuilder(builder) ... annotations, err := getBuilderAnnotations(builder.Name) if err != nil &#123; return \"\", err &#125; ... go task.DoCreateBuilder( taskId, &amp;kubeclient.Deployment&#123; Name: builder.Name, Labels: labels, MatchLabels: matchlabels, Replicas: &amp;replicas, Pod: kubeclient.Pod&#123; Labels: labels, Annotations: annotations, Volumes: volumes, Containers: []kubeclient.Container&#123; &#123; Image: builder.Image, Resources: *resources, Env: getEnvs(builder.Env), Command: builder.Command, VolumeMounts: volumeMounts, &#125;, &#125;, NodeMatches: nodeMatches, Tolerations: tolers, PullImageSecret: pullImageSecret, &#125;, &#125;, ) return taskId, nil&#125;// buildDedicatedBuilder 获取污点和节点亲和度配置func buildDedicatedBuilder(builder *Builder) ([]corev1.Toleration, []kubeclient.NodeMatch) &#123; // 优先读取专机配置 ... // 读取具有特殊配置的机器 ... // 如果配置中配置了节点选择器则使用节点选择器 ... return nil, nil&#125;// getBuilderAnnotations 获取构建机注释配置func getBuilderAnnotations(builderName string) (map[string]string, error) &#123; ... // 获取节点记录，用来把构建机分配到已有的节点 ... // 获取RealResource记录 ... return result, nil&#125;dispatch-k8s-manager/pkg/kubeclient/deployment.gofunc CreateDeployment(dep *Deployment) error &#123; ... // 将 NodeMatches 转为 nodeAffinity var affinity *corev1.Affinity if len(dep.Pod.NodeMatches) &gt; 0 &#123; var matches []corev1.NodeSelectorRequirement for _, mat := range dep.Pod.NodeMatches &#123; matches = append(matches, corev1.NodeSelectorRequirement&#123; Key: mat.Key, Operator: mat.Operator, Values: mat.Values, &#125;) &#125; affinity = &amp;corev1.Affinity&#123; NodeAffinity: &amp;corev1.NodeAffinity&#123; RequiredDuringSchedulingIgnoredDuringExecution: &amp;corev1.NodeSelector&#123; NodeSelectorTerms: []corev1.NodeSelectorTerm&#123; &#123; MatchExpressions: matches, &#125;, &#125;, &#125;, &#125;, &#125; &#125; ... return nil&#125;在 CreateBuilder 里，调度相关的两个核心参数 tolers 和 nodeMatches 都是通过 buildDedicatedBuilder(builder) 返回的，这两个参数会一起传递给 kubeclient 层，在 kubeclient 的 CreateDeployment 方法中：NodeMatches 会被转换为 affinity.nodeAffinity，用于节点亲和调度。Tolerations 会直接下发到 Pod 的 spec.tolerations 字段，用于污点容忍。3.2 历史节点调度蓝盾源码里我们找到了有关亲和性以及污点容忍的实现，但是有关历史节点调度的实现只有通过 getBuilderAnnotations 给 Pod 设置注解。至于如何通过注解影响调度在蓝盾源码里并没有找到相关内容。我们进一步分析发现，历史节点调度需要通过蓝盾基于K8S调度插件实现。apiVersion: v1kind: Podmetadata: annotations: bkci.dispatch.kubenetes/builder-history-nodes: '[\"10.x.x.1\",\"10.x.x.2\",\"10.x.x.3\"]' labels: bkci.dispatch.kubenetes/core: build1753761077695-ivcpmoxg bkci.dispatch.kubenetes/watch-task: t-1753785688231121886-iInjpMUr-builder-start name: build1753761077695-ivcpmoxg-c9d8fc6c9-mqhkk ...package bkdevopsschedulerpluginimport ( \"context\" \"encoding/json\" \"k8s.io/api/core/v1\" \"k8s.io/kubernetes/pkg/scheduler/framework\")const nodesAnnotation = \"bkci.dispatch.kubenetes/builder-history-nodes\"const readResourceAnnotation = \"bkci.dispatch.kubenetes/builder-real-resources\"type realResourceUsage struct &#123; Cpu string `json:\"cpu\"` Memory string `json:\"memory\"`&#125;func (s *SchedulerPlugin) Score(_ context.Context, _ *framework.CycleState, pod *v1.Pod, nodeName string) (int64, *framework.Status) &#123; // 读取历史节点信息 var nodeHis []string if nodesS, ok := pod.ObjectMeta.Annotations[nodesAnnotation]; ok &#123; _ = json.Unmarshal([]byte(nodesS), &amp;nodeHis) &#125; // 读取资源信息 var realResources []realResourceUsage if realS, ok := pod.ObjectMeta.Annotations[readResourceAnnotation]; ok &#123; _ = json.Unmarshal([]byte(realS), &amp;realResources) &#125; // 计算历史节点分数 nodeScore := calculateNodeHisScore(nodeHis, nodeName) // 计算资源分数 // ...省略资源分数计算逻辑... realResourceScore := ... // 通过 realResources 和节点资源情况计算 // 返回总分 return nodeScore + realResourceScore, nil&#125;var nodeHisScores = map[int]int64&#123;0: 30, 1: 20, 2: 10&#125;// calculateNodeHisScore 计算历史节点分数，将3个历史节点从最近到最远依次打分 30 - 10分func calculateNodeHisScore(nodeHis []string, nodeName string) int64 &#123; if len(nodeHis) == 0 &#123; return framework.MinNodeScore &#125; for index, name := range nodeHis &#123; if name != nodeName &#123; continue &#125; score := framework.MinNodeScore if indexS, ok := nodeHisScores[index]; ok &#123; score = indexS &#125; return score &#125; return framework.MinNodeScore&#125;在插件的 Score 阶段，会读取 Pod 的 bkci.dispatch.kubenetes/builder-history-nodes 注解内容，并将其反序列化为历史节点名称数组，即提供历史节点信息。插件通过 calculateNodeHisScore 方法，根据当前调度节点是否在历史节点列表中，以及其在列表中的顺序，给予不同的分数（最近的历史节点分数最高）。该分数会与资源分数（通过 bkci.dispatch.kubenetes/builder-real-resources 注解和节点资源情况计算得出）相加，作为最终调度优先级，影响调度器选择节点的排序。4. 总结在蓝盾流水线中，通过以下方式实现了 Kubernetes 的调度优化：历史节点调度：通过注解记录历史节点信息，调度插件优先选择这些节点，减少初始化时间。亲和性（Affinity）：根据配置文件中的 nodeSelector 和代码中的 NodeMatches 转换为 nodeAffinity，确保 Pod 调度到特定节点。污点容忍（Tolerations）：仅在配置文件中指定了专机（privateMachine）时，生成污点容忍配置，允许 Pod 调度到带特定污点的节点。这些机制协同提升了调度效率和资源利用率。5. 参考https://github.com/TencentBlueKing/bk-ci/blob/v2.0.0/https://github.com/TencentBlueKing/ci-dispatch-k8s-manager-plugin","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"},{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾「Docker公共构建机」全链路源码解析","slug":"devops/landun_dispatch","date":"2025-07-17T16:00:00.000Z","updated":"2025-08-15T03:50:45.300Z","comments":true,"path":"2025/07/18/devops/landun_dispatch/","link":"","permalink":"https://blazehu.github.io/2025/07/18/devops/landun_dispatch/","excerpt":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。日常 CI 场景中，开发者点击 「执行流水线」 后，如果 Job 的构建类型选择 「容器构建机」，最终会在 Kubernetes 中启动一个 Deployment 作为构建 Pod。","text":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。日常 CI 场景中，开发者点击 「执行流水线」 后，如果 Job 的构建类型选择 「容器构建机」，最终会在 Kubernetes 中启动一个 Deployment 作为构建 Pod。1. 背景本文以蓝盾社区版7.1为例，结合实际源码和配置，详细梳理从前端点击「执行」到最终在 Kubernetes 集群拉起 Deployment 的全链路调用过程，2. 工程鸟瞰bk-ci/src├── gateway # OpenResty 网关（Lua）├── frontend # Vue 前端，模块级微前端├── backend # Kotlin + SpringCloud 微服务│ ├── process # 流水线引擎│ ├── dispatch # 构建调度（Docker &amp; K8s）│ └── ...├── agent # Go 语言 Agent└── pipeline-plugin # Java 插件 SDK3. 源码拆解3.1 前端触发页面地址：https://devops.bk.tencent.com/console/pipeline/{projectId}/{pipelineId}/preview事件/方法对应后端接口作用requestStartupInfoGET /ms/process/api/user/builds/{p}/{pl}/manualStartupInfo获取流水线启动所需参数executePipeline()POST /ms/process/api/user/builds/{p}/{pl}真正触发流水线执行相关文件路径：src/frontend/devops-pipeline/src/views/subpages/preview.vue： 获取流水线启动所需参数src/frontend/devops-pipeline/src/components/PipelineHeader/PreviewHeader.vue： 点击执行按钮，触发流水线执行通过全局事件总线 bus 通信，以及具名视图（named views）机制实现页面拆分和组合。在 preview.vue 页面监听 executePipeline 事件，然后在 PreviewHeader.vue 中通过事件总线触发执行。3.2 网关转发/ms/process/api/user/builds/… 统一转发到 process 微服务。location /ms/process/ &#123; proxy_pass http://process/;&#125;3.3 Process 服务：流水线启动主链路主要方法调用链如下：UserBuildResource.manualStartup() // 接收启动流水线的请求 ↓ServiceBuildResourceImpl.manualStartup() // 具体实现，做参数校验、权限校验等 ↓PipelineBuildFacadeService.buildManualStartup() // 负责组装启动参数、调用核心服务 ↓PipelineBuildService.startPipeline() // 启动流水线主流程，负责流水线状态流转、记录等 ↓PipelineRuntimeService.startBuild() // 流水线引擎，解析模型，调度 Stage/Job/Container，准备构建任务这一阶段主要负责接收前端的启动请求，经过参数校验、权限校验后，组装启动参数，最终进入流水线引擎。流水线引擎会解析流水线的模型（YAML/DSL），为后续的调度和任务准备做铺垫。3.4. 生成并下发构建任务主要方法调用链如下：PipelineContainerService.prepareBuildContainerTasks() // 遍历流水线模型，为每个 Job/Container 生成任务，判断分发类型 ↓VmOperateTaskGenerator.makeStartVMContainerTask() // 针对容器构建机，生成 VM 启动任务（taskAtom = \"dispatchVMStartupTaskAtom\"） ↓pipelineEventDispatcher.dispatch(PipelineBuildStartEvent()) // 下发流水线启动事件此阶段会遍历流水线模型中的每个 Job/Container，根据其类型（如容器构建机）生成对应的任务。对于容器构建机，会生成 VM 启动任务，并通过事件分发器下发流水线启动事件，为后续的事件驱动调度做准备。3.5. 事件驱动：Stage/Container/Task 调度主要方法调用链如下：PipelineBuildStartListener.run(event) // 消费 PipelineBuildStartEvent，驱动流水线调度 ↓BuildStartControl.handle(event) ↓PipelineBuildStartEvent.execute(watcher) ↓buildModel() ↓pipelineEventDispatcher.dispatch(PipelineBuildStageEvent()) // 下发 Stage 事件PipelineStageBuildListener.run(event) // 消费 PipelineBuildStageEvent ↓StageControl.handle(event) ↓PipelineBuildStageEvent.execute(watcher) ↓pipelineContainerService.listContainers(...) // 遍历当前 Stage 下所有 Container（Job） ↓pipelineEventDispatcher.dispatch(PipelineBuildContainerEvent()) // 为每个 Job 下发事件PipelineContainerBuildListener.run(event) // 消费 PipelineBuildContainerEvent ↓ContainerControl.handle(event) ↓ContainerCmdChain.doCommand(context) // 命令链执行，关键命令 StartActionTaskContainerCmd ↓pipelineEventDispatcher.dispatch(PipelineBuildAtomTaskEvent()) // 下发插件任务事件蓝盾采用事件驱动架构，每个阶段（Stage）、每个 Job（Container）、每个插件（Task）都通过事件进行调度。每个事件都有对应的 Listener 消费，逐步推进流水线的执行流程，保证了系统的高解耦和可扩展性。3.6. 插件任务调度与 VM 启动主要方法调用链如下：PipelineAtomTaskBuildListener.run(event) // 消费 PipelineBuildAtomTaskEvent ↓TaskControl.handle(event) ↓taskAtomService.start(buildTask) ↓SpringContextUtil.getBean(IAtomTask::class.java, task.taskAtom).execute(task, runVariables) ↓DispatchVMStartupTaskAtom.execute() // 对于 VM 启动任务，加载并执行 ↓dispatch() ↓getDispatchType() // 返回 DockerDispatchType（社区版容器构建机默认） ↓pipelineEventDispatcher.dispatch(PipelineAgentStartupEvent()) // 下发分发事件每个插件任务（Atom）都会被动态加载并执行。对于 VM 启动任务，会加载 DispatchVMStartupTaskAtom 插件，判断分发类型（如 Docker），并下发 PipelineAgentStartupEvent，为后续的构建机分发做准备。3.7. dispatch-docker 服务：分发到 k8s主要方法调用链如下：DockerVMListener.onStartup(dispatchMessage) // 消费 PipelineAgentStartupEvent ↓getDockerRoutingType(projectId) // 判断路由类型（如 configmap 配置为 \"KUBERNETES\"） ↓startKubernetesDocker(...) // 路由类型为 KUBERNETES 时，走 k8s 资源池 ↓DispatchBuildService.startUp() ↓createAndStartNewBuilder() ↓containerServiceFactory.load(projectId).createAndStartBuilder() ↓KubernetesContainerService.createAndStartBuilder() ↓kubernetesBuilderClient.createBuilder() // HTTP POST /api/builders 调用 dispatch-k8s-managerdispatch-docker 服务会根据项目的路由配置，决定是走本地 Docker 还是 k8s 资源池。若配置为 KUBERNETES，则会通过 HTTP 请求调用 dispatch-k8s-manager 服务，准备在 k8s 集群中拉起构建容器。查看 bk-ci-bk-ci-dispatch-docker 这个 configmap，可以发现配置文件里的 defaultDockerRoutingType 是 “KUBERNETES”。3.8. dispatch-k8s-manager 服务：拉起 k8s Deployment主要方法调用链如下：POST /api/builders // 路由 ↓createBuilder handler ↓service.CreateBuilder ↓task.DoCreateBuilder ↓kubeclient.CreateDeployment(dep) // 通过 k8s API 创建 Deployment，拉起实际的构建容器dispatch-k8s-manager 服务负责与 Kubernetes API 交互，接收来自 dispatch-docker 的 HTTP 请求后，组装 Deployment 对象并调用 k8s API，最终在集群中拉起实际的构建容器，完成流水线的环境准备。3.9 总结时序图4. 总结阶段关键技术点一句话描述前端Vue + Event Bus点击按钮 → 事件总线 → 请求发出网关OpenResty 前缀转发统一入口，/ms/process/** 直接透传至 process 服务。流程引擎自研事件-命令链框架PipelineBuildStart → Stage → Container → Task → AgentStartup，层层事件推进，高内聚低耦合。插件IAtomTask SPI 机制运行时动态加载 DispatchVMStartupTaskAtom，扩展即插即用。调度dispatch-docker → dispatch-kubernetes根据 defaultDockerRoutingType=KUBERNETES 路由到对应资源池。K8s 交付dispatch-k8s-manager 与 kube-apiserver 交互一条 HTTP 请求即可在集群内拉起 Deployment，数秒完成环境就绪。5. 参考https://github.com/TencentBlueKing/bk-ci/tree/v2.0.0","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾「Docker公共构建机」缓存清理","slug":"devops/landun_dind_cleaner","date":"2025-07-16T16:00:00.000Z","updated":"2025-07-30T03:02:53.139Z","comments":true,"path":"2025/07/17/devops/landun_dind_cleaner/","link":"","permalink":"https://blazehu.github.io/2025/07/17/devops/landun_dind_cleaner/","excerpt":"在使用蓝盾「Docker公共构建机」一段时间后，我们发现构建镜像偶发性超时。排查后发现是由于集群的 Node 节点的磁盘满了，本文会介绍如何清理构建缓存。","text":"在使用蓝盾「Docker公共构建机」一段时间后，我们发现构建镜像偶发性超时。排查后发现是由于集群的 Node 节点的磁盘满了，本文会介绍如何清理构建缓存。1. 背景我们发现构建镜像偶发性超时，排查发现是上了 Docker-in-Docker 构建镜像之后发生的，而且发生频率越来越高，进一步排查发现是由于 Pod 会通过 hostPath 挂载工作目录和日志目录，由于构建任务过多导致 Node 节点磁盘打满。2. 排查过程2.1 事件分析通过 Pod 事件可以发现是由于 Node 节点磁盘打满，导致 Pod 被驱逐，构建任务失败。Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning Evicted 20m kubelet The node was low on resource: ephemeral-storage. Container build1753761077695-ivcpmoxg was using 1580320Ki, which exceeds its request of 0. Normal NodeHasNoDiskPressure 3m (x32 over 6d5h) kubelet Node 10.10.32.2 status is now: NodeHasNoDiskPressurepod yaml是由于 Pod 通过 hostPath 挂载工作目录和日志目录，通过 hostPath 挂载目录是为了做缓存，当同一流水线任务重复执行时能够加速。volumes:- hostPath: path: /data/landun/workspace/build1753761077695-ivcpmoxg type: \"\" name: data-volume- hostPath: path: /data/landun/logs/build1753761077695-ivcpmoxg type: \"\" name: logs-volumedispatch-k8s-manager 模块的配置文件dispatch-k8s-manager/resources/config.yamldispatch: volume: # 构建机脚本 builderConfigMap: name: dispatch-kubernetes-builder items: # 初始化脚本 - key: initsh.properties path: init.sh # 登录调试需要的sleep脚本 - key: sleepsh.properties path: sleep.sh hostPath: # 数据盘 dataHostDir: /data/landun/workspace # 日志盘 logsHostDir: /data/landun/logs # 应用数据使用cfs cfs: path: /data/cfs volumeMount: dataPath: /data/landun/workspace logPath: /data/logs builderConfigMapPath: /data/landun/config cfs: path: /data/bkdevops/apps readOnly: true2.2 源码分析dispatch-k8s-manager/pkg/apiserver/service/builder_start.go// getBuilderVolumeAndMount 获取一些构建机的常规的被挂载到pod上的volume和mountfunc getBuilderVolumeAndMount( workloadName string, nFSs []types.NFS,) (volumes []corev1.Volume, volumeMounts []corev1.VolumeMount) &#123; volumes = getBuilderPodVolume(workloadName) volumeMounts = getBuilderPodVolumeMount() ... return volumes, volumeMounts&#125;// getBuilderPodVolume 获取一些构建机的常规的被挂载到pod上的volume，包括配置configmap和data目录hostpathfunc getBuilderPodVolume(workloadName string) []corev1.Volume &#123; dataHostPath := filepath.Join(config.Config.Dispatch.Volume.HostPath.DataHostDir, workloadName) logHostPath := filepath.Join(config.Config.Dispatch.Volume.HostPath.LogsHostDir, workloadName) var items []corev1.KeyToPath for _, v := range config.Config.Dispatch.Volume.BuilderConfigMap.Items &#123; items = append(items, corev1.KeyToPath&#123; Key: v.Key, Path: v.Path, &#125;) &#125; return ...&#125;通过源码分析可以发现 hostPath 是通过 dispatch-k8s-manager/resources/config.yaml 加上 workloadName 拼接而成的，所以没办法通过配置文件控制不使用 hostPath，于是我们通过定时任务来清理该缓存。3. 解决方案参考 bk-applog-bkapp-filebeat 的日志清理方案，通过 DaemonSet 实现蓝盾挂载工作目录实施定时清理操作。NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEbk-applog-bkapp-filebeat-ingress 18 18 18 18 18 &lt;none&gt; 424dbk-applog-bkapp-filebeat-json 18 18 18 18 18 &lt;none&gt; 424dbk-applog-bkapp-filebeat-log-cleaner 18 18 18 18 18 &lt;none&gt; 424dbk-applog-bkapp-filebeat-stdout 18 18 18 18 18 &lt;none&gt; 424dbk-ci-builder-cleaner 18 18 18 18 18 &lt;none&gt; 13d编写 daemonSet.yamlapiVersion: apps/v1kind: DaemonSetmetadata: name: bk-ci-builder-cleaner namespace: blueking labels: app: bk-ci-builderspec: revisionHistoryLimit: 10 selector: matchLabels: app: bk-ci-builder template: metadata: labels: app: bk-ci-builder name: bk-ci-builder-cleaner spec: hostPID: true restartPolicy: Always serviceAccountName: bk-applog-bkapp-filebeat containers: - name: batch-delete-files image: xxx.xxx.com/bk-ci-builder-cleaner:v1 imagePullPolicy: IfNotPresent command: - bash args: - -c - while true; do ./delete_files.sh; sleep 21600; done; resources: requests: cpu: 25m memory: 32Mi limits: cpu: 2560m memory: 256Mi volumeMounts: - mountPath: /data/devops/workspace name: data-volume - mountPath: /data/devops/logs name: logs-volume volumes: - name: data-volume hostPath: path: /data/landun/workspace type: DirectoryOrCreate - name: logs-volume hostPath: path: /data/landun/logs type: DirectoryOrCreate缓存清理脚本 delete_files.sh#!/usr/bin/env bash# delete_files.sh —— 正式删除版# 同时扫描 /data/devops/workspace 和 /data/devops/logsset -euo pipefail# --------- 可配置参数 ---------ROOT_DIRS=(\"/data/devops/workspace\" \"/data/devops/logs\")RETENTION_DAYS=7LOG_FILE=\"/tmp/delete_build_dirs.log\"# -----------------------------log() &#123; printf '%s [%s] %s\\n' \"$(date '+%F %T')\" \"$1\" \"$2\" | tee -a \"$LOG_FILE\"&#125;cutoff_date=$(date -d \"$RETENTION_DAYS days ago\" +%F)log INFO \"==== 开始检查并删除 $RETENTION_DAYS 天未更新的 build* 目录 ====\"for root in \"$&#123;ROOT_DIRS[@]&#125;\"; do [[ -d $root ]] || &#123; log WARN \"目录不存在: $root\"; continue; &#125; for dir in \"$root\"/build*; do [[ -d $dir ]] || continue # 二次确认：目录内是否仍无任何 7 天内更新的文件 if ! find \"$dir\" -type f -newermt \"$cutoff_date\" -print -quit | grep -q .; then log DELETE \"$dir\" rm -rf \"$dir\" else log SKIP \"$dir\" fi donedonelog INFO \"==== 清理完成，日志: $LOG_FILE ====\"4. 参考https://github.com/TencentBlueKing/bk-ci/blob/v2.0.0/","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾从单机到 DinD 的实践","slug":"devops/landun_dind","date":"2025-06-26T16:00:00.000Z","updated":"2025-09-26T07:22:29.384Z","comments":true,"path":"2025/06/27/devops/landun_dind/","link":"","permalink":"https://blazehu.github.io/2025/06/27/devops/landun_dind/","excerpt":"传统的单机构建环境在项目变大、任务变多时，容易出问题，比如容易崩溃、资源不够用、任务排队，以及成本和资源利用的矛盾。本文会介绍用容器化技术Docker-in-Docker（DinD）来解决这些问题，打造一个灵活、高效的CI/CD系统。","text":"传统的单机构建环境在项目变大、任务变多时，容易出问题，比如容易崩溃、资源不够用、任务排队，以及成本和资源利用的矛盾。本文会介绍用容器化技术Docker-in-Docker（DinD）来解决这些问题，打造一个灵活、高效的CI/CD系统。1. 背景当前构建环境因依赖单台机器，面临诸多挑战：单点故障风险，硬件或网络故障易致构建流程中断；资源瓶颈，频繁的构建任务使机器负载过高，频繁触发告警，影响系统稳定性；任务堆积，大量任务积压致后续任务延迟甚至超时失败，降低构建效率；成本与资源利用问题，增加机器虽可缓解资源紧张，但会增加运维和硬件成本，且任务非持续高峰，部分时间资源闲置浪费。2. 技术选型方案2.1 KanikoKaniko 是谷歌开源的一款构建容器镜像的工具。Kaniko 并不依赖于 Docker 守护进程，完全在用户空间根据 Dockerfile 的内容逐行执行命令来构建镜像，这就使得在一些无法获取 docker 守护 进程的环境下也能够构建镜像。Kaniko 通过提取基础镜像的文件系统，按顺序执行 Dockerfile 中的指令，每执行一条指令后在用户空间创建文件系统的快照并与上一状态对比，若有变化则生成新镜像层并更新元数据，最终将构建好的镜像推送到镜像仓库。2.1.1 简单例子下面是一个使用kaniko的构建的简单例子创建密钥kubectl create secret generic -n blazehu kaniko-secret-common --from-file=config.json构建测试apiVersion: v1kind: Podmetadata: name: kanikospec: containers: - name: kaniko image: m.daocloud.io/gcr.io/kaniko-project/executor:latest args: - \"--dockerfile=Dockerfile\" - \"--context=git://user:password@github.com:blazehu/go-examples.git#master\" - \"--destination=blazehu1122/example:latest\" volumeMounts: - name: kaniko-secret mountPath: /kaniko/.docker/ restartPolicy: Never volumes: - name: kaniko-secret secret: secretName: kaniko-secret-common使用 kaniko-project/executor:latest 镜像执行构建任务构建参数 –context: 上下文指定 Git Repository（仅支持 git://[repository url][#reference][#commit-id] 格式）构建参数 –destination: 指定配置的推送镜像的地址镜像推送挂载了 kaniko-secret 密钥2.1.2 构建新的CI镜像那我们如何结合蓝盾来实现Dind呢？我们需要重新制作一个新的蓝盾CI镜像，参考《构建并托管一个 CI 镜像 》，该CI镜像需要包括 kaniko 执行器。这里通过多阶段构建来制作新的CI镜像。FROM m.daocloud.io/gcr.io/kaniko-project/executor:latest as kanikoFROM bkci/ci:latest# 复制必要文件COPY --from=kaniko /kaniko /kanikoRUN chmod +x /kaniko/executorRUN apt install -y git python-pip python3-pip \\ &amp;&amp; pip config set global.index-url https://mirrors.aliyun.com/pypi/simple \\ &amp;&amp; pip config set install.trusted-host mirrors.aliyun.com# 设置环境变量ENV PATH $PATH:/kanikoENV DOCKER_CONFIG /kaniko/.dockerENV SSL_CERT_DIR /kaniko/ssl/certs# 验证 kaniko 可执行文件RUN /kaniko/executor version2.1.3 蓝盾流水线第一步使用蓝盾 Checkout 插件拉取代码第二步使用蓝盾 Shell Script 插件执行 kaniko 构建命令kaniko/executor --context=/data/devops/workspace --dockerfile=Dockerfile --destination=blazehu1122/example:latest --ignore-path=/ \"2.2 Dind Unix Socket使用 DaemonSet 来启动 Dind Pod，将 Docker socket 文件 /var/run/docker.sock 挂载到 Pod 中。在要使用Docker服务的 Pod 中都需要挂载 socket文件。2.2.1 简单例子apiVersion: apps/v1kind: DaemonSetmetadata: name: dinp-daemonsetspec: selector: matchLabels: name: dinp-daemonset template: metadata: labels: name: dinp-daemonset spec: containers: - name: dind image: docker:dind securityContext: privileged: true volumeMounts: - name: dockersock mountPath: /var/run/docker.sock volumes: - name: dockersock hostPath: path: /var/run/docker.sock type: Socket在这个配置中，/var/run/docker.sock 被挂载到 Pod 中，允许 Pod 直接与宿主机上的 Docker 守护进程通信。这种方式不需要设置 DOCKER_HOST 环境变量，因为 Docker 客户端和守护进程直接通过 socket 文件通信。2.3 Dind TCP定义一个 Deployment 和一个 Service，用于启动一个包含 Dind 的 Pod，并通过 Service 对外提供 Docker 服务。在要使用Docker服务的 Pod 中设置 DOCKER_HOST 环境变量，使得 Docker 客户端知道如何连接到 Docker 守护进程（比如在bkci的基础镜像中注入该环境变量）。2.3.1 简单例子apiVersion: apps/v1kind: Deploymentmetadata: name: dinp-deployment namespace: blueking labels: name: dinp-deploymentspec: replicas: 1 selector: matchLabels: name: dinp-deployment template: metadata: labels: name: dinp-deployment spec: containers: - name: dind image: docker:dind resources: requests: memory: \"4Gi\" cpu: \"2\" limits: memory: \"8Gi\" cpu: \"4\" securityContext: privileged: true env: - name: DOCKER_TLS_CERTDIR value: \"\" - name: DOCKER_HOST value: tcp://localhost:2375 tty: true volumeMounts: - name: docker-storage mountPath: /var/lib/docker - name: docker-run mountPath: /var/run readinessProbe: exec: command: [\"docker\", \"info\"] initialDelaySeconds: 10 failureThreshold: 6 livenessProbe: exec: command: [\"docker\", \"info\"] initialDelaySeconds: 60 failureThreshold: 10 ## 污点配置 tolerations: - key: \"svc\" value: \"bk\" operator: \"Equal\" effect: \"NoSchedule\" affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \"app.kubernetes.io/name\" operator: \"In\" values: - dockerhost topologyKey: \"kubernetes.io/hostname\" volumes: - name: docker-storage hostPath: path: /var/lib/docker_in_pod - name: docker-run hostPath: path: /blueking/run type: DirectoryOrCreate---apiVersion: v1kind: Servicemetadata: name: bk-ci-docker-dinp namespace: bluekingspec: selector: name: dinp-deployment ports: - protocol: TCP port: 2375 targetPort: 2375在需要使用 Docker 的 Pod 中设置 DOCKER_HOST 环境变量为 bk-ci-docker-dinp.blueking.svc.cluster.local，通过 Kubernetes Service 的域名解析和端口转发机制，使 Pod 内的 Docker 客户端能够连接到后端的 Docker 守护进程。2.3.2 蓝盾流水线第一步使用蓝盾 Checkout 插件拉取代码第二步使用蓝盾 Shell Script 插件执行 docker 构建命令docker context create dind --docker \"host=tcp://bk-ci-docker-dinp.blueking.svc.cluster.local:2375,ca=/root/.docker/certs/ca.pem,cert=/root/.docker/certs/cert.pem,key=/root/.docker/certs/key.pem\" docker context use dinddocker build --platform=linux/amd64 -t $&#123;IMAGE_REPO&#125;:$&#123;IMAGE_TAG&#125; -f Dockerfile . --push3. 技术选型对比特性/方案KanikoDind Unix SocketDind TCP依赖环境不依赖 Docker 守护进程依赖宿主机 Docker Socket依赖宿主机 Docker 守护进程（TCP）部署复杂度简单，只需部署 Pod中等，需要配置 DaemonSet较复杂，需要配置 Deployment 和 Service资源消耗低中等较高安全性高中等中等适用场景Kubernetes 环境单机或多节点集群跨节点或 Kubernetes 集群蓝盾集成难度中等低中等虽然我们最终选择了 Kaniko 方案，但在实际应用中发现，基于 m.daocloud.io/gcr.io/kaniko-project/executor:latest 制作的蓝盾 CI 镜像存在一些兼容性问题。根据 Kaniko 的官方文档，这种做法并不被推荐，可能会导致一些不可预见的问题。后续将根据蓝盾的官方文档和 Kaniko 的最佳实践，建议重新制作 CI 镜像。4. 参考https://github.com/GoogleContainerTools/kanikohttps://juejin.cn/post/7217665415710081081https://bk.tencent.com/docs/markdown/ZH/Devops/3.0/UserGuide/Services/Store/ci-images/docker-build.md","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"},{"name":"dind","slug":"dind","permalink":"https://blazehu.github.io/tags/dind/"}]},{"title":"ArgoCD 使用 GitLab 和 Dex 实现单点登录","slug":"cloudnative/argocd_sso_gitlab","date":"2025-06-15T16:00:00.000Z","updated":"2025-10-17T03:59:52.110Z","comments":true,"path":"2025/06/16/cloudnative/argocd_sso_gitlab/","link":"","permalink":"https://blazehu.github.io/2025/06/16/cloudnative/argocd_sso_gitlab/","excerpt":"ArgoCD 初始仅提供 admin 账号，用于首次部署和配置；为安全与协作，后续应启用本地用户或接入 SSO，避免长期使用超级管理员账号。","text":"ArgoCD 初始仅提供 admin 账号，用于首次部署和配置；为安全与协作，后续应启用本地用户或接入 SSO，避免长期使用超级管理员账号。1. 概述ArgoCD 以“开箱即用”的方式内置了 Dex（一个轻量级 OIDC 代理）。Dex 的职责只有一个：把企业里各式各样的身份源（SAML、LDAP、GitHub、GitLab …）统一翻译成 ArgoCD 能消费的 OIDC 令牌，从而把 ArgoCD SSO 落地成两行配置。下文以 GitLab OAuth2 为样本，演示如何修改 argocd-cm ConfigMap 完成连接器编排，并给出可直接粘贴的 GitLab-Dex 最小 YAML 模板。2. 整体流程GitLab: 注册 OAuth2 Application → 获取 Client ID/SecretArgoCD: 修改 argocd-cm 注入 dex gitlab 连接器ArgoCD: 修改 argocd-rbac-cm 把 GitLab Group 映射成 ArgoCD 角色3. GitLab 配置打开 Admin Area → Applications → New Application填写关键点Name：argocd-dexRedirect URI：https://argocd.blazehu.com/api/dex/callbackScopes：勾选 read_user openid profile email保存后记录 ClientID 和 ClientSecret4. ArgoCD 接入 Dex（GitLab 连接器）kubectl edit cm argocd-cm -n argocd新增以下内容：data: url: https://argocd.blazehu.com # 对外访问地址 dex.config: | connectors: - type: gitlab id: gitlab name: GitLab config: baseURL: https://gitlab.example.com # 自建 GitLab 填域名 clientID: XXXX... clientSecret: XXXX... redirectURI: https://argocd.blazehu.com/api/dex/callback url: https://argocd.blazehu.com users.anonymous.enabled: \"false\"如果登录提示：Failed to query provider “https://argocd.blazehu.com/api/dex “: Get “https://argocd-dex-server:5556/api/dex/.well-known/openid-configuration&quot;: http: server gave HTTP response to HTTPS client。这是由于协议对不上，首先检查证书是否合法，另外检查 argocd-cmd-params-cm 配置文件的 dex server 相关参数。5. RBAC：GitLab Group 映射成角色编辑 argocd-rbac-cm：data: policy.default: role:readonly policy.csv: | p, role:devops, applications, *, */*, allow p, role:devops, clusters, get, *, allow g, devops, role:devops6. 重启与验证kubectl rollout restart deployment/argocd-dex-server -n argocd重启后点击快速登录：7. 参考https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#ssohttps://dexidp.io/docs/connectors/gitlab/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"dex","slug":"dex","permalink":"https://blazehu.github.io/tags/dex/"},{"name":"gitlab","slug":"gitlab","permalink":"https://blazehu.github.io/tags/gitlab/"}]},{"title":"Argo Rollout 金丝雀发布实践","slug":"cloudnative/argo_rollout_practices","date":"2025-05-13T16:00:00.000Z","updated":"2025-11-13T03:52:18.353Z","comments":true,"path":"2025/05/14/cloudnative/argo_rollout_practices/","link":"","permalink":"https://blazehu.github.io/2025/05/14/cloudnative/argo_rollout_practices/","excerpt":"Argo Rollout 是 Kubernetes 生态中的渐进式交付工具之一，它提供了金丝雀发布、蓝绿部署等多种部署策略。本文将基于实际项目经验，介绍如何使用 Argo Rollout 实现金丝雀发布。","text":"Argo Rollout 是 Kubernetes 生态中的渐进式交付工具之一，它提供了金丝雀发布、蓝绿部署等多种部署策略。本文将基于实际项目经验，介绍如何使用 Argo Rollout 实现金丝雀发布。1. 概述Argo Rollout 是 Argo 项目的一部分，专门用于 Kubernetes 应用的渐进式交付。它支持多种部署策略，包括：金丝雀发布（Canary）：逐步将流量从旧版本转移到新版本蓝绿部署（Blue-Green）：同时运行两个版本，快速切换A/B 测试：基于用户特征进行流量分割本文重点介绍金丝雀发布策略，并结合 Istio 和 Nginx Ingress 两种流量管理方式，展示完整的配置。2. 整体架构根据Argo Rollouts官方架构文档，Argo Rollouts由以下核心组件构成：2.1 组件详解Argo Rollouts Controller监控集群中的Rollout资源变化读取Rollout定义并确保集群状态与定义一致不会干扰普通的Deployment资源Rollout Resource自定义Kubernetes资源，与原生Deployment兼容包含额外的字段控制金丝雀和蓝绿部署的阶段、阈值和方法需要将Deployment迁移为Rollout才能被Argo Rollouts管理Replica Sets标准Kubernetes ReplicaSet资源实例Argo Rollouts添加额外元数据来跟踪不同版本完全由控制器自动管理，不应手动干预Ingress/Service流量从用户进入集群并重定向到适当版本的机制支持多个服务：仅新版本、仅旧版本或两者兼有支持多种服务网格和Ingress解决方案进行流量分割AnalysisTemplate 和 AnalysisRun连接Rollout到指标提供者的能力定义特定指标的阈值来决定更新是否成功支持自动推进、回滚或暂停Rollout2.3 金丝雀发布流程创建 Rollout 资源：定义部署策略和步骤流量分割：通过 Istio 或 Nginx Ingress 控制流量分配渐进式发布：按照预定义步骤逐步增加新版本流量自动分析：基于指标自动判断是否继续或回滚自动回滚：基于指标自动回滚到稳定版本3. 配置实践本文基于一个Helm Chart例子，展示了如何将Argo Rollout集成到部署流程中。3.1 项目结构argocd-demo/├── charts/│ └── rollout/ # 统一的rollout Chart│ ├── templates/│ │ ├── _helpers.tpl # 模板辅助函数│ │ ├── app/ # 应用相关资源│ │ │ ├── deployment.yaml│ │ │ ├── rollout.yaml # Argo Rollout配置│ │ │ └── registry-secret.yaml│ │ └── traffic/ # 流量管理资源│ │ ├── tls-secret.yaml│ │ ├── istio/│ │ │ ├── gateway.yaml│ │ │ ├── services.yaml│ │ │ └── virtualservice.yaml│ │ ├── nginx-ingress/│ │ │ ├── ingress.yaml│ │ │ └── services.yaml│ │ └── service/│ │ └── loadbalancer.yaml│ └── values.yaml└── values.yaml3.2 Rollout 资源定义基于我们的Helm模板，Rollout资源支持动态配置：&#123;&#123;- if .Values.enabled &#125;&#125;apiVersion: argoproj.io/v1alpha1kind: Rolloutmetadata: name: &#123;&#123; include \"rollout.fullname\" . &#125;&#125; namespace: &#123;&#123; .Release.Namespace &#125;&#125; labels:&#123;&#123;- include \"rollout.labels\" . | nindent 4 &#125;&#125;spec: replicas: &#123;&#123; .Values.replicaCount &#125;&#125; strategy: canary: &#123;&#123;- if .Values.traffic.nginxIngress.enabled &#125;&#125; canaryService: &#123;&#123; include \"rollout.canaryServiceName\" . &#125;&#125; stableService: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; trafficRouting: nginx: stableIngress: &#123;&#123; include \"rollout.nginxIngressName\" . &#125;&#125; additionalIngressAnnotations: canary-by-header: \"X-Canary\" canary-by-header-value: \"true\" &#123;&#123;- end &#125;&#125; &#123;&#123;- if .Values.traffic.istio.enabled &#125;&#125; canaryService: &#123;&#123; include \"rollout.canaryServiceName\" . &#125;&#125; stableService: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; trafficRouting: istio: virtualService: name: &#123;&#123; include \"rollout.virtualServiceName\" . &#125;&#125; routes: - primary &#123;&#123;- end &#125;&#125; steps: - setWeight: 20 - pause: &#123;&#125; &#123;&#123;- if or .Values.traffic.nginxIngress.enabled .Values.traffic.istio.enabled &#125;&#125; - setCanaryScale: weight: 50 - pause: &#123;&#125; - setWeight: 50 - pause: &#123;&#125; - setCanaryScale: matchTrafficWeight: true - pause: &#123;&#125; &#123;&#123;- end &#125;&#125; revisionHistoryLimit: 3 selector: matchLabels:&#123;&#123;- include \"rollout.selectorLabels\" . | nindent 6 &#125;&#125; workloadRef: apiVersion: apps/v1 kind: Deployment name: &#123;&#123; include \"rollout.fullname\" . &#125;&#125;&#123;&#123;- end &#125;&#125;3.3 配置管理values.yaml 配置示例：rollout: enabled: true image: registry.example.com/demo/app imageTag: v1 replicaCount: 3 # 应用名称配置 nameOverride: \"\" fullnameOverride: \"\" app: name: \"demo-app\" secrets: registry: enabled: true name: registry-secret # 流量管理配置 traffic: # Istio 流量管理 istio: enabled: false host: demo-app.example.com port: 8080 gateway: name: common-inbound-gateway tlsName: tls-secret tlsNamespace: istio-system # Nginx Ingress 流量管理 nginxIngress: enabled: false host: demo-app.example.com port: 8080 tlsName: tls-secret tlsNamespace: \"\" # 使用 release namespace # 4层 Service 流量管理 service: enabled: false port: 8080 lbId: lb-xxxxxxxxxxxxxxxxx3.4 流量管理配置基于我们的Helm模板，支持三种流量管理方式：Istio、Nginx Ingress和4层Service。Kubernetes Ingress 支持指定 TLS 设置。 Istio 支持此功能，但是引用的 Secret 必须存在于 istio-ingressgateway 部署的命名空间（通常是 istio-system）中。3.4.1 Istio 流量管理VirtualService 配置：&#123;&#123;- if and .Values.enabled .Values.traffic.istio.enabled &#125;&#125;apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: &#123;&#123; include \"rollout.virtualServiceName\" . &#125;&#125; namespace: &#123;&#123; .Release.Namespace &#125;&#125; labels:&#123;&#123;- include \"rollout.labels\" . | nindent 4 &#125;&#125; component: virtualservicespec: gateways: - &#123;&#123; .Values.traffic.istio.gateway.name &#125;&#125; hosts: - &#123;&#123; .Values.traffic.istio.host &#125;&#125; http: - match: - headers: X-Canary: exact: 'true' name: canary route: - destination: host: &#123;&#123; include \"rollout.canaryServiceName\" . &#125;&#125; port: number: &#123;&#123; .Values.traffic.istio.port &#125;&#125; weight: 100 - match: - headers: X-Canary: exact: 'false' name: stable route: - destination: host: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; port: number: &#123;&#123; .Values.traffic.istio.port &#125;&#125; weight: 100 - name: primary route: - destination: host: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; port: number: &#123;&#123; .Values.traffic.istio.port &#125;&#125; headers: request: set: X-Canary: 'false' weight: 100 - destination: host: &#123;&#123; include \"rollout.canaryServiceName\" . &#125;&#125; port: number: &#123;&#123; .Values.traffic.istio.port &#125;&#125; headers: request: set: X-Canary: 'true' weight: 0&#123;&#123;- end &#125;&#125;3.4.2 Nginx Ingress 流量管理Ingress 配置：&#123;&#123;- if and .Values.enabled .Values.traffic.nginxIngress.enabled &#125;&#125;apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: &#123;&#123; include \"rollout.nginxIngressName\" . &#125;&#125; namespace: &#123;&#123; .Release.Namespace &#125;&#125; labels:&#123;&#123;- include \"rollout.labels\" . | nindent 4 &#125;&#125; component: ingressspec: ingressClassName: nginx tls: - hosts: - &#123;&#123; .Values.traffic.nginxIngress.host &#125;&#125; secretName: &#123;&#123; .Values.traffic.nginxIngress.tlsName &#125;&#125; rules: - host: &#123;&#123; .Values.traffic.nginxIngress.host &#125;&#125; http: paths: - backend: service: name: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; port: number: &#123;&#123; .Values.traffic.nginxIngress.port &#125;&#125; path: / pathType: Prefix&#123;&#123;- end &#125;&#125;3.4.3 服务配置&#123;&#123;- if and .Values.enabled .Values.traffic.istio.enabled &#125;&#125;apiVersion: v1kind: Servicemetadata: name: &#123;&#123; include \"rollout.canaryServiceName\" . &#125;&#125; namespace: &#123;&#123; .Release.Namespace &#125;&#125; labels:&#123;&#123;- include \"rollout.labels\" . | nindent 4 &#125;&#125; component: canaryspec: ports: - port: &#123;&#123; .Values.traffic.istio.port &#125;&#125; targetPort: http protocol: TCP name: http selector:&#123;&#123;- include \"rollout.selectorLabels\" . | nindent 4 &#125;&#125;---apiVersion: v1kind: Servicemetadata: name: &#123;&#123; include \"rollout.stableServiceName\" . &#125;&#125; namespace: &#123;&#123; .Release.Namespace &#125;&#125; labels:&#123;&#123;- include \"rollout.labels\" . | nindent 4 &#125;&#125; component: stablespec: ports: - port: &#123;&#123; .Values.traffic.istio.port &#125;&#125; targetPort: http protocol: TCP name: http selector:&#123;&#123;- include \"rollout.selectorLabels\" . | nindent 4 &#125;&#125;&#123;&#123;- end &#125;&#125;3.5 模板辅助函数我们的Helm Chart使用_helpers.tpl来统一管理命名规则：&#123;&#123;/*Canary Service Name*/&#125;&#125;&#123;&#123;- define \"rollout.canaryServiceName\" -&#125;&#125;&#123;&#123;- printf \"%s-canary\" (include \"rollout.appName\" .) -&#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;/*Stable Service Name*/&#125;&#125;&#123;&#123;- define \"rollout.stableServiceName\" -&#125;&#125;&#123;&#123;- printf \"%s-stable\" (include \"rollout.appName\" .) -&#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;/*Virtual Service Name*/&#125;&#125;&#123;&#123;- define \"rollout.virtualServiceName\" -&#125;&#125;&#123;&#123;- printf \"%s-vs\" (include \"rollout.appName\" .) -&#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;/*Application Name*/&#125;&#125;&#123;&#123;- define \"rollout.appName\" -&#125;&#125;&#123;&#123;- .Values.app.name -&#125;&#125;&#123;&#123;- end -&#125;&#125;4. 基于Helm的部署实践4.1 环境准备安装Argo Rollouts：# 安装Argo Rollouts Controllerkubectl create namespace argo-rolloutskubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml# 安装Argo Rollouts CLIcurl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64chmod +x ./kubectl-argo-rollouts-linux-amd64sudo mv ./kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts4.2 Helm部署流程使用Helm部署或者结合ArgoCD部署，下列步骤是Helm部署和验证流程。步骤一：使用Helm部署部署Istio模式：# 使用Helm部署Istio模式的金丝雀发布helm install demo-app . \\ --namespace demo \\ --create-namespace \\ --set rollout.enabled=true \\ --set rollout.traffic.istio.enabled=true \\ --set rollout.traffic.nginxIngress.enabled=false \\ --set rollout.traffic.service.enabled=false \\ --set rollout.app.name=demo-app \\ --set rollout.traffic.istio.host=demo-app.example.com部署Nginx Ingress模式：# 使用Helm部署Nginx Ingress模式的金丝雀发布helm install demo-app . \\ --namespace demo \\ --create-namespace \\ --set rollout.enabled=true \\ --set rollout.traffic.istio.enabled=false \\ --set rollout.traffic.nginxIngress.enabled=true \\ --set rollout.traffic.service.enabled=false \\ --set rollout.app.name=demo-app \\ --set rollout.traffic.nginxIngress.host=demo-app.example.com步骤二：验证部署状态# 查看Rollout状态kubectl get rollout -n demo# 查看Pod状态kubectl get pods -n demo -l app=demo-app# 查看服务状态kubectl get svc -n demo -l app=demo-app# 查看流量管理资源kubectl get virtualservice -n demo # Istio模式kubectl get ingress -n demo # Nginx模式步骤三：触发金丝雀发布# 方法1：通过Helm更新镜像版本helm upgrade demo-app . \\ --namespace demo \\ --set rollout.imageTag=v2# 方法2：直接更新Rollout资源kubectl patch rollout demo-app-rollout -n demo \\ --type='merge' -p='&#123;\"spec\":&#123;\"template\":&#123;\"spec\":&#123;\"containers\":[&#123;\"name\":\"demo-app\",\"image\":\"registry.example.com/demo/app:v2\"&#125;]&#125;&#125;&#125;&#125;'步骤四：监控发布进度# 查看Rollout详细状态kubectl describe rollout demo-app-rollout -n demo# 使用Argo Rollouts CLI查看发布历史kubectl argo rollouts get rollout demo-app-rollout -n demo# 查看流量分配（Istio模式）kubectl get virtualservice demo-app-vs -n demo -o yaml# 查看Ingress配置（Nginx模式）kubectl get ingress demo-app-stable -n demo -o yaml步骤五：手动控制发布# 推进到下一步kubectl argo rollouts promote demo-app-rollout -n demo# 暂停发布kubectl argo rollouts pause demo-app-rollout -n demo# 恢复发布kubectl argo rollouts resume demo-app-rollout -n demo# 回滚到稳定版本kubectl argo rollouts abort demo-app-rollout -n demo4.3 ArgoCD部署如果使用ArgoCD，灰度发布中流量拓扑图如下：Nginx Ingress 流量管理灰度前灰度中灰度结束Istio 流量管理灰度前灰度中灰度结束4.4 流量测试测试稳定版本# 不带特殊头部的请求（默认走稳定版本）curl http://demo-app.example.com/api/health# 明确指定稳定版本curl http://demo-app.example.com/api/health \\ -H \"X-Canary: false\"测试金丝雀版本# 明确指定金丝雀版本curl http://demo-app.example.com/api/health \\ -H \"X-Canary: true\"验证流量分配# 连续发送请求，观察流量分配for i in &#123;1..10&#125;; do curl -s http://demo-app.example.com/api/health; sleep 1; done5. 高级特性5.1 自动分析Argo Rollouts支持通过AnalysisTemplate和AnalysisRun实现自动化的指标分析，这是实现智能金丝雀发布的关键特性。AnalysisTemplate 定义：apiVersion: argoproj.io/v1alpha1kind: AnalysisTemplatemetadata: name: success-rate namespace: demospec: metrics: - name: success-rate interval: 30s successCondition: result[0] &gt;= 0.95 failureCondition: result[0] &lt; 0.90 provider: prometheus: address: http://prometheus:9090 query: | sum(rate(http_requests_total&#123;job=\"&#123;&#123;args.service-name&#125;&#125;\",status!~\"5..\"&#125;[5m])) / sum(rate(http_requests_total&#123;job=\"&#123;&#123;args.service-name&#125;&#125;\"&#125;[5m]))Rollout 中的分析配置：spec: strategy: canary: analysis: templates: - templateName: success-rate args: - name: service-name value: demo-app-stable - name: service-name-canary value: demo-app-canary steps: - setWeight: 20 - pause: &#123;duration: 10m&#125; - analysis: templates: - templateName: success-rate args: - name: service-name value: demo-app-stable - name: service-name-canary value: demo-app-canary5.2 渐进式发布spec: strategy: canary: steps: - setWeight: 10 - pause: &#123;duration: 5m&#125; - setWeight: 20 - pause: &#123;duration: 5m&#125; - setWeight: 40 - pause: &#123;duration: 5m&#125; - setWeight: 60 - pause: &#123;duration: 5m&#125; - setWeight: 80 - pause: &#123;duration: 5m&#125; - setWeight: 1005.3 自动回滚spec: strategy: canary: rollbackWindow: deployments: 5 replicas: 5 analysis: templates: - templateName: error-rate args: - name: service-name value: demo-app-stable - name: service-name-canary value: demo-app-canary6. 参考Argo Rollouts 官方文档Argo Rollouts 架构文档Istio 流量管理Nginx Ingress 金丝雀发布","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"rollout","slug":"rollout","permalink":"https://blazehu.github.io/tags/rollout/"},{"name":"canary","slug":"canary","permalink":"https://blazehu.github.io/tags/canary/"}]},{"title":"ArgoCD 扩展：实现 Pod 离群","slug":"cloudnative/argocd_outofcluster","date":"2025-04-20T16:00:00.000Z","updated":"2025-08-15T04:03:58.027Z","comments":true,"path":"2025/04/21/cloudnative/argocd_outofcluster/","link":"","permalink":"https://blazehu.github.io/2025/04/21/cloudnative/argocd_outofcluster/","excerpt":"线上异常 Pod 既要留现场，又得立刻摘流量，还要在 ArgoCD 资源拓扑图里一眼被看到。本文会介绍如何让 Pod 秒“离群”，既摘流量与同步循环，又在拓扑图高亮标注。","text":"线上异常 Pod 既要留现场，又得立刻摘流量，还要在 ArgoCD 资源拓扑图里一眼被看到。本文会介绍如何让 Pod 秒“离群”，既摘流量与同步循环，又在拓扑图高亮标注。1. 背景排查线上问题时，我们既想保留现场，又要快速恢复服务，不想让异常的 Pod 被 ArgoCD 自动回收。只需贴上两行标签和注解，就能让异常 Pod 立刻从 Service Endpoints 下线并被 ArgoCD 标为“离群”，现场保留、流量无损，排障后删除即可秒级复原。2. 原理把 Pod 的 Service selector 标签（如 app=xxx）摘掉，再给它打上 ArgoCD 「忽略差异」和「禁止回收」的注解，ArgoCD 就会把它标成“离群 Pod”而不参与同步。步骤如下：步骤目的命令1下线流量kubectl label pod app-xxx-abcde app-2脱离控制器kubectl label pod app-xxx-abcde pod-template-hash-3忽略差异kubectl annotate pod app-xxx-abcde argocd.argoproj.io/compare-options=IgnoreExtraneous4禁止回收kubectl annotate pod app-xxx-abcde argocd.argoproj.io/sync-options=Prune=false5不影响拓扑图展示kubectl label pod app-xxx-abcde argocd.argoproj.io/instance=your-app-name3. 实现效果前端实现参考：AntV G6 实现 k8s 资源拓扑图展示4. 总结优势说明零配置修改无需改 Git 仓库，不触发同步秒级生效纯标签/注解操作，1 秒完风险可控离群 Pod 不参与流量，随时删可视化ArgoCD UI 高亮提示，一眼识别下次线上再出 Bug，不妨先“离群”再排查！5. 参考资料https://argo-cd.readthedocs.io/en/stable/user-guide/compare-options/https://argo-cd.readthedocs.io/en/stable/user-guide/sync-options/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"}]},{"title":"快速搭建FTP服务","slug":"ops/linux/vsftpd","date":"2024-10-24T16:00:00.000Z","updated":"2025-11-04T13:09:28.849Z","comments":true,"path":"2024/10/25/ops/linux/vsftpd/","link":"","permalink":"https://blazehu.github.io/2024/10/25/ops/linux/vsftpd/","excerpt":"10 分钟搭好 FTP：装包、添用户、拷脚本、开防火墙，本地验证登录。","text":"10 分钟搭好 FTP：装包、添用户、拷脚本、开防火墙，本地验证登录。1. 安装 vsftpdsudo yum -y install vsftpd # CentOS 7/8# Ubuntu/Debian 用 sudo apt -y install vsftpd2. 建系统用户sudo adduser blazehusudo passwd blazehu3. 目录准备sudo mkdir -p /data/clientsudo chown -R blazehu:blazehu /data/clientsudo chmod 755 /data/client4. 配置 vsftpdsudo mv /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.baksudo tee /etc/vsftpd/vsftpd.conf &gt;/dev/null &lt;&lt;'EOF'#==========================================# vsftpd 最小可用模板（系统账号 + 被动模式）# 适用：CentOS 7/8 | Rocky | Alma | RHEL#==========================================# 关闭匿名登录anonymous_enable=NO# 允许系统账号登录local_enable=YES# 上传/删除/重命名总开关write_enable=YES# 新建文件 644，目录 755local_umask=022# 进入目录时显示 .message 文件（如有）dirmessage_enable=YES# 记录上传/下载日志xferlog_enable=YES# 使用标准 xferlog 格式xferlog_std_format=YES# PORT 模式数据端口 20connect_from_port_20=YES# 独立守护进程（IPv4）listen=YES# 使用 /etc/pam.d/vsftpd 认证pam_service_name=vsftpd# 启用白名单userlist_enable=YES# NO=仅允许 user_list 内用户登录userlist_deny=NO# 支持 /etc/hosts.allow|deny 访问控制tcp_wrappers=YES# 强制登录后落在 /data/client，不再进系统家目录local_root=/data/client# 所有用户被锁在家目录chroot_local_user=YES# 家目录可写时也接受（必加，否则 530）allow_writeable_chroot=YES# 启用“例外名单”chroot_list_enable=YES# 文件内用户不被禁锢（留空=全员禁锢）chroot_list_file=/etc/vsftpd/chroot_list# 开启被动模式pasv_enable=YES# 数据端口下限pasv_min_port=20000# 数据端口上限（共 11 个端口够用）pasv_max_port=20010EOF5. 白名单 &amp; 空例外文件echo blazehu &gt; /etc/vsftpd/user_listsudo touch /etc/vsftpd/chroot_list # 留空 = 全部用户都被 chroot6. 防火墙sudo firewall-cmd --permanent --add-service=ftp # 放行 21sudo firewall-cmd --permanent --add-port=20000-20010/tcp # 被动端口段sudo firewall-cmd --reload7. 重载sudo systemctl restart vsftpdsystemctl status vsftpd8. 验证[blazehu@centos7 ~]$ ftp 127.0.0.1Connected to 127.0.0.1 (127.0.0.1).220 (vsFTPd 3.0.2)Name (127.0.0.1:blazehu): blazehu331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.9.匿名下载后续如果希望开启匿名下载需要添加以下配置：#======== 匿名只读下载（与系统用户同目录） ========anonymous_enable=YESno_anon_password=YESanon_world_readable_only=NO# 把匿名根目录强行指到系统用户目录anon_root=/data/client# 以下两行显式关闭匿名写权限，覆盖全局 write_enable=YESanon_upload_enable=NOanon_mkdir_write_enable=NO更新名单：echo ftp &gt;&gt; /etc/vsftpd/user_listecho ftp &gt;&gt; /etc/vsftpd/chroot_list# 同时兼容 macOS 的 anonymousecho anonymous &gt;&gt; /etc/vsftpd/user_listecho anonymous &gt;&gt; /etc/vsftpd/chroot_list","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"ftp","slug":"ftp","permalink":"https://blazehu.github.io/tags/ftp/"}]},{"title":"快速安装 Istio 1.22.3 简记","slug":"cloudnative/istio_install","date":"2024-09-21T16:00:00.000Z","updated":"2025-11-05T07:33:33.046Z","comments":true,"path":"2024/09/22/cloudnative/istio_install/","link":"","permalink":"https://blazehu.github.io/2024/09/22/cloudnative/istio_install/","excerpt":"本文记录用 demo 配置 + DaoCloud 镜像 + 阿里云 SLB 一键安装 Istio 1.22.3，并部署示例应用与插件。","text":"本文记录用 demo 配置 + DaoCloud 镜像 + 阿里云 SLB 一键安装 Istio 1.22.3，并部署示例应用与插件。1. 下载 Istio参考官方文档下载对应版本的安装文件。我这里下载的是1.22.3版本。blaze@MACBOOK ~ % istioctl versionclient version: 1.22.3control plane version: 1.22.3data plane version: 1.22.3 (4 proxies)2. 安装 Istio一键安装（demo profile + DaoCloud 镜像 + 指定 SLB）# 安装 Istioistioctl install \\ --set hub=docker.m.daocloud.io/istio \\ --set tag=1.22.3 \\ --set profile=demo \\ --set values.gateways.istio-ingressgateway.serviceAnnotations.'service\\.beta\\.kubernetes\\.io/alibaba-cloud-loadbalancer-id'=\"lb-xxxxxxxxxxxxxxxxxxxxx\" \\ --set values.gateways.istio-ingressgateway.serviceAnnotations.'service\\.beta\\.kubernetes\\.io/alibaba-cloud-loadbalancer-force-override-listeners'=\"true\" \\ --set values.gateways.istio-ingressgateway.serviceAnnotations.'service\\.beta\\.kubernetes\\.io/alibaba-cloud-loadbalancer-address-type'=\"intranet\" \\ --set values.gateways.istio-ingressgateway.serviceAnnotations.'service\\.beta\\.kubernetes\\.io/alibaba-cloud-loadbalancer-ip-version'=\"ipv4\" \\ -y# 可选：安装 Kubernetes Gateway API CRDkubectl get crd gateways.gateway.networking.k8s.io &amp;&gt; /dev/null || \\&#123; kubectl kustomize \"github.com/kubernetes-sigs/gateway-api/config/crd?ref=v0.6.0\" | kubectl apply -f -; &#125;3. 部署示例应用参考官方文档部署一个简单的服务。# 部署一个简单的服务blaze@MACBOOK ~ % k get po -n blazehuNAME READY STATUS RESTARTS AGErollout-demo1-64bdbc558c-flvtf 1/1 Running 0 29srollout-demo1-64bdbc558c-gt26s 1/1 Running 0 29srollout-demo1-64bdbc558c-kd7n4 1/1 Running 0 29s# 给命名空间添加标签，指示 Istio 在部署应用的时候，自动注入 Envoy Sidecar 代理blaze@MACBOOK ~ % kubectl label namespace blazehu istio-injection=enablednamespace/blazehu labeled# 查看 Envoy Sidecar 注入完毕blaze@MACBOOK ~ % k get po -n blazehuNAME READY STATUS RESTARTS AGErollout-demo1-64bdbc558c-5789g 2/2 Running 0 3m46srollout-demo1-64bdbc558c-8vp8s 2/2 Running 0 3m46srollout-demo1-64bdbc558c-ncwzl 2/2 Running 0 3m46s4. 安装插件安装Kiali 和其他插件。# 可选：安装全部插件kubectl apply -f samples/addons# 安装 kiali 插件，并访问 Kiali 仪表板kubectl apply -f samples/addons/kiali.yamlkubectl apply -f samples/addons/prometheus.yamlistioctl dashboard kiali5. 卸载 Istio卸载 Istio（防止 webhook/CRD 残留）# 删除所有插件kubectl delete -f samples/addons# 删除 Istio 控制平面 + CRD + 所有资源 istioctl uninstall --purge -y# 可选：删除命名空间kubectl delete namespace istio-system# 可选：清理可能残留的 webhook（保险动作）kubectl delete mutatingwebhookconfiguration istio-revision-tag-default --ignore-not-foundkubectl delete validatingwebhookconfiguration istiod-istio-system --ignore-not-found","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"istio","slug":"istio","permalink":"https://blazehu.github.io/tags/istio/"}]},{"title":"基于 Istio 实现服务的泳道发布","slug":"cloudnative/lanes","date":"2024-08-30T16:00:00.000Z","updated":"2025-08-21T04:16:05.204Z","comments":true,"path":"2024/08/31/cloudnative/lanes/","link":"","permalink":"https://blazehu.github.io/2024/08/31/cloudnative/lanes/","excerpt":"基于 Istio 的泳道发布，让多条需求在同一套共享测试环境里并行测试互不干扰，既省资源又提效。","text":"基于 Istio 的泳道发布，让多条需求在同一套共享测试环境里并行测试互不干扰，既省资源又提效。1. 背景随着公司业务规模迅速扩张，同一微服务往往需要并行承载多个功能需求的同时开发与测试。当前一套测试环境出现了分支抢占、配置串扰、缓存冲突等问题，导致整体交付效率下滑。2. 什么是泳道泳道可以理解为多个并行隔离的调用链，调用互不干扰，类似泳池中的泳道。其中一条基线泳道作为主干道常备所有服务的默认实例，其他泳道的缺失服务会自动回退到这条基线泳道。使用流量泳道实现应用版本隔离，将链路透传请求头指定为引流请求头，使用链路透传请求头的内容向不同泳道引流。泳道中服务相互调用时，若目标服务不存在当前泳道则转发至基线泳道，保障链路完整性，简化流量管理。如下图：图中基于 svcA、svcB、svcC 构建 v1、v2、v3 三条泳道，分别对应服务调用链的三个版本。其中 v1 为基线泳道，包含完整的三个服务，v2 仅包含 svcA、svcC 两个服务，v3 仅包含 svcB 一个服务。同时，链路透传请求头与引流请求头都指定为 X-Lane。3. 方案探索以下资源的 YAML 按流量进入集群→路由→后端实例的顺序编排，依次对应泳道发布的 5 个关键环节。3.1 Gateway作用：定义统一入口，声明域名、端口及 TLS 终止方式，让外部流量能够打到集群内部。apiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata: name: common-inbound-gateway namespace: devopsspec: selector: istio: ingressgateway servers: - hosts: - '*' port: name: http number: 80 protocol: HTTP - hosts: - '*' port: name: https number: 443 protocol: HTTPS tls: credentialName: blazehu.com mode: SIMPLE3.2 VirtualService作用：定义基于 HTTP 头部信息的路由规则，包括基线泳道。按 HTTP 头 X-Lane 的值把请求精准地导到 v1/v2/v3 三个泳道；若无该头，则默认落到基线泳道 v1。apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata: name: argocd-demo-vs namespace: devopsspec: gateways: - common-inbound-gateway hosts: - argocd-demo.blazehu.com http: - match: # 定义基于 header 的路由规则 - headers: X-Lane: exact: v2 name: v2 route: - destination: host: argocd-demo-lanes port: number: 7777 subset: v2 - match: - headers: X-Lane: exact: v3 name: v3 route: - destination: host: argocd-demo-lanes port: number: 7777 subset: v3 - name: v1 # 基线泳道 v1，没有 match 条件，作为默认路由 route: - destination: host: argocd-demo-lanes port: number: 7777 subset: v13.3 DestinationRule作用：定义服务的子集和选择器，即给每个泳道打“版本标签”，让 VirtualService 在路由时能准确找到后端实例；同时定义负载均衡策略。apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata: name: argocd-demo-dr namespace: devopsspec: host: argocd-demo-lanes subsets: - labels: app: argocd-demo version: v1 name: v1 - labels: app: argocd-demo version: v2 name: v2 - labels: app: argocd-demo version: v3 name: v33.4 Service作用：把标有 app: argocd-demo 的 Pod 暴露为 argocd-demo-lanes:7777，供 VS/DR 路由。apiVersion: v1kind: Servicemetadata: name: argocd-demo-lanes namespace: devopsspec: ports: - name: http port: 7777 protocol: TCP targetPort: http selector: app: argocd-demo3.5. Deployment作用：定义工作负载，每个工作负载具有不同的标签。通过 version 标签把镜像 v1/v2/v3 部署成三套独立实例，对应三条泳道；缺失组件会自动回退到基线 v1，实现“按需部署”。# v1（基线）apiVersion: apps/v1kind: Deploymentmetadata: name: argocd-demo-v1 namespace: devopsspec: replicas: 1 selector: matchLabels: app: argocd-demo version: v1 template: metadata: labels: app: argocd-demo sidecar.istio.io/inject: 'true' version: v1 spec: containers: - image: 'xxx/blazehu-demo:v1' imagePullPolicy: Always name: argocd-demo ports: - containerPort: 8080 name: http protocol: TCP---# v2（仅改 version 与镜像）apiVersion: apps/v1kind: Deploymentmetadata: name: argocd-demo-v2 namespace: devopsspec: replicas: 1 selector: matchLabels: app: argocd-demo version: v2 template: metadata: labels: app: argocd-demo sidecar.istio.io/inject: 'true' version: v2 spec: containers: - image: 'xxx/blazehu-demo:v2' imagePullPolicy: Always name: argocd-demo ports: - containerPort: 8080 name: http protocol: TCP---# v3（仅改 version 与镜像）apiVersion: apps/v1kind: Deploymentmetadata: name: argocd-demo-v3 namespace: devopsspec: replicas: 1 selector: matchLabels: app: argocd-demo version: v3 template: metadata: labels: app: argocd-demo sidecar.istio.io/inject: 'true' version: v3 spec: containers: - image: 'xxx/blazehu-demo:v3' imagePullPolicy: Always name: argocd-demo ports: - containerPort: 8080 name: http protocol: TCP通过 Gateway 入口、VirtualService 路由规则、DestinationRule 后端分组的组合，再辅以按版本标签区分的 Deployment。3.6. 测试验证本地配置 hosts即可访问测试（修改 etc/hosts）：blazehu@MACBOOK ~ % curl http://argocd-demo.blazehu.com/api/check&#123;\"message\":\"v1\"&#125; blazehu@MACBOOK ~ % curl http://argocd-demo.blazehu.com/api/check -H \"X-Lane: v1\"&#123;\"message\":\"v1\"&#125; blazehu@MACBOOK ~ % curl http://argocd-demo.blazehu.com/api/check -H \"X-Lane: v2\"&#123;\"message\":\"v2\"&#125; blazehu@MACBOOK ~ % curl http://argocd-demo.blazehu.com/api/check -H \"X-Lane: v3\"&#123;\"message\":\"v3\"&#125;3.7 响应头添加泳道信息为了确保前后端泳道信息的一致性和可追踪性，并使前端能够识别请求所属的泳道，我们可以在响应中添加泳道的header头。仅当泳道有效时，才将其添加至响应头，以避免向前端传递无效或错误的泳道信息。这样，前端可以通过浏览器插件自动设置请求头，实现泳道信息的准确传递和验证。方案一：VirtualServicehttp: - match: - headers: X-Lane: exact: 'v2' name: v2 route: - destination: host: argocd-demo-lanes subset: v2 port: number: 7777 headers: response: add: X-Lane: \"v2\" # 将请求头 x-lane 传递到响应头方案二：EnvoyFilterapiVersion: networking.istio.io/v1alpha3kind: EnvoyFiltermetadata: name: lane-response-header namespace: devops spec: configPatches: - applyTo: HTTP_FILTER match: context: SIDECAR_INBOUND patch: operation: INSERT_BEFORE value: name: envoy.filters.http.lua typed_config: '@type': type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua inlineCode: | function envoy_on_request(request_handle) local headers = request_handle:headers() local lane = headers:get(\"x-lane\") or \"nil\" request_handle:logWarn(\"== envoy_on_request X-Lane: \" .. lane) request_handle:streamInfo():dynamicMetadata():set(\"envoy.filters.http.lua\", \"lane\", lane) end function envoy_on_response(response_handle) local headers = response_handle:headers() response_handle:logWarn(\"start add headers\") local metadata = response_handle:streamInfo():dynamicMetadata():get(\"envoy.filters.http.lua\") local lane = metadata and metadata[\"lane\"] or \"nil\" if lane == \"nil\" then response_handle:logWarn(\"X-Lane header not found in request\") else headers:add(\"x-lane\", lane) response_handle:logWarn(\"set x-lane, lane:\".. lane) end end workloadSelector: labels: app: argocd-demo两种方案均可，方案一通过 VirtualService 直接在路由层面处理请求和响应头，简单易用；方案二利用 EnvoyFilter 的 Lua 脚本在代理层面灵活操作请求和响应头，提供更高的灵活性和控制能力。4. 落地实践4.1. 模板渲染基础资源：在 base/ 目录下管理，包括 Gateway 和 Service 等基础资源。差异补丁：在 patch/ 目录下管理，包括 Deployment 和 VirtualService 的差异补丁。渲染管线：前端表单 → 后端生成全局唯一泳道名 → 模版渲染 → 推送到 Git → Argo CD 同步4.2. 元数据原理使用一个泳道 Lane CR（Custom Resource）或数据库作为唯一的数据来源。补充说明：我们可以通过 CR + Controller 的方式实现上述的模版渲染以及元数据管理。即将泳道定义为 XLane 类型的 CRD，并实现对应的 Controller 来管理要实现泳道功能的 Istio VirtualService 和 DestinationRule (实现路由功能) 和 K8S deployment (实现部署功能)。4.3. 功能清单创建：选应用 → 选分支（版本） → 填写 TTL → 一键生成查看：列表展示泳道、剩余 TTL、Pod 数等更新：仅允许改镜像或副本数，提交后滚动升级删除：二次确认后软删除并级联回收资源清理：TTL 到期自动删除；可一键续期，最多续 3 次5. 参考https://help.aliyun.com/zh/asm/sidecar/flow-lane-overviewhttps://istio.io/latest/zh/docs/concepts/traffic-management","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"},{"name":"istio","slug":"istio","permalink":"https://blazehu.github.io/tags/istio/"}]},{"title":"蓝盾「Docker公共构建机」超时问题排查","slug":"devops/landun_clb","date":"2024-08-19T16:00:00.000Z","updated":"2025-07-30T02:25:19.025Z","comments":true,"path":"2024/08/20/devops/landun_clb/","link":"","permalink":"https://blazehu.github.io/2024/08/20/devops/landun_clb/","excerpt":"在使用蓝盾「Docker公共构建机」时，我们发现构建机偶尔无法就绪。排查后发现问题出在拉起的 Pod 在安装蓝盾 Agent 时卡住。经进一步分析，这是由于该 Pod 与 Nginx Ingress Pod 被调度到了同一节点，而同节点访问异常。","text":"在使用蓝盾「Docker公共构建机」时，我们发现构建机偶尔无法就绪。排查后发现问题出在拉起的 Pod 在安装蓝盾 Agent 时卡住。经进一步分析，这是由于该 Pod 与 Nginx Ingress Pod 被调度到了同一节点，而同节点访问异常。背景在阿里云ACK集群中，出现同节点访问异常的网络现象：场景流量路径结果同节点Pod → CLB VIP → 同节点 NodePort → 被 CLB 丢弃（回环限制）❌ 超时跨节点Pod → CLB VIP → 其他节点 NodePort → Ingress Pod✅ 正常跨节点访问正常：业务 Pod 与 Nginx Ingress Controller 部署在不同节点时，通过 CLB 访问服务完全正常。同节点访问超时：当业务 Pod 与 Ingress Controller 调度到同一节点时，TCP 连接超时：# 在Pod内测试curl http://devops.bk.xxx.xxx/static/local/files/docker_init.sh# 返回错误curl: (28) Failed to connect to devops.bk.xxx.xxx port 80: Connection timed out关键组件Kubernetes 1.20.11 + Terway网络插件（非ENITrunking模式）Nginx Ingress 0.44.0（externalTrafficPolicy: Local）CLB 类型：四层TCP监听（端口80）服务转发模式：IPVS排查过程基础检查网络连通性测试：# DNS解析正常ping devops.bk.xxx.xxx # 返回CLB VIP 10.200.x.x# TCP连接失败（同节点）telnet 10.200.x.x 80 # Connection timed out安全组验证：已确认放行VPC内网段（10.200.0.0/16, 100.100.0.0/16），排除ACL拦截。流量路径分析CLB后端健康状态：kubectl get endpoints -n kube-system nginx-ingress-controllerENDPOINTS: 10.212.x.x:80,10.212.x.x:443 # 正常Ingress Controller配置：externalTrafficPolicy: Local导致 CLB 只会将流量转发到有 Ingress Pod 的节点。节点网络抓包：在Ingress节点执行抓包后，发现 CLB 的请求包能到达节点，但未转发到 Ingress Pod。根因定位阿里云 CLB 对四层TCP监听器默认禁止回环流量（即后端服务器通过 CLB VIP访问自身服务），相关阿里云文档。解决方案当前使用修改CoreDNS配置的临时方案，其他方案待评估后实施。修改CoreDNS配置（临时）将相关域名解析到 Ingress Service 的内网IP（如ClusterIP），绕过 CLB。更新集群组件升级 Nginx Ingress ：使用新版本，已修复兼容性问题。升级 Terway 插件：使用最新版本，优化节点内流量路由。参考为什么无法访问负载均衡使用Terway网络插件CLB 回环问题","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"},{"name":"clb","slug":"clb","permalink":"https://blazehu.github.io/tags/clb/"}]},{"title":"蓝盾存储服务梳理和数据迁移(v7.1)","slug":"devops/landun_storage","date":"2024-06-03T16:00:00.000Z","updated":"2025-03-24T13:25:43.042Z","comments":true,"path":"2024/06/04/devops/landun_storage/","link":"","permalink":"https://blazehu.github.io/2024/06/04/devops/landun_storage/","excerpt":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文档旨在提供蓝鲸智云 7.1 版本蓝盾的存储服务梳理及数据迁移方案。","text":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文档旨在提供蓝鲸智云 7.1 版本蓝盾的存储服务梳理及数据迁移方案。1. 存储服务梳理存储服务CPU/内存/磁盘部署方式实际资源配置所需版本连接串配置mysql1C/2G/50Gi云服务2core4G 100G5.7.26 (utf8字符集)values文件中配置redis1C/1G/20Gi云服务2分片4G6.2.5-debian-10-r63redis-cluster-/-/20Gi云服务-6.2.6-debian-10-r178mongodb-/-/20Gi云服务4C8G4.4.xelastic2C/4G云服务2c4g 20GiB7.16.2-debian-10-r0rabbitmq-/-/20Gi自建3.8.21-debian-10-r0zookeeper-/-/20Gi自建bitnami/zookeeper:3.8.0-debian-10-r20etcd-/-/20Gi自建bitnami/etcd:3.5.4-debian-11-r31influxdb-/-/20Gi自建influxdb:1.8.6-alpine基础存储服务包含：mysql、redis、mongodb、rabbitmq、elastic、zookeeper、etcd。蓝盾存储服务包含：mysql、redis、mongodb、rabbitmq、elastic、influxdb。其中 mysql、redis、mongodb、rabbitmq、elastic 可以复用。2. 基础存储服务包含：mysql、redis、mongodb、rabbitmq、elastic、zookeeper、etcd。2.1 mysql镜像： hub.bktencent.com/bitnami/mysql:5.7.26resources: limits: cpu: \"1\" memory: 2Gi requests: cpu: 200m memory: 512Mimysql: # 处于同一集群可以使用k8s service 名 host: \"bk-mysql-mysql\" port: 3306 rootPassword: blueking # 默认平台和saas都复用该mysql示例时，请分配大一点的磁盘空间给数据盘。 size: 50Gi2.2 rabbitmqrabbitmq: host: \"bk-rabbitmq\" # AMQP协议端口 port: 5672 username: admin password: blueking erlangCookie: bluekingcookie size: 20Gi2.3 redisresources: limits: memory: 1024Mi cpu: 1000m requests: memory: 64Mi cpu: 100mredis: size: 20Gi host: bk-redis-master port: 6379 password: \"blueking\"2.4 redis-clusterredisCluster: persistence: size: 20Gi host: bk-redis-cluster port: 6379 password: \"blueking\"2.5 mongodbmongodb: host: bk-mongodb-headless port: 27017 host_port: bk-mongodb-headless:27017 rootUsername: root rootPassword: blueking rsName: rs0 # 以下变量对部署bitnamiMongodb生效，外部mongodb服务不需要 replicaCount: 1 replicaSetKey: xEfhjshh3APP0arf size: 20Gi2.6 elasticmaster: replicas: 1 heapSize: 512m resources: limits: cpu: 2000m memory: 2048Mi requests: memory: 256Mi cpu: 500m persistence: size: 10Gi data: replicas: 1 resources: limits: cpu: 2000m memory: 4096Mi requests: memory: 256Mi cpu: 500m persistence: size: 40Gicoordinating: replicas: 1 resources: limits: cpu: 2000m memory: 2048Mi requests: memory: 256Mi cpu: 200melasticsearch: # 集群内访问的k8s service host: bk-elastic-elasticsearch-master.blueking.svc.cluster.local # http协议的REST端口 port: 9200 username: elastic # 以下变量对部署bitnamiElasticsearch生效，外部elasticsearch服务不需要 password: blueking size: 40Gi master: size: 20Gi2.7 zookeeperresources: requests: cpu: 250m memory: 256Mi2.8 etcd3. 蓝盾存储服务包含：mysql、redis、mongodb、rabbitmq、elastic、influxdb。3.1 自建存储服务mysql: primary: persistence: size: 20Giredis: replica: persistence: size: 20Gi master: persistence: size: 20Gielasticsearch: master: persistence: size: 20Gi data: persistence: size: 20Girabbitmq: persistence: size: 20Giinfluxdb: persistence: size: 20Gimongodb: persistence: size: 20Gi3.2 外部数据库externalMysql: host: localhost port: 3306 username: bkci password: bkciexternalRedis: host: localhost port: 6379 password: bkciexternalElasticsearch: host: localhost port: 9200 username: bkci password: bkciexternalRabbitmq: host: localhost username: bkci password: bkci vhost: bkciexternalInfluxdb: host: localhost port: 8086 username: bkci password: bkciexternalMongodb: turbo: turboUrl: mongodb://bkci:bkci@localhost:27017/db_turbo quartzUrl: mongodb://bkci:bkci@localhost:27017/db_quart4. 数据迁移(Mysql)4.1 数据备份1.备份脚本准备#!/bin/bashMYSQL_USER=rootMYSQL_HOST=127.0.0.1MYSQL_PASSWD=ignoredblist='information_schema|mysql|test|db_infobase|performance_schema|sys'dblist=\"$(mysql -h$MYSQL_HOST -u$MYSQL_USER -p$MYSQL_PASSWD -Nse\"show databases;\"|grep -Ewv \"$ignoredblist\" | xargs echo)\"mysqldump -h$MYSQL_HOST -u$MYSQL_USER -p$MYSQL_PASSWD --skip-opt --create-options --default-character-set=utf8mb4 -R -E -q -e --single-transaction --no-autocommit --max-allowed-packet=1G --hex-blob -B $dblist &gt; /tmp/bk_mysql_alldata.sql将其中的MYSQL_USER、MYSQL_HOST、MYSQL_PASSWORD更换成需要备份的数据库及用户名密码。存为 dbbackup_mysql.sh 文件。2.将脚本拷贝到容器内执行以自建的蓝盾mysql为例# 将上面的数据备份脚本拷贝至自建的蓝盾mysql的pod中kubectl cp -n blueking /data/dbbackup_mysql.sh bk-ci-mysql-0:/tmp/dbbackup_mysql.sh# 开始执行数据备份kubectl exec -it -n blueking bk-mysql-mysql-master-0 -- bash /tmp/dbbackup_mysql.sh# 将备份好的sql从pod拷贝到本机暂存kubectl cp -n blueking bk-ci-mysql-0:/tmp/bk_mysql_alldata.sql /data/bkmysql_bak/bk_mysql_alldata.sql最后一步数据拷贝可以不做，直接在这个pod里进行后续的数据导入操作。4.2 数据导入上一步的数据备份是用root用户进行操作，备份中涉及存储过程函数和赋权。注意：如果导入到阿里云mysql服务中需要处理导出的sql文件，因为阿里云提供的mysql服务，root作为保留字段，不能由用户自由创建，但允许创建拥有root权限的账户，所以需要修改备份数据中相关的内容，更换成实际使用的数据库用户，以替换成 superuser 为例执行如下命令：# 统计\"`root`@\"字符串一共有多少个grep -o '`root`@' bk_mysql_alldata.sql | wc -l# 将\"`root`@\" 修改为 \"`superuser`@\"sed -i 's/`root`@/`superuser`@/g' bk_mysql_alldata.sql# 二次确认grep -o '`superuser`@' bk_mysql_alldata.sql | wc -l导入mysql -h $NEW_MYSQL_HOST -usuperuser -p$YOUR_PASSWORD --force &lt; bk_mysql_alldata.sql检查mysql -h$MYSQL_HOST -usuperuser -p$MYSQL_PASSWD -Nse\"show databases like 'devops_ci%';\"4.3 Helmfile更新变更 bkci\\environments\\default\\bkci\\bkci-custom-values.yaml.gotmpl 文件后执行 helmfile 相关命令更新服务。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾快速部署文档(v7.1)","slug":"devops/landun_install","date":"2024-05-23T16:00:00.000Z","updated":"2025-10-17T03:57:40.146Z","comments":true,"path":"2024/05/24/devops/landun_install/","link":"","permalink":"https://blazehu.github.io/2024/05/24/devops/landun_install/","excerpt":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文档旨在提供蓝鲸智云 7.1 版本蓝盾的快速部署指南。通过详细的步骤说明和脚本示例，帮助用户在 Kubernetes 集群上快速搭建蓝鲸基础服务和蓝盾平台，并实现 HTTPS 安全访问。","text":"蓝鲸持续集成平台（蓝盾）是一个免费并开源的 CI 服务。本文档旨在提供蓝鲸智云 7.1 版本蓝盾的快速部署指南。通过详细的步骤说明和脚本示例，帮助用户在 Kubernetes 集群上快速搭建蓝鲸基础服务和蓝盾平台，并实现 HTTPS 安全访问。1. 概述需要先准备一台中控机，在中控机安装 kubectl、helm、helmfile 等工具，以及蓝鲸安装脚本。然后部署基础套餐，最后再部署持续集成套餐。简单来说就是三个步骤：1.准备环境 -&gt; 2.部署基础服务 -&gt; 3.部署蓝盾。2. 准备中控机按照官方文档安装和配置即可。3. 部署基础服务需要按照官方文档一步步部署。3.1 下载安装文件请在 中控机 使用下载脚本下载蓝鲸 helmfile 包及公共证书。（ helmfile相关value文件在git上维护）bkdl-7.1-stable.sh -ur latest base demo这些文件默认放在了 ~/bkce7.1-install/ 目录。3.2 配置 Helm Chart 仓库添加 charts 仓库helm repo add blueking https://hub.bktencent.com/chartrepo/bluekinghelm repo updatehelm repo list3.3 配置全局 custom-values相关文件已经修改，在git上维护，配置访问域名。BK_DOMAIN=bk.blazehu.com # 请修改为你分配给蓝鲸平台的主域名 cd ~/bkce7.1-install/blueking/ # 进入工作目录# 可使用如下命令添加域名。如果文件已存在，请手动编辑。custom=environments/default/custom.yamlcat &gt;&gt; \"$custom\" &lt;&lt;EOFimageRegistry: $&#123;REGISTRY:-hub.bktencent.com&#125;domain: bkDomain: $BK_DOMAIN bkMainSiteDomain: $BK_DOMAINEOF3.4 生成 values 文件还有一些 values 文件随着部署环境的不同而变化，所以我们提供了脚本快速生成。生成蓝鲸 app code 对应的 secret./scripts/generate_app_secret.sh ./environments/default/app_secret.yaml生成 apigw 所需的 keypair./scripts/generate_rsa_keypair.sh ./environments/default/bkapigateway_builtin_keypair.yaml生成 paas 所需的 clusterAdmin./scripts/create_k8s_cluster_admin_for_paas3.sh3.5 安装入口网关3.5.1 安装 ingress controller先检查你的环境是否已经部署了 ingress controller:kubectl get pods -A -l app.kubernetes.io/name=ingress-nginx如果没有，则使用如下命令创建：helmfile -f 00-ingress-nginx.yaml.gotmpl synckubectl get pods -A -l app.kubernetes.io/name=ingress-nginx 查看创建的podpops集群相关标签如下：kubectl get pods -A -l app=ingress-nginx # 查看创建的podIP1=$(kubectl get svc -A -l app=nginx-ingress-lb -o jsonpath='&#123;.items[0].status.loadBalancer.ingress[0].ip&#125;')# IP1=$(kubectl get svc -A -l app.kubernetes.io/name=ingress-nginx -o jsonpath='&#123;.items[0].status.loadBalancer.ingress[0].ip&#125;')3.5.2 配置 coredns在部署过程中，会在容器内访问这些域名，所以需要提前配置 coredns，将蓝鲸域名解析到 service IP。注意：当 service 被删除，重建后 clusterIP 会变动，此时需刷新 hosts 文件。因此需要注入 hosts 配置项到 kube-system namespace 下的 coredns 系列 pod，步骤如下：cd ~/bkce7.1-install/blueking/ # 进入工作目录BK_DOMAIN=$(yq e '.domain.bkDomain' environments/default/custom.yaml) # 从自定义配置中提取, 也可自行赋值#IP1=$(kubectl get svc -A -l app.kubernetes.io/instance=ingress-nginx -o jsonpath='&#123;.items[0].spec.clusterIP&#125;')IP1=$(kubectl get svc -A -l app=nginx-ingress-lb -o jsonpath='&#123;.items[0].status.loadBalancer.ingress[0].ip&#125;')./scripts/control_coredns.sh update \"$IP1\" $BK_DOMAIN bkrepo.$BK_DOMAIN docker.$BK_DOMAIN bkapi.$BK_DOMAIN bkpaas.$BK_DOMAIN bkiam-api.$BK_DOMAIN bkiam.$BK_DOMAIN apps.$BK_DOMAIN bknodeman.$BK_DOMAIN job.$BK_DOMAIN jobapi.$BK_DOMAIN./scripts/control_coredns.sh update \"$IP1\" devops.$BK_DOMAIN./scripts/control_coredns.sh list # 检查添加的记录。确认注入结果，执行如下命令：cd ~/bkce7.1-install/blueking/ 进入工作目录./scripts/control_coredns.sh list参考输出如下：10.241.0.9 bk.blazehu.com10.241.0.9 apps.bk.blazehu.com10.241.0.9 bkrepo.bk.blazehu.com10.241.0.9 docker.bk.blazehu.com10.241.0.9 bkapi.bk.blazehu.com10.241.0.9 bkpaas.bk.blazehu.com10.241.0.9 bkiam-api.bk.blazehu.com10.241.0.9 bkiam.bk.blazehu.com10.241.0.9 bcs.bk.blazehu.com10.241.0.9 bknodeman.bk.blazehu.com10.241.0.9 job.bk.blazehu.com10.241.0.9 jobapi.bk.blazehu.com3.6 部署或对接存储服务3.6.1 部署蓝鲸预置的存储服务参考官方文档安装，相关helm配置已经放在git上维护，可以直接简单执行以下命令：helmfile -f base-storage.yaml.gotmpl sync注意：我当前使用阿里云盘，使用该存储类创建的存储盘最小容量为20Gi，目前git上已经都修改为20Gi.3.6.2 对接已有的存储服务禁用蓝鲸内置服务，配置使用已有服务。请参考helmfile定义及values文件自行研究。参考官方文档的例子。3.7 部署基础套餐通过helmfile安装 base-blueking.yaml.gotmpl ，按照顺序依次安装。具体每层安装的内容可以查看文件内容。helmfile -f base-blueking.yaml.gotmpl -l seq=first synchelmfile -f base-blueking.yaml.gotmpl -l seq=second synchelmfile -f base-blueking.yaml.gotmpl -l seq=third sync#helmfile -f base-blueking.yaml.gotmpl -l seq=fourth sync3.8 访问蓝鲸桌面在负载均衡器配置后端为 ingress-nginx pod 所在机器的内网 IP，端口为 80。详细信息参考文档。3.9 对接Ldap服务在用户中心里配置Ldap相关配置，然后更新 bk-user-api-web 服务的镜像。4. 部署蓝盾参考官方文档部署，配置 custom values 的内容提前修改完成，执行类似部署基础服务的以下命令：cd ~/bkce7.1-install/blueking/ # 进入工作目录helmfile -f 03-bkci.yaml.gotmpl sync # 部署helmfile -f 03-bkci.yaml.gotmpl apply # 更新剩下的步骤参考官方文档执行即可，主要步骤有以下三个，其他的步骤可以不做。4.1 注册默认构建镜像我们提供了 bkci/ci 镜像用于提供构建环境。为了加速镜像下载过程，可以修改镜像地址为 hub.bktencent.com/bkci/ci，或者为你自己托管的内网 registry。先检查数据库有没有历史数据：kubectl exec -it -n blueking bk-ci-mysql-0 -- /bin/bash -c 'MYSQL_PWD=\"$MYSQL_ROOT_PASSWORD\" mysql -u root -e \"USE devops_ci_store; SELECT IMAGE_NAME,IMAGE_CODE,IMAGE_REPO_NAME FROM T_IMAGE WHERE IMAGE_CODE = \\\"bkci\\\" ;\"'请根据结果进行操作：如果有显示镜像数据，可以修改镜像地址为蓝鲸国内仓库，也可改为你已经缓存在内网的镜像：kubectl exec -it -n blueking bk-ci-mysql-0 -- /bin/bash -c 'MYSQL_PWD=\"$MYSQL_ROOT_PASSWORD\" mysql -u root -e \"USE devops_ci_store; UPDATE T_IMAGE SET IMAGE_REPO_NAME=\\\"hub.bktencent.com/bkci/ci\\\" WHERE IMAGE_CODE = \\\"bkci\\\" ;\"'然后重新查询数据库，可以看到 IMAGE_REPO_NAME 列已经更新。如果没有镜像，可以新增：kubectl exec -n blueking deploy/bk-ci-bk-ci-store -- \\curl -vs http://bk-ci-bk-ci-store.blueking.svc.cluster.local/api/op/market/image/init -X POST \\-H 'X-DEVOPS-UID: admin' -H 'Content-type: application/json' -d '&#123;\"imageCode\":\"bkci\",\"imageName\":\"bkci\",\"imageRepo\":\"hub.bktencent.com/bkci/ci\",\"projectCode\":\"demo\",\"userId\":\"admin\"&#125;' | jq .注意：当你单独卸载蓝盾重装后，可能出现查询镜像为空，但是新增镜像时报错 { status: 400, message: “权限中心创建项目失败” } 的情况。这是因为权限中心存在蓝盾 demo 项目的数据所致，我们后续会优化蓝盾单独卸载的文档。请先手动新建项目，并修改上述代码中 projectCode 字段的值。4.2 对接制品库蓝盾依靠蓝鲸制品库来提供流水线仓库和自定义仓库，需要调整制品库的认证模式。当 bk-ci release 成功启动后，我们开始配置蓝鲸制品库，并注册到蓝盾中。4.2.1 修改 bk-repo custom valuescd ~/bkce7.1-install/blueking/case $(yq e '.auth.config.realm' environments/default/bkrepo-custom-values.yaml.gotmpl 2&gt;/dev/null) in null|\"\") tee -a environments/default/bkrepo-custom-values.yaml.gotmpl &lt;&lt;&lt; $'auth:\\n config:\\n realm: devops' ;; devops) echo \"environments/default/bkrepo-custom-values.yaml.gotmpl 中配置了 .auth.config.realm=devops, 无需修改.\" ;; *) echo \"environments/default/bkrepo-custom-values.yaml.gotmpl 中配置了 .auth.config.realm 为其他值, 请手动修改值为 devops.\" ;;esac修改成功后，继续在工作目录执行如下命令使修改生效：helmfile -f base-blueking.yaml.gotmpl -l name=bk-repo apply4.2.2 检查配置是否生效检查 release 生效的 values 和 configmap 是否重新渲染。请在 中控机 执行：helm get values -n blueking bk-repo | yq e '.auth.config.realm'kubectl get cm -n blueking bk-repo-bkrepo-auth -o json | jq -r '.data.\"application.yml\"' | yq e '.auth.realm' -预期 2 条命令均显示 devops。如果任意配置没有生效，请检查上述 helmfile 命令的输出是否正常。4.2.3 重启 bk-repo auth 微服务因为 deployment 没有变动，所以不会自动重启，此处需要单独重启：kubectl rollout restart deployment -n blueking bk-repo-bkrepo-auth4.2.4 在蓝盾中注册制品库请在 中控机 执行：cd ~/bkce7.1-install/blueking/ BK_DOMAIN=$(yq e '.domain.bkDomain' environments/default/custom.yaml) kubectl exec -i -n blueking deploy/bk-ci-bk-ci-project -- curl -sS -X PUT -H 'Content-Type: application/json' -H 'Accept: application/json' -H 'X-DEVOPS-UID: admin' -d \"&#123;\\\"showProjectList\\\":true,\\\"showNav\\\":true,\\\"status\\\":\\\"ok\\\",\\\"deleted\\\":false,\\\"iframeUrl\\\":\\\"//bkrepo.$BK_DOMAIN/ui/\\\"&#125;\" \"http://bk-ci-bk-ci-project.blueking.svc.cluster.local/api/op/services/update/Repo\"4.3 下载和上传插件4.3.1 下载插件请在 中控机 执行：bkdl-7.1-stable.sh -ur latest ci-plugins4.3.2 上传插件此操作只能新建插件，每个插件只能上传一次。cd ~/bkce7.1-install/blueking/ # 进入工作目录for f in ../ci-plugins/*.zip; do atom=\"$&#123;f##*/&#125;\" atom=$&#123;atom%.zip&#125; echo &gt;&amp;2 \"upload $atom from $f\" kubectl exec -i -n blueking deploy/bk-ci-bk-ci-store -- \\ curl -s \\ http://bk-ci-bk-ci-store.blueking.svc.cluster.local/api/op/pipeline/atom/deploy/\"?publisher=admin\" \\ -H 'X-DEVOPS-UID: admin' -F atomCode=$atom -F file=@- &lt; \"$f\" | jq . # 设置为默认插件，全部项目可见。 kubectl exec -n blueking deploy/bk-ci-bk-ci-store -- \\ curl -s http://bk-ci-bk-ci-store.blueking.svc.cluster.local/api/op/pipeline/atom/default/atomCodes/$atom \\-H 'X-DEVOPS-UID: admin' -X POST | jq .done注意事项：插件重复上传：如果重复执行会报错：{“status”: 2100001, “message”: “系统内部繁忙，请稍后再试”}。后续更新插件，请访问蓝盾研发商店的工作台界面，在列表中找到对应插件进行“升级”操作。插件包体过大：上传或者更新插件报错：”413 Request Entity Too Large”。原因是nginx-ingress的默认配置中proxy-body-size的数值太小，具体解决方式详见：Ingress 域名方式导致413 Request Entity Too Large-阿里云开发者社区。5. TLS配置如果开始就准备好了相关证书，那么可以将该步骤提前，在部署基础服务和蓝盾之前就先修改好相关的yaml，将需要创建的Secret和要更新的Ingress配置都提前修改好，然后直接部署即可。5.1 购买相关证书涉及的域名：bk.blazehu.com、*.bk.blazehu.com（如devops.bk.blazehu.com）。需购买泛域名证书。5.2 创建相关Secret（用于存储TLS证书和私钥）# 创建SecretBK_DOMAIN=$(yq e '.domain.bkDomain' environments/default/custom.yaml)cd $HOME/$BK_DOMAINkubectl create secret tls $BK_DOMAIN -n blueking --cert=$HOME/$BK_DOMAIN/$BK_DOMAIN.pem --key=$HOME/$BK_DOMAIN/$BK_DOMAIN.key5.3 更新 Ingress TLS在证书及证书secret准备好之后，需要变更蓝鲸系列ingress开启tls的支持，执行对应的脚本#!/bin/bash# 配置变量NAMESPACE=\"blueking\"DOMAIN_FILE=\"environments/default/custom.yaml\"BK_DOMAIN=$(yq e '.domain.bkDomain' \"$DOMAIN_FILE\") # 从配置文件中读取域名TLS_HOST=\"*.$BK_DOMAIN\" # 泛域名TLS_SECRET=\"$BK_DOMAIN\" # Secret 名称与域名一致# 检查域名和 Secret 是否正确if [[ -z \"$BK_DOMAIN\" ]]; then echo \"Error: BK_DOMAIN is not set in $DOMAIN_FILE.\" exit 1fi# 获取命名空间中的所有 Ingress 资源ingresses=$(kubectl get ingress -n \"$NAMESPACE\" -o jsonpath='&#123;.items[*].metadata.name&#125;')# 遍历所有 Ingress 资源并更新 TLS 配置for ingress in $ingresses; do echo \"Updating Ingress: $ingress in namespace: $NAMESPACE\" # 检查 Ingress 是否已存在 TLS 配置 if kubectl get ingress \"$ingress\" -n \"$NAMESPACE\" -o jsonpath='&#123;.spec.tls&#125;' | grep -q \"$TLS_HOST\"; then echo \"TLS configuration for $TLS_HOST already exists in Ingress $ingress. Skipping.\" continue fi # 更新 Ingress 的 TLS 配置 kubectl patch ingress \"$ingress\" -n \"$NAMESPACE\" --type=json -p='[ &#123; \"op\": \"add\", \"path\": \"/spec/tls\", \"value\": [ &#123; \"hosts\": [\"'\"$TLS_HOST\"'\"], \"secretName\": \"'\"$TLS_SECRET\"'\" &#125; ] &#125; ]' || &#123; echo \"Failed to update Ingress $ingress\"; exit 1; &#125; echo \"Updated Ingress $ingress with TLS configuration for $TLS_HOST.\"doneecho \"All Ingress resources in namespace $NAMESPACE have been updated with TLS configuration for $TLS_HOST.\"5.4 配置蓝鲸启用HTTPS在git仓库维护，主要有两个变更：environments/default/custom.yaml: .bkDomainScheme 值设置为 httpsenvironments/default/bkci/bkci-custom-values.yaml.gotmpl: .config.bkHttpSchema 值设置为 httpsyq -i '.bkDomainScheme = \"https\"' environments/default/custom.yaml# 将bkHttpSchema: https替换为bkHttpSchema: httpsed -i 's|bkHttpSchema: http|bkHttpSchema: https|' environments/default/bkci/bkci-custom-values.yaml.gotmpl重启服务使https配置生效# 重启第一批服务helmfile -f base-blueking.yaml.gotmpl -l seq=first sync# bk-apigateway 部分 pod 不会重启，主动删除等重建kubectl delete pod -n blueking -l 'app.kubernetes.io/instance=bk-apigateway,app.kubernetes.io/component in (api-support-fe, dashboard-fe)'# 等待 bk-apigateway 全部 pod 重启成功后进行下一步kubectl get pod -n blueking -l 'app.kubernetes.io/instance=bk-apigateway,app.kubernetes.io/component in (api-support-fe, dashboard-fe)'# bkrepo 部分 pod 不会重启，主动删除等重建kubectl delete pod -n blueking -l 'app.kubernetes.io/instance=bk-repo,bk.repo.scope=backend'# 等待 bkrepo 全部 pod 重启成功后进行下一步# 这里一定要等所有pod重启成功后，才开始下一步，否则会导致服务异常# repo系列服务会因为阿里云EKS csi插件问题，导致服务卡住，需要手动删除卡在ContainerCreating的pod，让pod重启watch -n 1 kubectl get pod -n blueking -l 'app.kubernetes.io/instance=bk-repo,bk.repo.scope=backend'# 重启第二批服务helmfile -f base-blueking.yaml.gotmpl -l seq=second sync# 持续观察等 bk-repo-repository pod 全部Readywatch -n 1 kubectl get pod -n blueking -l 'app.kubernetes.io/instance=bk-repo,app.kubernetes.io/component=repository'# 重启第三批服务helmfile -f base-blueking.yaml.gotmpl -l seq=third sync # bk-paas-webfe-web pod 不会重启，主动删除等重建kubectl delete pod -n blueking -l 'app.kubernetes.io/instance=bk-paas,app.kubernetes.io/name=webfe'# 重启蓝盾服务helmfile -f 03-bkci.yaml.gotmpl sync# 这里蓝盾系列服务可能不会重启，需要手动删除老podkubectl get pods -n blueking --field-selector=status.phase=Running| grep 'bk-ci-bk-ci' |awk '&#123;print $1&#125;' | xargs kubectl delete pod -n blueking5.5 构建机Agent配置变更及重启# 停止agent服务./stop.shBK_DOMAIN=\"deveops.bk.blazehu.com\"# 修改.agent.properties文件，开启httpssed -i '' 's|http://$BK_DOMAIN|https://$BK_DOMAIN|g' .agent.properties# 修改telegraf.conf文件，开启httpssed -i '' 's|http://$BK_DOMAIN|https://$BK_DOMAIN|g' telegraf.conf# 启动agent./start.sh# 这里需要注意，仔细查看.agent.properties里devops.agent.user， 这里是哪个用户就用哪个用户启动agent6. 参考官方文档官方论坛对接Ldap登陆蓝盾源码Ingress 域名方式导致413 Request Entity Too Large-阿里云开发者社区","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"蓝盾接入LDAP登录(v7.1)","slug":"devops/landun_login_ldap","date":"2024-05-21T16:00:00.000Z","updated":"2025-06-30T03:50:01.716Z","comments":true,"path":"2024/05/22/devops/landun_login_ldap/","link":"","permalink":"https://blazehu.github.io/2024/05/22/devops/landun_login_ldap/","excerpt":"通过蓝鲸用户中心配置 LDAP 后，存在登录失败以及用户名需要加域（与当前用户的使用习惯不符）等问题。","text":"通过蓝鲸用户中心配置 LDAP 后，存在登录失败以及用户名需要加域（与当前用户的使用习惯不符）等问题。背景按照官方文档对接 LDAP 服务后用户正常同步，但是登录时报用户密码错误。问题分析后台查看 bk-user-api-web 日志，报错如下：&#123; \"levelname\": \"ERROR\", \"asctime\": \"2024-05-22 15:15:30,947\", \"pathname\": \"/app/bkuser_core/api/login/views.py\", \"lineno\": 205, \"funcName\": \"login\", \"process\": 530, \"thread\": 140333237386568, \"request_id\": \"ebf27affe3f74e77b961a11df38583e9\", \"exc_info\": \"Traceback (most recent call last): File \\\"/app/bkuser_core/api/login/views.py\\\", line 197, in login login_class().check(profile, password) File \\\"/app/bkuser_core/categories/plugins/ldap/login.py\\\", line 62, in check target_dn = self.fetch_dn(user) File \\\"/app/bkuser_core/categories/plugins/ldap/login.py\\\", line 30, in fetch_dn return force_str(user_info[\\\"raw_attributes\\\"][\\\"entryDN\\\"][0]) File \\\"/usr/local/lib/python3.6/site-packages/ldap3/utils/ciDict.py\\\", line 68, in __getitem__ return self._store[self._case_insensitive_keymap[self._ci_key(key)]] KeyError: 'entrydn'\"&#125;报错信息很明显，在 user_info.raw_attributes 里找不到 entryDN 这个 key。即获取用户用于登陆的 login dn 失败，需要修改相关逻辑。解决方案修改代码本地通过 vscode 插件连上 ldap 后，发现用户用于登陆的 login dn 的 key 应该是 dn，修改用于用户登陆的 login dn 逻辑。详细步骤如下：通过部署的配置文件 environments/default/version.yaml 找到部署的 bk-user 的版本为：bk-user: &quot;1.4.14-beta.10&quot;下载该包到本地 helm pull blueking/bk-user --version 1.4.14-beta.10，解压找到镜像版本：tag: &quot;v2.5.4-beta.10&quot;找到 bk-user 该 tag 源码地址：https://github.com/TencentBlueKing/bk-user/tree/v2.5.4-beta.10根据日志找到对应文件 src/api/bkuser_core/categories/plugins/ldap/login.py修改 fetch_dn 函数的实现，将 entryDN 修改为 dn。@staticmethoddef fetch_dn(user_info: dict) -&gt; str: return force_str(user_info[\"raw_attributes\"][\"dn\"][0])更新服务制作镜像我们只需要更新 bk-user-api-web 服务所以只需要制作该服务镜像，执行命令 make build-api。变更模版在 environments/default 目录下新建 bkuser-custom-values.yaml.gotmpl 文件使用新的镜像，若以存在则跳过。# bk-user-api:v1.0.1api: image: registry: your registry repository: bk-user-api pullPolicy: IfNotPresent tag: \"v1.0.1\"更新服务执行下面的命令进行更新：helmfile -f base-blueking.yaml.gotmpl -l seq=third sync检查以下容器镜像的变更是否符合预期：bk-user-api-beatbk-user-api-webbk-user-api-worker总结登陆失败的问题可以通过修改源码进行修复。登陆无需加域的临时方案：将用户和组织结构信息同步至默认域，然后查找默认域。需要修改同步逻辑。参考https://bk.tencent.com/s-mart/community/question/9114?type=articlehttps://github.com/TencentBlueKing/bk-user/tree/v2.5.4-beta.10","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"}]},{"title":"基于 k8s 的发布编排工具的思考","slug":"cloudnative/k8s_lo","date":"2024-05-07T16:00:00.000Z","updated":"2025-11-14T03:45:01.358Z","comments":true,"path":"2024/05/08/cloudnative/k8s_lo/","link":"","permalink":"https://blazehu.github.io/2024/05/08/cloudnative/k8s_lo/","excerpt":"在 PAAS 平台里，应用发布、配置变更（端口、就绪/存活探针）、灰度策略、扩缩容、规格调整（CPU/MEM/DISK）、路由策略、熔断限流等，最终都要落在 Kubernetes 资源编排与变更之上。","text":"在 PAAS 平台里，应用发布、配置变更（端口、就绪/存活探针）、灰度策略、扩缩容、规格调整（CPU/MEM/DISK）、路由策略、熔断限流等，最终都要落在 Kubernetes 资源编排与变更之上。1. 概述核心链路：定义意图 → 产出清单 → 与集群对齐（apply/sync）。实现思路：首先是“能写出来”（可自动生成资源清单）。然后是“能管起来”（一致性、漂移检测、审计、回滚、协同）。期间逐步抽象：将“不变的结构”做成模板，将“变化的参数”外置化。2. 原生 client-go 直连 kube-apiserver最直接的实现方式：后端用 client-go 调 kube-apiserver，完成 CRUD 与控制流。2.1 原理用 client-go 拉取/更新对象（Deployment/Service/ConfigMap 等），以编程方式表达“变更”。2.2 简单示例dep, _ := client.AppsV1().Deployments(ns).Get(ctx, name, getOpts)dep.Spec.Template.Spec.Containers[0].Image = newImageclient.AppsV1().Deployments(ns).Update(ctx, dep, updateOpts)优缺点：优点：改动即生效，表达能力强，学习与接入成本低。不足：与 K8s API 强耦合；无版本审计与回滚；难以规模化复用。3. 模板渲染（抽象结构，参数外置）在方案一基础上把“不变的结构”抽为模板，把“变化的数值”当参数传入，渲染出最终 YAML，再 kubectl 或 client-go 等方式应用到集群。模板实现可以是 Go Template、Helm、Kustomize 等。3.1 原理模板负责“结构”，参数负责“取值”；把相同形态的资源一次建模、多次复用。3.2 模板示例以 demo/template/simple-deployment.yaml 为例，通过 等占位符参数化，运行时渲染后应用到集群。image: &#123;&#123;image&#125;&#125;replicas: '&#123;&#123;replicas&#125;&#125;'优缺点：优点：形态清晰、复用良好；降低重复劳动和出错率。不足：解决了“怎么写”的问题，但对“怎么管”（版本、审计、漂移）还不够。4. 引入 GitOps（把“写”升级为“管”）当模板体系成熟后，新的问题是“如何管理”：版本历史、审计与回滚、多人协同、漂移检测与持续调协。这时将模板与参数纳入 Git 管理，把 Git 作为唯一事实来源（SSOT），由控制器（如 ArgoCD）持续对齐集群状态。4.1 原理变更即 PR/MR；合入即发布；历史天然可审计可回滚。控制器（ArgoCD）提供漂移检测与持续调协，保证集群与 Git 一致。模板与参数可以共存于一个仓库、拆分到独立模板仓库，或依旧存 DB（但推荐以 Git 为主）。4.2 模板选择与组织渲染方式：直接读取原始 YAML、Helm 再渲染、或 Kustomize 叠加；依据场景取舍。变量提取：是写在模板里，还是由上层代码合成，实质差别不大；重点是统一规范与可维护性。4.3 Helm 片段示例# templates/deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: &#123;&#123; .Values.name &#125;&#125;spec: replicas: &#123;&#123; .Values.replicas &#125;&#125; selector: matchLabels: app: &#123;&#123; .Values.name &#125;&#125; template: metadata: labels: app: &#123;&#123; .Values.name &#125;&#125; spec: containers: - name: &#123;&#123; .Values.containerName &#125;&#125; image: &#123;&#123; .Values.image &#125;&#125; ports: - containerPort: &#123;&#123; .Values.port &#125;&#125;# values.yamlname: demo-deploymentreplicas: 3containerName: webimage: nginx:1.14port: 80优缺点：优点：把“写”纳入“管”，提供一致性、可追溯、可回滚与自动调协。不足：引入仓库治理与冲突处理成本；需要制定分支与审批策略。5. 综合对比方案架构定位可扩展性可维护性耦合度资源联动适用场景直接调用SDK直连 kube-apiserver高中高代码显式处理小团队起步、快速打通链路模板渲染结构抽象 + 参数外置中中中模板参数化支撑通用形态、需复用与降错GitOpsGit 为唯一事实 + 控制器调协高高低原生支持（Helm/Kustomize）需要审计/回滚/漂移检测/协同6. 推荐方案小团队/快速起步：从方案一开始，先跑通核心能力。形成通用结构：引入方案二，把不变抽模板、把变化参数化（Go Template/Helm/Kustomize 皆可）。需要“管”的能力：升级到方案三（GitOps），用控制器提供审计/回滚/漂移检测/调协。","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://blazehu.github.io/tags/kubernetes/"},{"name":"helm","slug":"helm","permalink":"https://blazehu.github.io/tags/helm/"}]},{"title":"Golang archive/zip 问题排查小记","slug":"backend/golang/golang_archive_zip","date":"2024-02-17T16:00:00.000Z","updated":"2025-11-05T08:31:33.588Z","comments":true,"path":"2024/02/18/backend/golang/golang_archive_zip/","link":"","permalink":"https://blazehu.github.io/2024/02/18/backend/golang/golang_archive_zip/","excerpt":"2021年给开发商做了一个移动端版本体验，近期开发商反馈当上传的ipa文件比较大超过4G的时候上传失败。","text":"2021年给开发商做了一个移动端版本体验，近期开发商反馈当上传的ipa文件比较大超过4G的时候上传失败。背景移动端版本体验的技术架构如下图，，蓝盾插件请求版本体验后端，后端临时缓存文件并解析ipa和apk文件，获取包的相关信息（包名，版本号，图标等），然后上传至cos存储。服务端使用的golang的版本是go1.16。问题分析插件侧报错用户反馈插件执行报错 “zip: not a valid zip file”（插件将ipa或者apk包上传至版本体验后端）服务端解析包报错通过排查后端服务日志，问题比较清晰，就是后端解析包的时候报错。解析ipa包的相关代码如下所示，整体逻辑比较简单，通过 archive/zip 读取ipa文件，通过正则找到 plist 和 AppIcon 文件，然后分别通过 plist 和 iospng 解析得到相关信息。func ParseIpa(readerAt io.ReaderAt, size int64) (*App, error) &#123; log.Info(\"[upload] file size : \", size) var reInfoPlist = regexp.MustCompile(`Payload/[^/]+/Info\\.plist`) reader, err := zip.NewReader(readerAt, size) if err != nil &#123; log.Error(\"[upload] zip new reader failed, err: \", err.Error()) return nil, err &#125; var plistFile, iosIconFile *zip.File for _, f := range reader.File &#123; log.Info(\"[upload] reader file: \", f.Name) switch &#123; case reInfoPlist.MatchString(f.Name): plistFile = f case strings.Contains(f.Name, \"AppIcon60x60\"): iosIconFile = f &#125; &#125; log.Info(\"[upload] reader plist file: \", plistFile.Name) log.Info(\"[upload] reader icon file: \", iosIconFile.Name) app, err := parseIpaFile(plistFile) if err != nil &#123; // NOTE: ignore error log.Error(\"[upload] parse ipa failed, err: \", err.Error()) &#125; log.Info(\"[upload] parse ipa success, err: \", app) icon, err := parseIpaIcon(iosIconFile) if err != nil &#123; // NOTE: ignore error log.Error(\"[upload] parse ipa icon failed, err: \", err.Error()) &#125; app.Size = size app.Icon = icon return app, nil&#125;上述的报错：“zip: not a valid zip file” 定位是 archive/zip 库抛出的。源码阅读(archive/zip)通过查阅源码，发现该错误就是常量 ErrFormat，NewReader 方法调用了 init 方法，而 init 方法在循环读取文件头部 readDirectoryHeader 时会判断错误类型，如果是 ErrFormat 会将错误抛出。var ( ErrFormat = errors.New(\"zip: not a valid zip file\"))func NewReader(r io.ReaderAt, size int64) (*Reader, error) &#123; if size &lt; 0 &#123; return nil, errors.New(\"zip: size cannot be negative\") &#125; zr := new(Reader) var err error if err = zr.init(r, size); err != nil &amp;&amp; err != ErrInsecurePath &#123; return nil, err &#125; return zr, err&#125;func (r *Reader) init(rdr io.ReaderAt, size int64) error &#123; end, baseOffset, err := readDirectoryEnd(rdr, size) if err != nil &#123; return err &#125; r.r = rdr r.baseOffset = baseOffset // Since the number of directory records is not validated, it is not // safe to preallocate r.File without first checking that the specified // number of files is reasonable, since a malformed archive may // indicate it contains up to 1 &lt;&lt; 128 - 1 files. Since each file has a // header which will be _at least_ 30 bytes we can safely preallocate // if (data size / 30) &gt;= end.directoryRecords. if end.directorySize &lt; uint64(size) &amp;&amp; (uint64(size)-end.directorySize)/30 &gt;= end.directoryRecords &#123; r.File = make([]*File, 0, end.directoryRecords) &#125; r.Comment = end.comment rs := io.NewSectionReader(rdr, 0, size) if _, err = rs.Seek(r.baseOffset+int64(end.directoryOffset), io.SeekStart); err != nil &#123; return err &#125; buf := bufio.NewReader(rs) // The count of files inside a zip is truncated to fit in a uint16. // Gloss over this by reading headers until we encounter // a bad one, and then only report an ErrFormat or UnexpectedEOF if // the file count modulo 65536 is incorrect. for &#123; f := &amp;File&#123;zip: r, zipr: rdr&#125; err = readDirectoryHeader(f, buf) if err == ErrFormat || err == io.ErrUnexpectedEOF &#123; break &#125; if err != nil &#123; return err &#125; f.headerOffset += r.baseOffset r.File = append(r.File, f) &#125; if uint16(len(r.File)) != uint16(end.directoryRecords) &#123; // only compare 16 bits here // Return the readDirectoryHeader error if we read // the wrong number of directory entries. return err &#125; if zipinsecurepath.Value() == \"0\" &#123; for _, f := range r.File &#123; if f.Name == \"\" &#123; // Zip permits an empty file name field. continue &#125; // The zip specification states that names must use forward slashes, // so consider any backslashes in the name insecure. if !filepath.IsLocal(f.Name) || strings.Contains(f.Name, `\\`) &#123; zipinsecurepath.IncNonDefault() return ErrInsecurePath &#125; &#125; &#125; return nil&#125;4. 本地复现本地复现该问题的时候发现解析正常，但是打成镜像容器部署会报错，通过对比我发现本地使用的go的版本是 go1.21 ，而镜像使用的构建镜像是 go1.16 。挨个查阅 golang 的 release 最终定位到是 go1.19 的新特性导致的差异。相关改动代码如下：// The count of files inside a zip is truncated to fit in a uint16.// Gloss over this by reading headers until we encounter// a bad one, and then only report an ErrFormat or UnexpectedEOF if// the file count modulo 65536 is incorrect.for &#123; f := &amp;File&#123;zip: z, zipr: r&#125; err = readDirectoryHeader(f, buf) // For compatibility with other zip programs, // if we have a non-zero base offset and can't read // the first directory header, try again with a zero // base offset. if err == ErrFormat &amp;&amp; z.baseOffset != 0 &amp;&amp; len(z.File) == 0 &#123; z.baseOffset = 0 if _, err = rs.Seek(int64(end.directoryOffset), io.SeekStart); err != nil &#123; return err &#125; buf.Reset(rs) continue &#125; if err == ErrFormat || err == io.ErrUnexpectedEOF &#123; break &#125; if err != nil &#123; return err &#125; f.headerOffset += z.baseOffset z.File = append(z.File, f)&#125;新增逻辑解读：如果在读取第一个目录头时遇到 ErrFormat 错误，并且基偏移量不为零，则尝试使用零基偏移量重新读取目录头。如果重新读取目录头仍然失败，则返回错误。NOTE: 不同操作系统或 ZIP 工具创建的 ZIP 文件时，可能会遇到不同的实现和约定。这可能导致基偏移量的计算方式不同，从而导致错误的值。解决方案升级golang构建的基础镜像，从1.16 -&gt; 1.22，重新构建新的服务镜像更新服务，这样基本满足了用户的需求。# builderFROM golang:1.22 AS builderCOPY . /src/RUN cd /src &amp;&amp; go mod tidyRUN cd /src &amp;&amp; go build -ldflags '-linkmode \"external\" --extldflags \"-static\"' main.go# runtimeFROM alpine:3.14LABEL maintainer=\"blazehu\"WORKDIR /ipapkCOPY --from=builder /src/main /ipapkCOPY docker-entrypoint.sh /docker-entrypoint.shRUN chmod +x /docker-entrypoint.shENTRYPOINT /docker-entrypoint.sh参考资料https://go.dev/doc/go1.19https://bk.tencent.com/docs/markdown/ZH/Devops/3.0/UserGuide/Services/Client-experience/intro.md","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"},{"name":"archive/zip","slug":"archive-zip","permalink":"https://blazehu.github.io/tags/archive-zip/"}]},{"title":"ArgoCD 源码解析：SSE 实时推送机制","slug":"cloudnative/argocd_sse","date":"2023-11-29T16:00:00.000Z","updated":"2025-08-15T04:08:57.227Z","comments":true,"path":"2023/11/30/cloudnative/argocd_sse/","link":"","permalink":"https://blazehu.github.io/2023/11/30/cloudnative/argocd_sse/","excerpt":"服务器发送事件 (Server-Sent Events) 是一种服务器推送技术，使客户端能够通过 HTTP 连接从服务器接收自动更新，并描述了在建立初始客户端连接后服务器如何向客户端发起数据传输。","text":"服务器发送事件 (Server-Sent Events) 是一种服务器推送技术，使客户端能够通过 HTTP 连接从服务器接收自动更新，并描述了在建立初始客户端连接后服务器如何向客户端发起数据传输。1. 背景在使用Argo CD的时候可以发现页面可以实时刷新应用的状态，比如同步中，那Argo CD是如何实现消息的实时推送的呢？本文将简要介绍Argo CD使用到的消息推送技术：SSE。2. 源码解析通过浏览器开发者工具可以发现前端请求的地址是 stream/applications，响应头表示这是一个服务器发送事件（Server-Sent Events，SSE）。本文的源码基于2.6.0版本Content-Type: text/event-stream：这个响应头告诉客户端，服务器将发送的数据是以文本格式的事件流（Event Stream）。2.1 客户端实现Argo CD的前端使用的是 React，相关代码 application-details.tsx 实现如下：private loadAppInfo(name: string, appNamespace: string): Observable&lt;&#123;application: appModels.Application; tree: appModels.ApplicationTree&#125;&gt; &#123; return from(services.applications.get(name, appNamespace)) .pipe( mergeMap(app =&gt; &#123; const fallbackTree = &#123; nodes: app.status.resources.map(res =&gt; (&#123;...res, parentRefs: [], info: [], resourceVersion: '', uid: ''&#125;)), orphanedNodes: [], hosts: [] &#125; as appModels.ApplicationTree; return combineLatest( merge( from([app]), this.appChanged.pipe(filter(item =&gt; !!item)), AppUtils.handlePageVisibility(() =&gt; services.applications .watch(&#123;name, appNamespace&#125;) .pipe( map(watchEvent =&gt; &#123; if (watchEvent.type === 'DELETED') &#123; this.onAppDeleted(); &#125; return watchEvent.application; &#125;) ) .pipe(repeat()) .pipe(retryWhen(errors =&gt; errors.pipe(delay(500)))) ) ), merge( from([fallbackTree]), services.applications.resourceTree(name, appNamespace).catch(() =&gt; fallbackTree), AppUtils.handlePageVisibility(() =&gt; services.applications .watchResourceTree(name, appNamespace) .pipe(repeat()) .pipe(retryWhen(errors =&gt; errors.pipe(delay(500)))) ) ) ); &#125;) ) .pipe(filter(([application, tree]) =&gt; !!application &amp;&amp; !!tree)) .pipe(map(([application, tree]) =&gt; (&#123;application, tree&#125;)));&#125;loadAppInfo 方法的主要目的是从服务器加载应用信息，并在页面可见时实时更新。它返回一个 Observable，包含应用信息 services.applications.watch 和应用资源树 services.applications.watchResourceTree。我们继续查看应用信息的 watch 函数实现。public watch(query?: &#123;name?: string; resourceVersion?: string; projects?: string[]; appNamespace?: string&#125;, options?: QueryOptions): Observable&lt;models.ApplicationWatchEvent&gt; &#123; const search = new URLSearchParams(); if (query) &#123; if (query.name) &#123; search.set('name', query.name); &#125; if (query.resourceVersion) &#123; search.set('resourceVersion', query.resourceVersion); &#125; if (query.appNamespace) &#123; search.set('appNamespace', query.appNamespace); &#125; &#125; if (options) &#123; const searchOptions = optionsToSearch(options); search.set('fields', searchOptions.fields); search.set('selector', searchOptions.selector); search.set('appNamespace', searchOptions.appNamespace); query?.projects?.forEach(project =&gt; search.append('projects', project)); &#125; const searchStr = search.toString(); const url = `/stream/applications$&#123;(searchStr &amp;&amp; '?' + searchStr) || ''&#125;`; return requests .loadEventSource(url) .pipe(repeat()) .pipe(retry()) .pipe(map(data =&gt; JSON.parse(data).result as models.ApplicationWatchEvent)) .pipe( map(watchEvent =&gt; &#123; watchEvent.application = this.parseAppFields(watchEvent.application); return watchEvent; &#125;) );&#125;可以看到该函数使用 requests.loadEventSource(url) 加载服务器发送的事件流（Event Stream），请求地址为 /stream/applications。loadEventSource 的实现是基于 EventSource 对象的, EventSource 实例设置 onmessage 事件处理程序，当接收到新消息时，调用 observer.next(msg.data) 将消息数据推送到 Observable 实现页面的实时刷新。在文档 Using server-sent events 中有介绍, 这里就不详细介绍了。export default &#123; loadEventSource(url: string): Observable&lt;string&gt; &#123; return Observable.create((observer: Observer&lt;any&gt;) =&gt; &#123; let eventSource = new EventSource(`$&#123;apiRoot()&#125;$&#123;url&#125;`); eventSource.onmessage = msg =&gt; observer.next(msg.data); eventSource.onerror = e =&gt; () =&gt; &#123; observer.error(e); onError.next(e); &#125;; // EventSource does not provide easy way to get notification when connection closed. // check readyState periodically instead. const interval = setInterval(() =&gt; &#123; if (eventSource &amp;&amp; eventSource.readyState === ReadyState.CLOSED) &#123; observer.error('connection got closed unexpectedly'); &#125; &#125;, 500); return () =&gt; &#123; clearInterval(interval); eventSource.close(); eventSource = null; &#125;; &#125;); &#125;&#125;;2.2 服务端实现Argo CD的后端使用的是 Go，相关代码 application.go 实现如下：type ApplicationService_WatchServer interface &#123; Send(*v1alpha1.ApplicationWatchEvent) error grpc.ServerStream&#125;func (s *Server) Watch(q *application.ApplicationQuery, ws application.ApplicationService_WatchServer) error &#123; appName := q.GetName() appNs := s.appNamespaceOrDefault(q.GetAppNamespace()) logCtx := log.NewEntry(log.New()) if q.Name != nil &#123; logCtx = logCtx.WithField(\"application\", *q.Name) &#125; projects := map[string]bool&#123;&#125; for i := range q.Projects &#123; projects[q.Projects[i]] = true &#125; claims := ws.Context().Value(\"claims\") selector, err := labels.Parse(q.GetSelector()) if err != nil &#123; return fmt.Errorf(\"error parsing labels with selectors: %w\", err) &#125; minVersion := 0 if q.GetResourceVersion() != \"\" &#123; if minVersion, err = strconv.Atoi(q.GetResourceVersion()); err != nil &#123; minVersion = 0 &#125; &#125; // sendIfPermitted is a helper to send the application to the client's streaming channel if the // caller has RBAC privileges permissions to view it sendIfPermitted := func(a appv1.Application, eventType watch.EventType) &#123; if len(projects) &gt; 0 &amp;&amp; !projects[a.Spec.GetProject()] &#123; return &#125; if appVersion, err := strconv.Atoi(a.ResourceVersion); err == nil &amp;&amp; appVersion &lt; minVersion &#123; return &#125; matchedEvent := (appName == \"\" || (a.Name == appName &amp;&amp; a.Namespace == appNs)) &amp;&amp; selector.Matches(labels.Set(a.Labels)) if !matchedEvent &#123; return &#125; if !s.enf.Enforce(claims, rbacpolicy.ResourceApplications, rbacpolicy.ActionGet, a.RBACName(s.ns)) &#123; // do not emit apps user does not have accessing return &#125; s.inferResourcesStatusHealth(&amp;a) err := ws.Send(&amp;appv1.ApplicationWatchEvent&#123; Type: eventType, Application: a, &#125;) if err != nil &#123; logCtx.Warnf(\"Unable to send stream message: %v\", err) return &#125; &#125; events := make(chan *appv1.ApplicationWatchEvent, watchAPIBufferSize) // Mimic watch API behavior: send ADDED events if no resource version provided // If watch API is executed for one application when emit event even if resource version is provided // This is required since single app watch API is used for during operations like app syncing and it is // critical to never miss events. if q.GetResourceVersion() == \"\" || q.GetName() != \"\" &#123; apps, err := s.appLister.List(selector) if err != nil &#123; return fmt.Errorf(\"error listing apps with selector: %w\", err) &#125; sort.Slice(apps, func(i, j int) bool &#123; return apps[i].QualifiedName() &lt; apps[j].QualifiedName() &#125;) for i := range apps &#123; sendIfPermitted(*apps[i], watch.Added) &#125; &#125; unsubscribe := s.appBroadcaster.Subscribe(events) defer unsubscribe() for &#123; select &#123; case event := &lt;-events: sendIfPermitted(event.Application, event.Type) case &lt;-ws.Context().Done(): return nil &#125; &#125;&#125;在这段代码中，ws 用于发送实时更新的应用程序事件。当有新的事件发生时，sendIfPermitted 函数会将事件发送到客户端。NOTE: ws 是一个实现了 ApplicationService_WatchServer 接口的对象。ApplicationService_WatchServer 接口继承了 grpc.ServerStream 接口，并定义了一个名为 Send 的方法。这意味着 ws 可以用作服务器端的流，并具有发送 ApplicationWatchEvent 类型消息的能力。3 实现一个简单的SSE接口服务样例相关代码地址，实现如下效果，页面上通过 sse 获取数据（当前时间和推送人），后端服务由 grpc｜grpc-gateway stream 推送。NOTE: 后续补充更新中3.1 使用 protobuf 定义 gRPC 服务新建一个项目sse-demo，在项目目录下执行go mod init命令完成go module初始化。 在项目目录下创建一个 proto/chat.proto 文件，其内容如下:syntax = \"proto3\";option go_package = \"github.com/blazehu/sse-demo/server/apiclient/chat\";package chat;import \"google/api/annotations.proto\";import \"google/protobuf/empty.proto\";service ChatService &#123; rpc Chat(google.protobuf.Empty) returns (stream Message) &#123; option (google.api.http) = &#123; get: \"/api/v1/stream/chat\" &#125;; &#125;&#125;message Message &#123; string user = 1; string content = 2;&#125;3.2 生成代码这用 buf 生成代码，首先在项目目录下执行 buf mod init 生成 buf.yaml 文件，我们需要修改该文件内容如下：version: v1name: buf.build/blazehu/sse-demodeps: - buf.build/googleapis/googleapisbreaking: use: - FILElint: use: - DEFAULTNOTE: 这里主要是添加依赖项 googleapis，相关详细文档。修改完成后执行 buf mod update 来选择要使用的依赖项的版本。 然后我们创建一个 buf.gen.yaml 文件用于生成存根。buf.gen.yaml文件内容如下：version: v1plugins: - plugin: go out: gen opt: paths=source_relative - plugin: go-grpc out: gen opt: paths=source_relative,require_unimplemented_servers=false - plugin: grpc-gateway out: gen opt: paths=source_relative这时候我们可以通过 buf generate 生成存根，也可以使用 protoc 来生成存根，这里就不展开说明。$ buf generate这时候将会由如下的目录结构：├── buf.gen.yaml├── buf.lock├── buf.yaml├── gen│ └── proto│ ├── chat.pb.go│ ├── chat.pb.gw.go│ └── chat_grpc.pb.go├── go.mod└── proto └── chat.proto3.3 实现 GRPC 服务上述生成 pb 和 grpc 相关代码后，实现一个 gRPC Server 服务，相关代码如下：package mainimport ( \"github.com/blazehu/sse-demo/gen/proto\" \"google.golang.org/grpc\" \"google.golang.org/protobuf/types/known/emptypb\" \"log\" \"net\" \"time\")// Server provides chat servicetype Server struct &#123; chat.UnimplementedChatServiceServer&#125;// Chat returns chat contentfunc (s *Server) Chat(_ *emptypb.Empty, stream chat.ChatService_ChatServer) error &#123; for &#123; msg := chat.Message&#123; User: \"blazehu\", Content: time.Now().Format(time.RFC3339), &#125; if err := stream.Send(&amp;msg); err != nil &#123; return err &#125; time.Sleep(time.Second * 1) &#125;&#125;func main() &#123; lis, err := net.Listen(\"tcp\", \":50051\") if err != nil &#123; log.Fatalf(\"failed to listen: %v\", err) &#125; var opts []grpc.ServerOption grpcServer := grpc.NewServer(opts...) chat.RegisterChatServiceServer(grpcServer, &amp;Server&#123;&#125;) grpcServer.Serve(lis)&#125;代码逻辑非常简单，定义 Server 对象然后实现了相关的 Chat 方法，然后 main 函数注册并启动了一个 gRPC Server 服务。NOTE: Chat 方法是每隔一秒钟就发送一条消息，该消息内容就是当前的时间。3.4 实现 HTTP 服务新增 main.go 文件，在 main.go 文件中添加和启动 gRPC-Gateway mux。相关代码如下：package mainimport ( \"context\" \"github.com/blazehu/sse-demo/gen/proto\" \"github.com/blazehu/sse-demo/util\" \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials/insecure\" googleproto \"google.golang.org/protobuf/proto\" \"log\" \"net/http\")const ( grpcEndpoint = \"localhost:50051\" httpPort = \":8080\")func myFilter(ctx context.Context, w http.ResponseWriter, resp googleproto.Message) error &#123; w.Header().Set(\"Connection\", \"keep-alive\") w.Header().Set(\"Cache-Control\", \"no-cache\") return nil&#125;func main() &#123; ctx := context.Background() ctx, cancel := context.WithCancel(ctx) defer cancel() // 创建 gRPC 连接 var opts []grpc.DialOption opts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials())) grpcConn, err := grpc.DialContext(ctx, grpcEndpoint, opts...) if err != nil &#123; log.Fatalf(\"Failed to dial server: %v\", err) &#125; defer grpcConn.Close() // 创建 gRPC-Gateway 服务器 gwmux := runtime.NewServeMux( runtime.WithMarshalerOption(runtime.MIMEWildcard, util.NewCustomTranscoder(&amp;runtime.JSONPb&#123;&#125;)), runtime.WithForwardResponseOption(myFilter), ) err = chat.RegisterChatServiceHandler(ctx, gwmux, grpcConn) if err != nil &#123; log.Fatalf(\"Failed to register gateway: %v\", err) &#125; // 设置 CORS 策略 mux := http.NewServeMux() handler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; w.Header().Set(\"Access-Control-Allow-Origin\", \"*\") w.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS\") w.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\") if r.Method == \"OPTIONS\" &#123; w.WriteHeader(http.StatusOK) return &#125; gwmux.ServeHTTP(w, r) &#125;) mux.Handle(\"/\", handler) // 启动 gRPC-Gateway 服务器 log.Printf(\"Starting gRPC-Gateway on %s\", httpPort) if err := http.ListenAndServe(httpPort, mux); err != nil &#123; log.Fatalf(\"Failed to serve: %v\", err) &#125;&#125;因为前端 sse 访问需要跨域所以需要设置 CORS 策略，并且返回的消息类型为 text/event-stream，所以我们这里自定义一个 CustomTranscoder，它将 JSON 转换为 text/event-stream 格式。相关实现如下：package utilimport ( \"bytes\" \"encoding/json\" \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\" \"google.golang.org/protobuf/proto\" \"io\")type CustomTranscoder struct &#123; marshaler runtime.Marshaler&#125;func NewCustomTranscoder(marshaler runtime.Marshaler) *CustomTranscoder &#123; return &amp;CustomTranscoder&#123;marshaler: marshaler&#125;&#125;func (c *CustomTranscoder) ContentType(_ interface&#123;&#125;) string &#123; return \"text/event-stream\"&#125;func (c *CustomTranscoder) Marshal(v interface&#123;&#125;) ([]byte, error) &#123; var jsonBytes []byte var err error if pb, ok := v.(proto.Message); ok &#123; // Marshal message to JSON jsonBytes, err = c.marshaler.Marshal(pb) &#125; else &#123; // If not a proto.Message, try to marshal it as a regular JSON object jsonBytes, err = json.Marshal(v) &#125; if err != nil &#123; return nil, err &#125; var buf bytes.Buffer buf.WriteString(\"data: \") buf.Write(jsonBytes) buf.WriteString(\"\\n\\n\") return buf.Bytes(), nil&#125;func (c *CustomTranscoder) Unmarshal(data []byte, v interface&#123;&#125;) error &#123; return c.marshaler.Unmarshal(data, v)&#125;func (c *CustomTranscoder) NewDecoder(r io.Reader) runtime.Decoder &#123; return c.marshaler.NewDecoder(r)&#125;func (c *CustomTranscoder) NewEncoder(w io.Writer) runtime.Encoder &#123; return c.marshaler.NewEncoder(w)&#125;NOTE: 这里需要注意输入值转化为 proto.Message 类型可能会失败，所以我们在 Marshal 方法中添加一个检查，以确保输入值是一个 proto.Message 类型。如果不是，我们可以尝试将其序列化为 JSON。3.5 测试同时启动 gRPC Server 和 HTTP Server，然后浏览器访问地址: http://127.0.0.1:8080/api/v1/stream/chat ，可以发现浏览器将会每秒刷新一条数据。3.6 前端实现前端使用 vue2，这里就不详细说明了，页面通过 EventSource 与服务端建立通信，然后一直在接收服务端推送的消息，并将消息更新至页面上。mounted() &#123; this.loadData();&#125;,methods: &#123; async loadData() &#123; const vm = this; const eventSource = new EventSource(\"http://127.0.0.1:8080/api/v1/stream/chat\"); eventSource.onopen = function () &#123; console.log('connect eventSource success.'); &#125;; eventSource.onmessage = (e) =&gt; &#123; const data = JSON.parse(e.data); vm.msg = `$&#123;data.result.content&#125; - $&#123;data.result.user&#125; send`; &#125;; eventSource.onerror = function () &#123; console.log('connect eventSource failed.'); &#125;; this.$forceUpdate(); &#125;,&#125;4. 参考资料https://en.wikipedia.org/wiki/Server-sent_eventshttps://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_eventshttps://grpc-ecosystem.github.io/grpc-gateway/docs/tutorials/generating_stubs/using_buf/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"},{"name":"sse","slug":"sse","permalink":"https://blazehu.github.io/tags/sse/"}]},{"title":"ArgoCD 源码解析：自动同步机制","slug":"cloudnative/argocd_webhook","date":"2023-10-24T16:00:00.000Z","updated":"2025-08-15T04:10:23.370Z","comments":true,"path":"2023/10/25/cloudnative/argocd_webhook/","link":"","permalink":"https://blazehu.github.io/2023/10/25/cloudnative/argocd_webhook/","excerpt":"Argo CD 的自动同步功能通过监控 Git 仓库中的更改来自动部署和更新应用程序。这确保了 Kubernetes 集群中的应用程序始终与 Git 仓库中的配置保持一致。开发团队只需将应用程序的描述和配置存储在 Git 仓库中，Argo CD 会根据这些信息自动部署和更新应用程序。","text":"Argo CD 的自动同步功能通过监控 Git 仓库中的更改来自动部署和更新应用程序。这确保了 Kubernetes 集群中的应用程序始终与 Git 仓库中的配置保持一致。开发团队只需将应用程序的描述和配置存储在 Git 仓库中，Argo CD 会根据这些信息自动部署和更新应用程序。1. 背景Argo CD 是一个开源的持续部署工具，专为 Kubernetes 应用程序设计。它遵循 GitOps 原则，将 Git 仓库作为应用程序部署和基础设施管理的“单一真实来源”。架构上 Argo CD 采用基于组件的架构设计，将不同可部署单元的职责分开，以提高系统的灵活性、可维护性和可扩展性。有关架构的详细介绍可以阅读这篇文档。通过阅读 Argo CD 官方文档我们可以知道 Argo CD 每三分钟轮询一次 Git 存储库，以检测清单的更改。为了消除轮询延迟，Argo CD API server 支持 配置 Git Webhook。2. 源码解析本文的源码基于2.6.0版本2.1 main.go 入口函数Argo CD 使用 cobra 来构建应用程序。通过 cmd 目录下的 main.go 入口函数，我们可以很轻易的找到每个组件。根据架构可知 API Server 是控制平面中的唯一入口。command = apiserver.NewCommand()2.2 argocd-server阅读 ArgoCDServer 实例的 Run 方法，可以发现 ArgoCDServer 使用 cmux 库在多路复用，在同一端口上处理标准 HTTP 和 gRPC 请求。grpcS, appResourceTreeFn := a.newGRPCServer() grpcWebS := grpcweb.WrapServer(grpcS)// 省略...httpS = a.newHTTPServer(ctx, a.ListenPort, grpcWebS, appResourceTreeFn, listeners.GatewayConn) tcpm := cmux.New(listeners.Main)if !a.useTLS() &#123; httpL = tcpm.Match(cmux.HTTP1Fast()) grpcL = tcpm.MatchWithWriters(cmux.HTTP2MatchHeaderFieldSendSettings(\"content-type\", \"application/grpc\"))&#125; else &#123; // 省略...&#125;go func() &#123; a.checkServeErr(\"grpcS\", grpcS.Serve(grpcL)) &#125;()go func() &#123; a.checkServeErr(\"httpS\", httpS.Serve(httpL)) &#125;()我在官方文档上找到 Argo CD 中如何实现身份验证（authn）和授权（authz）的一张图，可以发现当我们通过 Web 页面或者 CLI 调用 apiserver 的时候首先经过 cmux 检查匹配，如果请求是 http1.x 将由 http mux 处理，如果是 http2 并且 content-type: application/grpc 则由 grpc Server 处理。由于 Argo CD apiserver 绝大多数的 API 服务是通过 gRPC 实现的，所以这里引入了 gRPC Gateway 来将 gRPC 服务转换为 RESTful API。2.2.1 ArgoCDWebhookHandler从配置 Git Webhook 中找到 webhook events 的 endpoint 是 /api/webhook 。是走的 http1.x，我们查看 ArgoCDServer 实例的 newHTTPServer 方法，路径为 “/api/webhook” 的 HTTP 请求映射的是 acdWebhookHandler.Handler。// Webhook handler for git events (Note: cache timeouts are hardcoded because API server does not write to cache and not really using them)argoDB := db.NewDB(a.Namespace, a.settingsMgr, a.KubeClientset)acdWebhookHandler := webhook.NewHandler(a.Namespace, a.ArgoCDServerOpts.ApplicationNamespaces, a.AppClientset, a.settings, a.settingsMgr, repocache.NewCache(a.Cache.GetCache(), 24*time.Hour, 3*time.Minute), a.Cache, argoDB)mux.HandleFunc(\"/api/webhook\", acdWebhookHandler.Handler)继续往下看 ArgoCDWebhookHandler 的 Handle 方法的具体实现，根据请求的 Header 解析得到不同 Git 服务提供商的 Git 事件的数据，然后交给 HandleEvent 方法来处理，HandleEvent 经过一系列的校验检查后执行 RefreshApp 刷新应用。// HandleEvent handles webhook events for repo push eventsfunc (a *ArgoCDWebhookHandler) HandleEvent(payload interface&#123;&#125;)2.2.2 RefreshApp注释写的很清楚，RefreshApp 通过更新应用的注解，强制控制器处理它。// RefreshApp updates the refresh annotation of an application to coerce the controller to process itfunc RefreshApp(appIf v1alpha1.ApplicationInterface, name string, refreshType argoappv1.RefreshType) (*argoappv1.Application, error) &#123; metadata := map[string]interface&#123;&#125;&#123; \"metadata\": map[string]interface&#123;&#125;&#123; \"annotations\": map[string]string&#123; argoappv1.AnnotationKeyRefresh: string(refreshType), &#125;, &#125;, &#125; var err error patch, err := json.Marshal(metadata) if err != nil &#123; return nil, fmt.Errorf(\"error marshaling metadata: %w\", err) &#125; for attempt := 0; attempt &lt; 5; attempt++ &#123; app, err := appIf.Patch(context.Background(), name, types.MergePatchType, patch, metav1.PatchOptions&#123;&#125;) if err != nil &#123; if !apierr.IsConflict(err) &#123; return nil, fmt.Errorf(\"error patching annotations in application %q: %w\", name, err) &#125; &#125; else &#123; log.Infof(\"Requested app '%s' refresh\", name) return app, nil &#125; time.Sleep(100 * time.Millisecond) &#125; return nil, err&#125;2.3 application-controller沿着之前的路径，从入口函数找到应用控制器的实现，appcontroller 中定义了默认的同步周期为180s。控制器通过 newApplicationInformerAndLister 创建 ApplicationInformer 监听应用的事件并加入到队列中。const ( // Default time in seconds for application resync period defaultAppResyncPeriod = 180)// 省略...resyncDuration = time.Duration(appResyncPeriod) * time.Second// 省略...appController, err = controller.NewApplicationController( namespace, settingsMgr, kubeClient, appClient, repoClientset, cache, kubectl, resyncDuration, hardResyncDuration, time.Duration(selfHealTimeoutSeconds)*time.Second, metricsPort, metricsCacheExpiration, metricsAplicationLabels, kubectlParallelismLimit, persistResourceHealth, clusterFilter, applicationNamespaces)// 省略...go appController.Run(ctx, statusProcessors, operationProcessors)2.3.1 newApplicationInformerAndLister上文中 RefreshApp 更新应用的注解将会产生一个 Update Event，将会走到 requestAppRefresh 。informer.AddEventHandler( cache.ResourceEventHandlerFuncs&#123; AddFunc: func(obj interface&#123;&#125;) &#123; if !ctrl.canProcessApp(obj) &#123; return &#125; key, err := cache.MetaNamespaceKeyFunc(obj) if err == nil &#123; ctrl.appRefreshQueue.Add(key) ctrl.appOperationQueue.Add(key) &#125; &#125;, UpdateFunc: func(old, new interface&#123;&#125;) &#123; if !ctrl.canProcessApp(new) &#123; return &#125; key, err := cache.MetaNamespaceKeyFunc(new) if err != nil &#123; return &#125; var compareWith *CompareWith oldApp, oldOK := old.(*appv1.Application) newApp, newOK := new.(*appv1.Application) if oldOK &amp;&amp; newOK &amp;&amp; automatedSyncEnabled(oldApp, newApp) &#123; log.WithField(\"application\", newApp.QualifiedName()).Info(\"Enabled automated sync\") compareWith = CompareWithLatest.Pointer() &#125; ctrl.requestAppRefresh(newApp.QualifiedName(), compareWith, nil) ctrl.appOperationQueue.Add(key) &#125;, DeleteFunc: func(obj interface&#123;&#125;) &#123; if !ctrl.canProcessApp(obj) &#123; return &#125; // IndexerInformer uses a delta queue, therefore for deletes we have to use this // key function. key, err := cache.DeletionHandlingMetaNamespaceKeyFunc(obj) if err == nil &#123; ctrl.appRefreshQueue.Add(key) &#125; &#125;, &#125;,)2.3.2 requestAppRefreshcompareWith 是 CompareWithLatest， after 是 nil。requestAppRefresh 方法将会在 appRefreshQueue 和 appOperationQueue 队列中添加该更新事件。// requestAppRefresh adds a request for given app to the refresh queue. appName// needs to be the qualified name of the application, i.e. &lt;namespace&gt;/&lt;name&gt;.func (ctrl *ApplicationController) requestAppRefresh(appName string, compareWith *CompareWith, after *time.Duration) &#123; key := ctrl.toAppKey(appName) if compareWith != nil &amp;&amp; after != nil &#123; ctrl.appComparisonTypeRefreshQueue.AddAfter(fmt.Sprintf(\"%s/%d\", key, compareWith), *after) &#125; else &#123; if compareWith != nil &#123; ctrl.refreshRequestedAppsMutex.Lock() ctrl.refreshRequestedApps[key] = compareWith.Max(ctrl.refreshRequestedApps[key]) ctrl.refreshRequestedAppsMutex.Unlock() &#125; if after != nil &#123; ctrl.appRefreshQueue.AddAfter(key, *after) ctrl.appOperationQueue.AddAfter(key, *after) &#125; else &#123; ctrl.appRefreshQueue.Add(key) ctrl.appOperationQueue.Add(key) &#125; &#125;&#125;2.3.3 run控制器使用两个单独的队列来处理应用的协调（appRefreshQueue）和同步（appOperationQueue），这两个队列分别通过 processAppRefreshQueueItem 和 processAppOperationQueueItem 来处理。statusProcessors 和 operationProcessors 来控制启动协程的数量。// Run starts the Application CRD controller.func (ctrl *ApplicationController) Run(ctx context.Context, statusProcessors int, operationProcessors int) &#123; defer runtime.HandleCrash() defer ctrl.appRefreshQueue.ShutDown() defer ctrl.appComparisonTypeRefreshQueue.ShutDown() defer ctrl.appOperationQueue.ShutDown() defer ctrl.projectRefreshQueue.ShutDown() ctrl.metricsServer.RegisterClustersInfoSource(ctx, ctrl.stateCache) ctrl.RegisterClusterSecretUpdater(ctx) go ctrl.appInformer.Run(ctx.Done()) go ctrl.projInformer.Run(ctx.Done()) errors.CheckError(ctrl.stateCache.Init()) if !cache.WaitForCacheSync(ctx.Done(), ctrl.appInformer.HasSynced, ctrl.projInformer.HasSynced) &#123; log.Error(\"Timed out waiting for caches to sync\") return &#125; go func() &#123; errors.CheckError(ctrl.stateCache.Run(ctx)) &#125;() go func() &#123; errors.CheckError(ctrl.metricsServer.ListenAndServe()) &#125;() for i := 0; i &lt; statusProcessors; i++ &#123; go wait.Until(func() &#123; for ctrl.processAppRefreshQueueItem() &#123; &#125; &#125;, time.Second, ctx.Done()) &#125; for i := 0; i &lt; operationProcessors; i++ &#123; go wait.Until(func() &#123; for ctrl.processAppOperationQueueItem() &#123; &#125; &#125;, time.Second, ctx.Done()) &#125; go wait.Until(func() &#123; for ctrl.processAppComparisonTypeQueueItem() &#123; &#125; &#125;, time.Second, ctx.Done()) go wait.Until(func() &#123; for ctrl.processProjectQueueItem() &#123; &#125; &#125;, time.Second, ctx.Done()) &lt;-ctx.Done()&#125;2.3.4 processAppRefreshQueueItem从 appRefreshQueue 获取到上文中更新注解的事件后调用 needRefreshAppStatus，needRefresh, refreshType, comparisonLevel = true, RefreshTypeNormal, CompareWithLatestForceResolve。然后通过 CompareAppState 使用指定的版本和提供的源来比较应用程序 git 状态与实时应用程序状态。appKey, shutdown := ctrl.appRefreshQueue.Get()obj, exists, err := ctrl.appInformer.GetIndexer().GetByKey(appKey.(string))origApp, ok := obj.(*appv1.Application)needRefresh, refreshType, comparisonLevel := ctrl.needRefreshAppStatus(origApp, ctrl.statusRefreshTimeout, ctrl.statusHardRefreshTimeout)compareResult := ctrl.appStateManager.CompareAppState(app, project, revisions, sources, refreshType == appv1.RefreshTypeHard, comparisonLevel == CompareWithLatestForceResolve, localManifests, hasMultipleSources)上文提到的三分钟定时轮训也是在 needRefreshAppStatus 中实现。CompareAppState 方法中会调用 appStateManager 实例的 getRepoObjs 来获取 Git 仓库中渲染出的清单文件。getRepoObjs 通过 gRPC 调用 reposerver 的 GenerateManifest 方法获取渲染出的清单文件。// AppStateManager defines methods which allow to compare application spec and actual application state.type AppStateManager interface &#123; CompareAppState(app *v1alpha1.Application, project *appv1.AppProject, revisions []string, sources []v1alpha1.ApplicationSource, noCache bool, noRevisionCache bool, localObjects []string, hasMultipleSources bool) *comparisonResult SyncAppState(app *v1alpha1.Application, state *v1alpha1.OperationState)&#125;// repoClientset 初始化后层层传递至 `AppStateManager` 实例中repoClientset := apiclient.NewRepoServerClientset(repoServerAddress, repoServerTimeoutSeconds, tlsConfig)// getRepoObjs 通过 gRPC 调用 reposerver 的 GenerateManifest 方法manifestInfo, err := repoClient.GenerateManifest(context.Background(), &amp;apiclient.ManifestRequest&#123; Repo: repo, Repos: permittedHelmRepos, Revision: revisions[i], NoCache: noCache, NoRevisionCache: noRevisionCache, AppLabelKey: appLabelKey, AppName: app.InstanceName(m.namespace), Namespace: app.Spec.Destination.Namespace, ApplicationSource: &amp;source, Plugins: tools, KustomizeOptions: kustomizeOptions, KubeVersion: serverVersion, ApiVersions: argo.APIResourcesToStrings(apiResources, true), VerifySignature: verifySignature, HelmRepoCreds: permittedHelmCredentials, TrackingMethod: string(argo.GetTrackingMethod(m.settingsMgr)), EnabledSourceTypes: enabledSourceTypes, HelmOptions: helmOptions, HasMultipleSources: app.Spec.HasMultipleSources(), RefSources: refSources,&#125;)得到 compareResult 后会调用 autoSync 方法，如果应用开启了自动同步，将会更新 Application 的 Operation ，来启动同步操作。// autoSync will initiate a sync operation for an application configured with automated syncfunc (ctrl *ApplicationController) autoSync(app *appv1.Application, syncStatus *appv1.SyncStatus, resources []appv1.ResourceStatus) *appv1.ApplicationConditionprocessAppRefreshQueueItem 最后将会调用 persistAppStatus 方法用于持久化，通过调用 k8s api 更新 applicaition 的 status。// persistAppStatus persists updates to application status. If no changes were made, it is a no-opfunc (ctrl *ApplicationController) persistAppStatus(orig *appv1.Application, newStatus *appv1.ApplicationStatus) ``` ##### 2.3.5 processAppOperationQueueItem跟 `processAppRefreshQueueItem` 类似，从 `appOperationQueue` 队列中拿到待执行同步操作的应用实例，判断该应用的 `Operation` 字段是否为空，如果不为空则执行 `processRequestedAppOperation`。`processRequestedAppOperation` 也会进行一些状态校验，比如是否正在同步中等，最终应用下资源的同步将由 `appStateManager` 实例的 `SyncAppState` 实现。```gofunc (ctrl *ApplicationController) processRequestedAppOperation(app *appv1.Application) &#123; // ... if err := argo.ValidateDestination(context.Background(), &amp;app.Spec.Destination, ctrl.db); err != nil &#123; state.Phase = synccommon.OperationFailed state.Message = err.Error() &#125; else &#123; ctrl.appStateManager.SyncAppState(app, state) &#125; // ....&#125;func (m *appStateManager) SyncAppState(app *v1alpha1.Application, state *v1alpha1.OperationState) &#123; // Sync requests might be requested with ambiguous revisions (e.g. master, HEAD, v1.2.3). // This can change meaning when resuming operations (e.g a hook sync). After calculating a // concrete git commit SHA, the SHA is remembered in the status.operationState.syncResult field. // This ensures that when resuming an operation, we sync to the same revision that we initially // started with. // 省略... syncCtx, cleanup, err := sync.NewSyncContext( compareResult.syncStatus.Revision, reconciliationResult, restConfig, rawConfig, m.kubectl, app.Spec.Destination.Namespace, openAPISchema, opts..., ) if err != nil &#123; state.Phase = common.OperationError state.Message = fmt.Sprintf(\"failed to initialize sync context: %v\", err) return &#125; defer cleanup() start := time.Now() if state.Phase == common.OperationTerminating &#123; syncCtx.Terminate() &#125; else &#123; syncCtx.Sync() &#125; // 省略...&#125;syncCtx 我们这里看接口定义大致了解即可，具体实现这里就不再展开了。// SyncContext defines an interface that allows to execute sync operation step or terminate it.type SyncContext interface &#123; // Terminate terminates sync operation. The method is asynchronous: it starts deletion is related K8S resources // such as in-flight resource hooks, updates operation status, and exists without waiting for resource completion. Terminate() // Executes next synchronization step and updates operation status. Sync() // Returns current sync operation state and information about resources synchronized so far. GetState() (common.OperationPhase, string, []common.ResourceSyncResult)&#125;这里的 SyncContext 是由 gitops-engine 库实现。3. 源码流程图4. 总结自动同步是 Argo CD 的核心功能，了解其底层实现原理和源码有助于拓展技术视野，深入理解 Argo CD 的工作原理，并在遇到问题时提供解决方案。5. 参考文档https://argo-cd.readthedocs.io/en/stable/developer-guide/architecture/components/https://argo-cd.readthedocs.io/en/stable/developer-guide/architecture/authz-authn/https://argo-cd.readthedocs.io/en/stable/operator-manual/webhook/https://argo-cd.readthedocs.io/en/stable/operator-manual/high_availability/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"}]},{"title":"Protocol Buffers 学习笔记","slug":"backend/golang/golang_pb","date":"2023-03-21T16:00:00.000Z","updated":"2025-07-08T03:48:45.528Z","comments":true,"path":"2023/03/22/backend/golang/golang_pb/","link":"","permalink":"https://blazehu.github.io/2023/03/22/backend/golang/golang_pb/","excerpt":"Protocol Buffers 是一种跨语言、跨平台的序列化方法，可实现结构化数据的高效编码和解码。","text":"Protocol Buffers 是一种跨语言、跨平台的序列化方法，可实现结构化数据的高效编码和解码。概述Protocol Buffers 是一种数据序列化格式，类似于 JSON，但体积更小、速度更快，并支持本地语言绑定。它允许用户定义数据结构，并自动生成源代码，以便在各种数据流和编程语言中轻松读写结构化数据。Protocol Buffers 解决了什么问题？Protocol Buffers 为最大几兆字节的类型化、结构化数据包提供一种序列化格式。该格式适用于短暂的网络传输和长期数据存储。它支持在不影响现有数据或更新代码的情况下扩展新信息，广泛应用于谷歌的服务器间通信和数据存储。它还能保持向后兼容性，支持添加新字段和删除现有字段。使用 Protocol Buffers 有什么好处？Protocol Buffers 非常适合需要以语言无关、平台无关、可扩展的方式序列化结构化、类似记录的类型化数据的任何场景。它们通常用于定义通信协议（与 gRPC 一起使用）以及数据存储。使用 Protocol Buffers 的一些优点紧凑的数据存储快速解析多种编程语言的支持通过自动生成的类优化功能跨语言兼容性同样的消息可以由任何支持的编程语言编写的代码读取。可以在一个平台上使用 Java 程序从一个软件系统捕获数据，根据 .proto 定义序列化它，然后在另一个平台上运行的单独的 Python 应用程序中从序列化数据中提取特定值。Protocol buffers 编译器 protoc 直接支持以下语言：C++C#JavaKotlinObjective-CPHPPythonRuby以下语言由 Google 支持，但项目源代码位于 GitHub 仓库。protoc 编译器为这些语言使用插件：DartGo其他语言不直接由 Google 支持，而是由其他 GitHub 项目支持。这些语言在协议缓冲区的第三方插件中有介绍。跨项目支持可以通过在 .proto 文件中定义消息类型并将其放置在特定项目代码库之外来在项目之间使用 Protocol buffers。如果你正在定义消息类型或枚举，并预计你的团队之外的人员将广泛使用它们，那么可以将它们放在没有依赖关系的单独文件中。谷歌内部广泛使用的一些 proto 定义示例包括 timestamp.proto 和 status.proto。Go 生成代码指南编译器调用Protocol buffer 编译器需要一个插件来生成 Go 代码。使用 Go 1.16 或更高版本运行以下命令来安装它：go install google.golang.org/protobuf/cmd/protoc-gen-go@latest定义 proto 文件创建如下目录结构和定义一个用于测试的 proto 文件:.└── proto └── demo.protosyntax = \"proto3\";message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 results_per_page = 3;&#125;定义好测试用的消息后，为了生成 GO 代码，还必须为每个 .proto 文件提供 Go 包的导入路径。有两种方式指定Go导入路径：NOTE: 导入路径就是生成的 Go 代码的文件路径。在 .proto 文件中声明它在调用 protoc 时在命令行上声明它NOTE: 通常建议在 .proto 文件中声明它，以便通过 .proto 文件本身来集中识别，并简化调用 protoc 时传递的标志集。1. 在 .proto 文件中声明在文件中通过 go_package 选项声明：syntax = \"proto3\";option go_package = \"proto/demo\";message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 results_per_page = 3;&#125;执行 protoc --proto_path=proto --go_out=. demo.proto 可以看到成功生成了代码：.└── proto ├── demo │ └── demo.pb.go └── demo.proto2. 在调用 protoc 时在命令行上声明传递一个或多个 M${PROTO_FILE}=${GO_IMPORT_PATH} 标志在命令行上指定。这个例子中通过 --go_opt=Mdemo.proto=proto/demo 声明。protoc --proto_path=proto --go_out=. --go_opt=Mdemo.proto=proto/demo demo.protoNOTE: Go 导入路径和 .proto 文件中的包说明符 package 之间没有关联。后者仅与 protobuf 命名空间相关，而前者仅与 Go 命名空间相关。此外，Go 导入路径和 .proto 导入路径之间没有关联。生成 GO 代码使用 protoc 命令生成，如：protoc --proto_path=proto --go_out=. --go_opt=paths=source_relative demo.protoproto_path：指定在编译 .proto 文件时查找导入文件的路径go_out：生成的 Go 代码的导入路径go_opt：用来指定生成的 Go 代码的一些特性，比如是否生成 gRPC 代码、是否使用快速的路径解析器等常用的 go_opt 选项paths=source_relative: 表示生成的 Go 代码的导入路径应该相对于 .proto 文件的源文件路径（即 .proto 文件的相对路径），而不是相对于 GOPATH。M&lt;proto_import_path&gt;=&lt;go_import_path&gt;: 映射 .proto 文件中的导入路径到 Go 代码中的导入路径。这在处理第三方 .proto 文件时非常有用，特别是当这些文件的导入路径与 Go 代码的导入路径不匹配时。参考资料https://protobuf.dev/overview/https://protobuf.dev/reference/go/go-generated/#invocation","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"}]},{"title":"AntV G6 实现 k8s 资源拓扑图展示","slug":"frontend/g6_tree_demo","date":"2023-01-29T16:00:00.000Z","updated":"2025-08-15T03:48:13.289Z","comments":true,"path":"2023/01/30/frontend/g6_tree_demo/","link":"","permalink":"https://blazehu.github.io/2023/01/30/frontend/g6_tree_demo/","excerpt":"使用 AntV G6 实现类似 argocd 资源拓扑图的树图。","text":"使用 AntV G6 实现类似 argocd 资源拓扑图的树图。简介本文主要记录总结如何使用 AntV G6 来展示 k8s 的资源拓扑图，下文简单实现一个 helm 部署 zookeeper 的图例，代码地址 。准备工作这里使用 vue2 来快速搭建一个页面，对 vue 熟悉的可以略过。 相关版本如下：BLAZEHU-MB:Projects $ node --versionv14.16.0BLAZEHU-MB:Projects $ vue --version@vue/cli 5.0.8创建项目vue create g6-tree-demo官方快速上手文档：https://cn.vuejs.org/guide/quick-start.html#creating-a-vue-application安装 &amp; 引用 G6npm install --save @antv/g6官方快速上手文档：https://g6.antv.antgroup.com/manual/getting-started实现自定义元素文件地址：common/index.js，参考官方 modelRect 内置节点源码。拓扑图实现逻辑文件地址：components/DemoTree.vue，下面简单介绍：页面挂载后注册自定义元素 执行 register 函数，后面简写为函数名，初始化拓扑图 initTree。初始化拓扑图首先准备数据 initData，然后创建拓扑图 createTree。配置数据源，渲染 data、render。更新数据使用 changeData 函数。NOTE: id 如果不更新 changeData 页面刷新不完全，不能识别到node节点的变化。最终实现效果如下：总结上文简单介绍了如何使用G6来绘制拓扑图，要实现类似 argocd 前端页面的效果我们还需要做节点折叠、节点菜单、节点标签展示等等，后续作者也在陆续完善。参考资料http://g6.antv.antgroup.com/manual/faq/performance-opthttp://g6.antv.antgroup.com/zh/examples/scatter/node/#node","categories":[{"name":"前端开发","slug":"前端开发","permalink":"https://blazehu.github.io/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"g6","slug":"g6","permalink":"https://blazehu.github.io/tags/g6/"}]},{"title":"Golang 版本管理工具：g","slug":"backend/golang/golang_g","date":"2023-01-14T16:00:00.000Z","updated":"2025-07-08T03:48:48.529Z","comments":true,"path":"2023/01/15/backend/golang/golang_g/","link":"","permalink":"https://blazehu.github.io/2023/01/15/backend/golang/golang_g/","excerpt":"在开发 Go 项目时，不同项目可能需要不同版本的 Go 语言环境。g 是一个简单而强大的 Go 版本管理工具，它可以帮助我们在同一台主机上轻松切换 Go 版本，并为每个项目创建独立的开发环境，避免版本冲突。","text":"在开发 Go 项目时，不同项目可能需要不同版本的 Go 语言环境。g 是一个简单而强大的 Go 版本管理工具，它可以帮助我们在同一台主机上轻松切换 Go 版本，并为每个项目创建独立的开发环境，避免版本冲突。g 安装g 是一个跨平台的 Go 版本管理工具，支持 Windows、Linux 和 macOS。安装文档g 常用命令查看可用的 Go 版本g ls-remote安装指定版本的 Gog install 1.20.3设置全局 Go 版本g use 1.20.3查看已安装的 Go 版本g ls卸载 Go 版本g uninstall 1.20.3总结通过使用 g，我们可以在同一台主机上轻松管理多个 Go 版本，并为每个项目选择合适的版本。这不仅解决了不同项目对 Go 版本的需求，还避免了版本冲突，提高了开发效率。参考资料g 文档","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"}]},{"title":"服务上云后如何使用 perf 生成火焰图","slug":"cloudnative/perf_analyse","date":"2022-09-13T16:00:00.000Z","updated":"2025-08-15T06:47:10.919Z","comments":true,"path":"2022/09/14/cloudnative/perf_analyse/","link":"","permalink":"https://blazehu.github.io/2022/09/14/cloudnative/perf_analyse/","excerpt":"业务上云迁移至腾讯云 Serverless 集群后，使用perf生成服务器的火焰图。","text":"业务上云迁移至腾讯云 Serverless 集群后，使用perf生成服务器的火焰图。背景业务模块使用的基础镜像是Ubuntu20.04，上云前的做法是在机器上docker run的，命令如下：docker run --cap-add CAP_SYS_ADMIN --privileged=true --pid=container:$&#123;targetContainerId&#125; --network=container:$&#123;targetContainerId&#125; $&#123;image&#125;:$&#123;imageTag&#125; -ti ...上云后通过在 Pod 中的容器之间共享进程命名空间的方式实现，在业务Pod中注入一个用于perf分析的容器。安装 perfapt-get install linux-tools-genericln -s /usr/lib/linux-tools/5.4.0-125-generic/perf /usr/bin/perf注意事项安装 linux-tools-generic 完成后，需要建立软链接，不然查看 perf版本，会提示如下报错信息。root@game-server-6-6f446dcxxx-5j45b:~# perfWARNING: perf not found for kernel 5.4.119-1 You may need to install the following packages for this specific kernel: linux-tools-5.4.119-1-tlinux4-0009-public-eks linux-cloud-tools-5.4.119-1-tlinux4-0009-public-eks You may also want to install one of the following packages to keep up to date: linux-tools-tlinux4-0009-public-eks linux-cloud-tools-tlinux4-0009-public-eks这里报错其实是因为perf已经内置在linux-tools-generic里面，所以我们安装后创建perf软链接即可（5.4.0-125-generic 版本目录根据实际情况替换即可）。使用 perf 生成火焰图pod 共享进程命名空间使用 Pod .spec 中的 shareProcessNamespace 字段可以启用进程命名空间共享，官方例子：apiVersion: v1kind: Podmetadata: name: nginxspec: shareProcessNamespace: true containers: - name: nginx image: nginx - name: shell image: busybox:1.28 securityContext: capabilities: add: - SYS_PTRACE privileged: true stdin: true tty: true注意事项我们需要在 perf 容器中分析业务容器 gamesvr，这个操作需要 SYS_PTRACE 权能。所以我们需要为 perf Container 设置权能。通过安全上下文（Security Context）定义 Pod 或 Container 的特权与访问控制设置。这里列举部分能力：CAP_SYS_MODULE: 允许插入和删除内核模块CAP_SYS_RAWIO: 允许直接访问/devport,/dev/mem,/dev/kmem及原始块设备CAP_SYS_CHROOT: 允许使用chroot()系统调用CAP_SYS_PTRACE: 允许跟踪任何进程CAP_SYS_PACCT: 允许执行进程的BSD式审计我们使用 perf来分析业务进程，所以需要 CAP_SYS_PTRACE 权能。Linux Capabilities 的定义的形式为 CAP_XXX。但是你在 Container 字段使用时，需要将名称中的 CAP_ 部分去掉。例如，要添加 CAP_SYS_PTRACE，可在 capabilities 列表中添加 SYS_PTRACE。perf 容器注入我这里工作负载是使用的 deployment，通过 openkruise sidecarset 注入，这里就不赘述。注入完成后我们 exec 进入 perf 容器，执行 ps -ef 可以看到业务容器的进程 gamesvr 的进程ID是13。root@game-server-6-6f446dcxxx-5j45b:~# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 19:29 ? 00:00:00 /pauseroot 13 0 6 19:29 ? 00:02:37 /root/example/bin/gamesvrroot 26 0 0 19:29 ? 00:00:00 sleep 9droot 786 0 0 20:02 pts/0 00:00:00 /bin/bashroot 855 842 0 20:11 pts/1 00:00:00 ps -efperf 分析执行 perf record -F 99 -g -m 1 -p ${targetContainerId} -- sleep 120，targetContainerId 是业务进程ID。root@game-server-6-6f446dcxxx-5j45b:~# perf record -F 99 -g -m 1 -p 13 -- sleep 120[ perf record: Woken up 65 times to write data ][ perf record: Captured and wrote 0.148 MB perf.data (524 samples) ]查看分析文件root@game-server-6-6f446dcxxx-5j45b:~# perf report -i perf.data &gt; perf.txt生成火焰图，这里会用到火焰图工具。root@game-server-6-6f446dcxxx-5j45b:~# git clone https://github.com/brendangregg/FlameGraph.gitroot@game-server-6-6f446dcxxx-5j45b:~# perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl &gt; demo.svg这里生成的 demo.svg 就是我们需要的火焰图（下面是一个例图）。开发可以通过火焰图来查看看服务的性能热点。总结这里协助开发使用 perf 生成火焰图的过程中遇到了2个问题，一是安装 perf 装不上报错，二是由于 perf 容器没有 SYS_PTRACE 权能导致生成的分析数据没有函数名称（只有地址信息）。通过协助排查问题加深了对 k8s Security Context的理解。参考文档https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/security-context/https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/share-process-namespace/https://www.cnblogs.com/iamfy/archive/2012/09/20/2694977.htmlhttps://github.com/brendangregg/FlameGraph","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"perf","slug":"perf","permalink":"https://blazehu.github.io/tags/perf/"}]},{"title":"Ubuntu20.04 安装 perf 报错","slug":"ops/linux/ubuntu_install_perf","date":"2022-09-12T16:00:00.000Z","updated":"2025-09-23T02:42:15.462Z","comments":true,"path":"2022/09/13/ops/linux/ubuntu_install_perf/","link":"","permalink":"https://blazehu.github.io/2022/09/13/ops/linux/ubuntu_install_perf/","excerpt":"在Ubuntu20.04系统中安装perf工具时出现的报错问题及解决方法。","text":"在Ubuntu20.04系统中安装perf工具时出现的报错问题及解决方法。背景尝试安装perf生成服务器的火焰图，安装perf后报错，安装命令如下：apt-get install linux-tools-generic安装完成后查看perf版本，发现报错如下解决方案其实perf已经内置在linux-tools-generic里面，所以安装后创建perf软链接即可（5.4.0-125-generic 版本目录根据实际情况替换即可）ln -s /usr/lib/linux-tools/5.4.0-125-generic/perf /usr/bin/perf","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"perf","slug":"perf","permalink":"https://blazehu.github.io/tags/perf/"}]},{"title":"蓝盾插件问题排查小记","slug":"devops/landun_plugins_ipapk","date":"2022-08-20T16:00:00.000Z","updated":"2025-08-15T03:54:52.975Z","comments":true,"path":"2022/08/21/devops/landun_plugins_ipapk/","link":"","permalink":"https://blazehu.github.io/2022/08/21/devops/landun_plugins_ipapk/","excerpt":"2021年给开发商做了一个移动端版本体验，最近开发商反馈当上传的文件比较大时经常失败。","text":"2021年给开发商做了一个移动端版本体验，最近开发商反馈当上传的文件比较大时经常失败。背景用户报障说蓝盾插件使用经常失败。问题分析插件执行报错报错日志内容如下：2022-06-28 16:44:19:202 : OverflowError: string longer than 2147483647 bytes2022-06-28 16:44:19:362 : ##[error] 2022-06-28 16:44:19:362 : Fail to run the plugin because of error(Process exited with an error: 1)2022-06-28 16:44:19:364 : ##[warning]No output日志报错分析：该插件是用来上传文件的，使用 requests 库来上传文件，这里报错信息是说明插件上传的文件太大。之前没有考虑到文件太大的情况。修复后偶尔报错超时504日志报错分析：插件日志504，重试了3次。查看后端服务日志发现业务逻辑正常处理完毕，但是请求返回时 write: broken pipe。这里的报错可以基本判断是由于请求处理时间过长，当后端服务返回时 CLB 已经断开了连接。请求调用链路蓝盾插件 -&gt; 腾讯云CLB -&gt; 后端服务（CVM上跑的docker）腾讯云CLB监控排查到这里可以确定问题根因：CLB 的超时导致的504。解决方案插件上传报错解决方案插件侧优化代码使用 requests-toolbelt 上传文件。同时修改 CLB个性化配置 支持超过2G的大文件上传，不缓存客户端请求体。client_max_body_size 5120M;proxy_request_buffering off;keepalive_timeout 900s;超时问题解决方案修改 CLB个性化配置 ，修改超时设置。这里主要修改 proxy_read_timeout。NOTE: proxy_read_timeout 是控制 CLB 至后端服务之间的超时时间。proxy_read_timeout 900s","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"}],"tags":[{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"},{"name":"腾讯云","slug":"腾讯云","permalink":"https://blazehu.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"}]},{"title":"Kubebuilder Webhook 开发之创建 TLS 证书","slug":"cloudnative/k8s_csr_tls","date":"2022-08-15T16:00:00.000Z","updated":"2025-03-24T13:20:20.027Z","comments":true,"path":"2022/08/16/cloudnative/k8s_csr_tls/","link":"","permalink":"https://blazehu.github.io/2022/08/16/cloudnative/k8s_csr_tls/","excerpt":"在编写一个准入 Webhook 服务时，需要配置相关证书，k8s 提供了 api 用于对用户自主创建的证书进行认证签发。以下部分演示为 Webhook 服务创建 TLS 证书。","text":"在编写一个准入 Webhook 服务时，需要配置相关证书，k8s 提供了 api 用于对用户自主创建的证书进行认证签发。以下部分演示为 Webhook 服务创建 TLS 证书。创建 TLS 证书创建你的证书通过运行以下命令生成私钥:cat &lt;&lt;EOF | cfssl genkey - | cfssljson -bare server&#123; \"hosts\": [ \"my-svc.my-namespace.svc.cluster.local\", \"my-pod.my-namespace.pod.cluster.local\", \"192.0.2.24\", \"10.0.34.2\" ], \"CN\": \"my-pod.my-namespace.pod.cluster.local\", \"key\": &#123; \"algo\": \"ecdsa\", \"size\": 256 &#125;&#125;EOF此命令生成两个文件；它生成包含 PEM 编码 PKCS#10 证书请求的 server.csr， 以及 PEM 编码密钥的 server-key.pem，用于待生成的证书。创建证书签名请求（CSR）cat &lt;&lt;EOF | kubectl apply -f -apiVersion: certificates.k8s.io/v1beta1kind: CertificateSigningRequestmetadata: name: examplespec: request: $(cat server.csr | base64 | tr -d '\\n') usages: - digital signature - key encipherment - server authEOF你能看到的输出类似于：certificatesigningrequest.certificates.k8s.io/example createdWarning: certificates.k8s.io/v1beta1 CertificateSigningRequest is deprecated in v1.19+, unavailable in v1.22+; use certificates.k8s.io/v1 CertificateSigningRequestCSR 处于 Pending 状态。执行下面的命令你将可以看到：kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONexample 17s kubernetes.io/legacy-unknown 100015926370-1650441195 Pending批准证书签名请求（CSR）kubectl certificate approve examplecertificatesigningrequest.certificates.k8s.io/example approved你现在应该能看到如下输出：kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONexample 5m4s kubernetes.io/legacy-unknown 100015926370-1650441195 Approved,Issued下载证书并使用它kubectl get csr example -o jsonpath='&#123;.status.certificate&#125;' | base64 --decode &gt; server.crt现在你可以将 server.crt 和 server-key.pem 作为你的服务的 https 认证了。例如 kubebuilder 中使用 TLS 证书，将 server.crt 和 server-key.pem 放在 cert 目录中并修改名称为 tls.crt 和 tls.key，然后指定证书目录：mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options&#123; Scheme: scheme, MetricsBindAddress: metricsAddr, Port: 9443, HealthProbeBindAddress: probeAddr, LeaderElection: enableLeaderElection, LeaderElectionID: \"27e1b0af.blazehu.com\", CertDir: \"./cert/\", &#125;)从 v1beta1 迁移到 v1上述例子使用 certificates.k8s.io/v1beta1 API 版本的 CertificateSigningRequest 不在 v1.22 版本中继续提供。官方迁移指南点这里。 我们可以使用 certificates.k8s.io/v1 API 版本，此 API 从 v1.19 版本开始可用。certificates.k8s.io/v1 中需要额外注意的变更：对于请求证书的 API 客户端而言：spec.signerName 现在变成必需字段（参阅 已知的 Kubernetes 签署者）， 并且通过 certificates.k8s.io/v1 API 不可以创建签署者为 kubernetes.io/legacy-unknown 的请求spec.usages 现在变成必需字段，其中不可以包含重复的字符串值， 并且只能包含已知的用法字符串创建你的证书通过运行以下命令生成私钥:cat &lt;&lt;EOF | cfssl genkey - | cfssljson -bare server&#123; \"hosts\": [ \"my-svc.my-namespace.svc.cluster.local\", \"my-pod.my-namespace.pod.cluster.local\", \"192.0.2.24\", \"10.0.34.2\" ], \"CN\": \"my-pod.my-namespace.pod.cluster.local\", \"key\": &#123; \"algo\": \"ecdsa\", \"size\": 256 &#125;&#125;EOF创建证书签名请求（CSR）这里 csr signerName 不能是 kubernetes.io/legacy-unknown，演示我们随便指定一个为 example.com/serving，v1beta1 版本默认是 kubernetes.io/legacy-unknown。cat &lt;&lt;EOF | kubectl apply -f -apiVersion: certificates.k8s.io/v1kind: CertificateSigningRequestmetadata: name: examplespec: request: $(cat server.csr | base64 | tr -d '\\n') signerName: example.com/serving usages: - digital signature - key encipherment - server authEOF批准证书签名请求（CSR）kubectl certificate approve examplecertificatesigningrequest.certificates.k8s.io/example approved你现在应该能看到如下输出：kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONexample 11s example.com/serving 100015926370-1650441195 Approved这里可以看到证书请求已被批准，但是没有自动签名，正在等待请求的签名者对其签名。签名证书签名请求（CSR）我们扮演证书签署者的角色，颁发证书并将其上传到 API 服务器。创建证书颁发机构通过运行以下命令创建签名证书:cat &lt;&lt;EOF | cfssl gencert -initca - | cfssljson -bare ca&#123; \"CN\": \"example.com/serving\", \"key\": &#123; \"algo\": \"rsa\", \"size\": 2048 &#125;&#125;EOF这会产生一个证书颁发机构密钥文件（ca-key.pem）和证书（ca.pem）。颁发证书创建文件 server-signing-config.json 内容如下：&#123; \"signing\": &#123; \"default\": &#123; \"usages\": [ \"digital signature\", \"key encipherment\", \"server auth\" ], \"expiry\": \"876000h\", \"ca_constraint\": &#123; \"is_ca\": false &#125; &#125; &#125;&#125;使用 server-signing-config.json 签名配置、证书颁发机构密钥文件和证书来签署证书请求：kubectl get csr example -o jsonpath='&#123;.spec.request&#125;' | \\ base64 --decode | \\ cfssl sign -ca ca.pem -ca-key ca-key.pem -config server-signing-config.json - | \\ cfssljson -bare ca-signed-server这会生成一个签名的服务证书文件，ca-signed-server.pem。上传签名证书kubectl get csr example -o json | \\ jq '.status.certificate = \"'$(base64 ca-signed-server.pem | tr -d '\\n')'\"' | \\ kubectl replace --raw /apis/certificates.k8s.io/v1/certificatesigningrequests/example/status -f -批准 CSR 并上传签名证书后，你现在应该能看到如下输出：kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONexample 10m example.com/serving 100015926370-1650441195 Approved,Issued这是你可以正常下载证书并使用它了。参考文档https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/certificate-signing-requests/https://kubernetes.io/zh-cn/docs/tasks/tls/managing-tls-in-a-cluster/#configuring-your-cluster-to-provide-signinghttps://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"kubebuilder","slug":"kubebuilder","permalink":"https://blazehu.github.io/tags/kubebuilder/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"}]},{"title":"Kubebuilder Watching Resources","slug":"cloudnative/kubebuilder_watch_resource","date":"2022-07-07T16:00:00.000Z","updated":"2025-03-24T13:20:26.607Z","comments":true,"path":"2022/07/08/cloudnative/kubebuilder_watch_resource/","link":"","permalink":"https://blazehu.github.io/2022/07/08/cloudnative/kubebuilder_watch_resource/","excerpt":"我们在开发过程中，可能需要开发一个类似Deployment的资源逻辑，管理依赖资源是控制器的基础，如果不能观察它们的状态变化就不可能管理它们。这就意味着，我们需要 reconciler 能监控多个资源的变化。","text":"我们在开发过程中，可能需要开发一个类似Deployment的资源逻辑，管理依赖资源是控制器的基础，如果不能观察它们的状态变化就不可能管理它们。这就意味着，我们需要 reconciler 能监控多个资源的变化。NOTE: Deployment 必须知道其管理的 ReplicaSet 何时更改，ReplicaSet 必须知道其管理的 Pod 何时被删除，或者从健康变为不健康等。控制器运行时库为管理和监视资源提供了多种方式。这包括从简单而明显的用例（例如查看由控制器创建和管理的资源）到更独特和更高级的用例。控制器创建和管理的资源 (Watching Operator Managed Resources)外部管理的资源 (Watching Externally Managed Resources)背景以 Tcaplus 资源为例，Tcaplus 资源通过 ConfigMap（proto 文件）来创建表格。当 ConfigMap 发生变化时自动更新表格，下面例子不实际调用腾讯云API，只要验证接收到事件请求即可。NOTE: TcaplusDB 是腾讯出品的分布式NoSQL数据库。官方API文档：https://cloud.tencent.com/document/product/596/39648。控制器创建和管理的资源资源定义 (Defined Tcaplus Resources)api/v1/tcaplus_types.gotype TcaplusSpec struct &#123; Checksum string `json:\"checksum,omitempty\"` ConfigMapTemplate ConfigMapTemplate `json:\"configMapTemplate,omitempty\"`&#125;type ConfigMapTemplate struct &#123; Name string `json:\"name,omitempty\"` Data map[string]string `json:\"data,omitempty\"`&#125;控制器逻辑 (Manage the Owned Resource)controllers/tcaplus_controller.go当 tcaplus CR 创建时根据 ConfigMapTemplate 创建附属的 ConfigMap 资源并设置属主关系。Reconcile 方法：根据模版创建 ConfigMap 并设置属主关系SetupWithManager 方法：For 方法之后调用 Owns 方法func (r *TcaplusReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) &#123; logger := log.FromContext(ctx) logger.Info(\"reconciling\") tcaplus := &amp;examplev1.Tcaplus&#123;&#125; if err := r.Get(ctx, req.NamespacedName, tcaplus); err != nil &#123; return ctrl.Result&#123;&#125;, client.IgnoreNotFound(err) &#125; configMap := &amp;corev1.ConfigMap&#123;&#125; configMap.Name = tcaplus.Spec.ConfigMapTemplate.Name configMap.Namespace = tcaplus.Namespace configMap.Data = tcaplus.Spec.ConfigMapTemplate.Data if err := controllerutil.SetControllerReference(tcaplus, configMap, r.Scheme); err != nil &#123; logger.Error(err, \"get configmap failed\", \"configmap\", configMap.Name) return ctrl.Result&#123;&#125;, err &#125; foundConfigMap := &amp;corev1.ConfigMap&#123;&#125; err := r.Get(ctx, types.NamespacedName&#123;Name: configMap.Name, Namespace: tcaplus.Namespace&#125;, foundConfigMap) if err != nil &amp;&amp; errors.IsNotFound(err) &#123; logger.V(1).Info(\"creating configmap\", \"configmap\", configMap.Name) err = r.Create(ctx, configMap) &#125; return ctrl.Result&#123;&#125;, nil&#125;// SetupWithManager sets up the controller with the Manager.func (r *TcaplusReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; return ctrl.NewControllerManagedBy(mgr). For(&amp;examplev1.Tcaplus&#123;&#125;). Owns(&amp;corev1.ConfigMap&#123;&#125;). Complete(r)&#125;NOTE：同一控制器创建的资源才可以设置属主关系，不然会提示：already owned by another controller。测试config/samples/example_v1_tcaplus.yamlapiVersion: example.blazehu.com/v1kind: Tcaplusmetadata: name: tcaplus-samplespec: checksum: \"123\" configMapTemplate: name: \"tcaplus-configmap-example\" data: demo.proto: | syntax = \"proto3\"; package example; message Example &#123; uint32 a = 1; uint32 b = 2; uint32 c = 3; &#125;使用上述配置文件创建 tcaplus 资源。创建结果：BLAZEHU-MB2:samples $ k get tcaplusNAME AGEtcaplus-sample 19mBLAZEHU-MB2:samples $ k get configmapNAME DATA AGEtcaplus-configmap-example 1 19m可以查看 tcaplus-configmap-example 的属主关系：apiVersion: v1data: demo.proto: | syntax = \"proto3\"; package example; message Example &#123; uint32 a = 1; uint32 b = 2; &#125;kind: ConfigMapmetadata: creationTimestamp: \"2022-07-07T09:02:43Z\" name: tcaplus-configmap-example namespace: default ownerReferences: - apiVersion: example.blazehu.com/v1 blockOwnerDeletion: true controller: true kind: Tcaplus name: tcaplus-sample uid: 7c50f2e1-0e37-4aa0-bf49-c2d410d6153e resourceVersion: \"6837330713\" selfLink: /api/v1/namespaces/default/configmaps/tcaplus-configmap-example uid: 6c29f90b-0e51-4d9f-a6a8-cfb6906ed1b0手动修改 tcaplus-sample 和 tcaplus-configmap-example 后查看控制器日志发现能正常观察 CR 和 ConfigMap 的变化了。外部管理的资源资源定义 (Defined Tcaplus Resources)api/v1/tcaplus_types.gotype TcaplusSpec struct &#123; Checksum string `json:\"checksum,omitempty\"` ConfigMapRef ConfigMapReference `json:\"configMapRef,omitempty\"`&#125;type ConfigMapReference struct &#123; Name string `json:\"name,omitempty\"`&#125;控制器逻辑 (Manage the Owned Resource)controllers/tcaplus_controller.goFor 方法之后调用 Watches 方法就可以监听对应资源的事件，但是会监听集群里所有相关资源的事件，所以这里我们自定义事件处理方法来过滤出我们关注的资源的事件。通过 EnqueueRequestsFromMapFunc 创建一个事件处理方法，该方法通过 FieldSelector 在 ConfigMap 的事件中过滤出跟 tcaplus CR 相关联的事件。使用 FieldSelector 时我们需要建立对应的索引，使用 mgr.GetFieldIndexer().IndexField() 创建。const ( ConfigMapField = \".spec.configMapRef.name\")func (r *TcaplusReconciler) findObjectsForConfigMap(configMap client.Object) []reconcile.Request &#123; attachedTcaplusList := &amp;examplev1.TcaplusList&#123;&#125; listOps := &amp;client.ListOptions&#123; FieldSelector: fields.OneTermEqualSelector(ConfigMapField, configMap.GetName()), Namespace: configMap.GetNamespace(), &#125; err := r.List(context.TODO(), attachedTcaplusList, listOps) if err != nil &#123; return []reconcile.Request&#123;&#125; &#125; requests := make([]reconcile.Request, len(attachedTcaplusList.Items)) for i, item := range attachedTcaplusList.Items &#123; requests[i] = reconcile.Request&#123; NamespacedName: types.NamespacedName&#123; Name: item.GetName(), Namespace: item.GetNamespace(), &#125;, &#125; &#125; return requests&#125;// SetupWithManager sets up the controller with the Manager.func (r *TcaplusReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; if err := mgr.GetFieldIndexer().IndexField(context.Background(), &amp;examplev1.Tcaplus&#123;&#125;, ConfigMapField, func(rawObj client.Object) []string &#123; tcaplus := rawObj.(*examplev1.Tcaplus) if tcaplus.Spec.ConfigMapRef.Name == \"\" &#123; return nil &#125; return []string&#123;tcaplus.Spec.ConfigMapRef.Name&#125; &#125;); err != nil &#123; return err &#125; return ctrl.NewControllerManagedBy(mgr). For(&amp;examplev1.Tcaplus&#123;&#125;). Watches( &amp;source.Kind&#123;Type: &amp;corev1.ConfigMap&#123;&#125;&#125;, handler.EnqueueRequestsFromMapFunc(r.findObjectsForConfigMap), builder.WithPredicates(predicate.ResourceVersionChangedPredicate&#123;&#125;), ). Complete(r)&#125;上面 ConfigMap 监听使用默认的 Predicates 过滤器 ResourceVersionChangedPredicate，查看源码定义就是说当 resource version 变化时事件会入队。// ResourceVersionChangedPredicate implements a default update predicate function on resource version change.type ResourceVersionChangedPredicate struct &#123; Funcs&#125;NOTE: 我们也可以自己定一个变更过滤器 Predicate。也可以通过 WithEventFilter 来针对监听的所有资源过滤。测试config/samples/example_v1_tcaplus.yamlapiVersion: v1kind: ConfigMapmetadata: name: tcaplus-configmap-exampledata: demo.proto: | syntax = \"proto3\"; package example; message Example &#123; uint32 a = 1; uint32 b = 2; uint32 c = 3; &#125;---apiVersion: example.blazehu.com/v1kind: Tcaplusmetadata: name: tcaplus-samplespec: checksum: \"123\" configMapRef: name: \"tcaplus-configmap-example\"使用上述配置创建完毕后，手动修改 tcaplus-sample 和 tcaplus-configmap-example 查看控制器日志发现同样能正常观察 CR 和 ConfigMap 的变化。NOTE: 查看 tcaplus-configmap-example 可以看到没有和 tcaplus 的属主关系。总结EventHandler 可以在 watch 特定资源时设置该资源的事件监听规则。WithEventFilter 配置变更过滤器，可以针对 watch 的所有资源，统一地设置事件监听规则。Owns 源码分析可以发现 Owns 相当于调用 Watches(&amp;source.Kind{Type: &lt;ForType-forInput&gt;}, &amp;handler.EnqueueRequestForOwner{OwnerType: apiType, IsController: true})。参考文档https://www.kubebuilder.io/reference/watching-resources.htmlhttps://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/owners-dependents/https://segmentfault.com/a/1190000020359577","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"kubebuilder","slug":"kubebuilder","permalink":"https://blazehu.github.io/tags/kubebuilder/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"}]},{"title":"Kubebuilder Admission Webhooks","slug":"cloudnative/kubebuilder_admission_webhooks","date":"2022-04-11T16:00:00.000Z","updated":"2025-08-15T06:43:49.510Z","comments":true,"path":"2022/04/12/cloudnative/kubebuilder_admission_webhooks/","link":"","permalink":"https://blazehu.github.io/2022/04/12/cloudnative/kubebuilder_admission_webhooks/","excerpt":"","text":"1. 什么是准入控制?准入控制（Admission Controller）是 Kubernetes API Server 用于拦截请求的一种手段。Admission 可以做到对请求的资源对象进行校验，修改。service mesh 最近很火的项目 Istio 天生支持 Kubernetes，利用的就是 Admission 对服务实例自动注入 sidecar。2. 什么是准入 Webhook？准入 Webhook 是一种用于接收准入请求并对其进行处理的 HTTP 回调机制。 可以定义两种类型的准入 webhook，即 验证性质的准入 Webhook 和 修改性质的准入 Webhook。修改性质的准入 Webhook 会先被调用。它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作。在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后， 验证性质的 Webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。说明： 如果准入 Webhook 需要保证它们所看到的是对象的最终状态以实施某种策略。 则应使用验证性质的准入 Webhook，因为对象被修改性质 Webhook 看到之后仍然可能被修改。3. 尝试准入 Webhook先决条件确保 Kubernetes 集群版本至少为 v1.16（以便使用 admissionregistration.k8s.io/v1 API） 或者 v1.9 （以便使 admissionregistration.k8s.io/v1beta1 API）。确保启用 MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook 控制器。 这里是一组推荐的 admission 控制器，通常可以启用。确保启用了 admissionregistration.k8s.io/v1beta1 API。4. 配置准入 Webhook你可以通过 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些准入 Webhook 处理。详细配置可以参阅 Webhook配置 部分。5. 认证和信任默认情况下，apiserver不会向webhooks进行身份验证。但是，如果您想对客户端进行身份验证，可以将apiserver配置为使用基本身份验证、承载令牌或证书对Webhook进行身份验证。你可以在这里找到详细的步骤。6. 编写一个准入 Webhook 服务器Webhook Admission 属于同步调用，需要用户部署自己的 webhook server，创建自定义的配置资源对象： ValidatingWebhookConfiguration 或 MutatingWebhookConfiguration。下面使用 kubebuilder 开发一个简单的 demo。6.1 创建项目kubebuilder init --domain blazehu.com --owner \"blazehu\" --repo blazehu.com/kubegame提示： 这里通过 kubebuilder v3 创建的话，在 config 目录下会缺少 certmanager、webhook 目录以及 default/manager_webhook_patch.yml 和 webhookcainjection_patch.yaml 文件。可以通过从v2生成拷贝过来进行修改。6.2 创建控制器这里只需要创建一个控制器kubebuilder create api --group svc --version v1 --kind App6.3 创建 webhookImplement Your Handler新增 mutatingwebhook.go &amp; validatingwebhook.go 文件// mutatingwebhook.gopackage controllersimport ( \"context\" \"encoding/json\" corev1 \"k8s.io/api/core/v1\" \"net/http\" \"sigs.k8s.io/controller-runtime/pkg/client\" \"sigs.k8s.io/controller-runtime/pkg/webhook/admission\")// +kubebuilder:webhook:admissionReviewVersions=v1,sideEffects=None,path=/mutate-v1-svc,mutating=true,failurePolicy=fail,groups=\"\",resources=services,verbs=create;update,versions=v1,name=msvc.kb.io// KubeGameAnnotator annotates Podstype KubeGameAnnotator struct &#123; Client client.Client decoder *admission.Decoder&#125;// Handle adds an annotation to every incoming pods.func (a *KubeGameAnnotator) Handle(ctx context.Context, req admission.Request) admission.Response &#123; pod := &amp;corev1.Pod&#123;&#125; err := a.decoder.Decode(req, pod) if err != nil &#123; return admission.Errored(http.StatusBadRequest, err) &#125; if pod.Annotations == nil &#123; pod.Annotations = map[string]string&#123;&#125; &#125; pod.Annotations[\"example-mutating-admission-webhook\"] = \"foo\" marshaledPod, err := json.Marshal(pod) if err != nil &#123; return admission.Errored(http.StatusInternalServerError, err) &#125; return admission.PatchResponseFromRaw(req.Object.Raw, marshaledPod)&#125;// KubeGameAnnotator implements admission.DecoderInjector.// A decoder will be automatically injected.// InjectDecoder injects the decoder.func (a *KubeGameAnnotator) InjectDecoder(d *admission.Decoder) error &#123; a.decoder = d return nil&#125;// validatingwebhook.gopackage controllersimport ( \"context\" \"fmt\" corev1 \"k8s.io/api/core/v1\" \"net/http\" \"sigs.k8s.io/controller-runtime/pkg/client\" \"sigs.k8s.io/controller-runtime/pkg/webhook/admission\")// +kubebuilder:webhook:admissionReviewVersions=v1,sideEffects=None,path=/validate-v1-svc,mutating=false,failurePolicy=fail,groups=\"\",resources=services,verbs=create;update,versions=v1,name=vsvc.kb.io// KubeGameValidator validates Podstype KubeGameValidator struct &#123; Client client.Client decoder *admission.Decoder&#125;// Handle admits a pod if a specific annotation exists.func (v *KubeGameValidator) Handle(ctx context.Context, req admission.Request) admission.Response &#123; pod := &amp;corev1.Pod&#123;&#125; err := v.decoder.Decode(req, pod) if err != nil &#123; return admission.Errored(http.StatusBadRequest, err) &#125; key := \"example-mutating-admission-webhook\" anno, found := pod.Annotations[key] if !found &#123; return admission.Denied(fmt.Sprintf(\"missing annotation %s\", key)) &#125; if anno != \"foo\" &#123; return admission.Denied(fmt.Sprintf(\"annotation %s did not have value %q\", key, \"foo\")) &#125; return admission.Allowed(\"\")&#125;// KubeGameValidator implements admission.DecoderInjector.// A decoder will be automatically injected.// InjectDecoder injects the decoder.func (v *KubeGameValidator) InjectDecoder(d *admission.Decoder) error &#123; v.decoder = d return nil&#125;注意：因为上述逻辑需要services权限，所以我们在控制器里需要添加如下内容 //+kubebuilder:rbac:groups=&quot;&quot;,resources=services,verbs=get;list;watch;create;update;patch;delete 用于生成 rbac manifests。Register Your Handler修改 main.go ，注册我们的 webhook handlersetupLog.Info(\"setting up webhook server\")hookServer := mgr.GetWebhookServer()setupLog.Info(\"registering webhooks to the webhook server\")hookServer.Register(\"/mutate-v1-svc\", &amp;webhook.Admission&#123;Handler: &amp;controllers.KubeGameAnnotator&#123;Client: mgr.GetClient()&#125;&#125;)hookServer.Register(\"/validate-v1-svc\", &amp;webhook.Admission&#123;Handler: &amp;controllers.KubeGameValidator&#123;Client: mgr.GetClient()&#125;&#125;)提示： 这里注册的path（例如 validate-v1-sv）路径需要和 validatingwebhook.go 、mutatingwebhook.go 文件里的 CRD validation 匹配，不然 kustomize 生成出来的 webhook yaml 文件不对。本地测试make run 会报如下错误，是因为没有证书导致，需要配置证书，可以手动签发证书。1.646924212701068e+09 ERROR setup problem running manager &#123;\"error\": \"open /var/folders/67/375276sx6hv0nln1whwm5syh0000gq/T/k8s-webhook-server/serving-certs/tls.crt: no such file or directory\"&#125;我本地指定证书目录：mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options&#123; Scheme: scheme, MetricsBindAddress: metricsAddr, Port: 9443, HealthProbeBindAddress: probeAddr, LeaderElection: enableLeaderElection, LeaderElectionID: \"27e1b0af.blazehu.com\", CertDir: \"./cert/\", &#125;)重新启动发现恢复正常提示： run controller-gen rbac:roleName=manager-role crd webhook paths=./... output:crd:artifacts:config=config/crd/bases -w to see all available markers, or controller-gen rbac:roleName=manager-role crd webhook paths=./... output:crd:artifacts:config=config/crd/bases -h for usage7. 部署至集群7.1 部署 cert manager建议使用 certmanager 为 webhook 服务器提供证书。其他解决方案也有效，只要它们将证书放在所需的位置。安装文档点这里通过如下方式注入 caBundle :# This patch add annotation to admission webhook config and# the variables $(CERTIFICATE_NAMESPACE) and $(CERTIFICATE_NAME) will be substituted by kustomize.apiVersion: admissionregistration.k8s.io/v1kind: MutatingWebhookConfigurationmetadata: name: mutating-webhook-configuration annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME)---apiVersion: admissionregistration.k8s.io/v1kind: ValidatingWebhookConfigurationmetadata: name: validating-webhook-configuration annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME)7.2 构建镜像镜像替换：default/manager_auth_proxy_patch.yaml 文件中的 gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0 （网络慢）Dockerfile 去掉 go mod download，直接使用本地 vendor 构建 （网络慢）Dockerfile 去掉 COPY api/ api/， 因为没有创建 Resource去掉 main.go 文件中配置的证书路径make docker-build IMG=xxxxmake docker-push IMG=xxxx7.3 修改模版，然后部署修改 config/default/kustomization.yaml ， 将 webhook、certmanager 相关的注释去掉。修改 config/crd/kustomization.yaml ，将 webhook、certmanager 相关的注释去掉。修改 config/default/kustomization.yaml ， 将 crd 相关的给注释掉。make deploy IMG=xxxx部署成功：查看控制器日志：7.4 测试简单创建一个 service，webhook 会注入一个注解，并进行验证。下图可以看到成功注入。控制日志：说明：查看 MutatingWebhookConfiguration 配置可以看到 caBundle 被注入其中了。8. 总结总结下 webhook Admission 的优势：webhook 可动态扩展 Admission 能力，满足自定义客户的需求。不需要重启 API Server，可通过创建 webhook configuration 热加载 webhook admission。Reference documentationhttps://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllershttps://kubernetes.io/zh/docs/tasks/tls/managing-tls-in-a-cluster/https://book.kubebuilder.io/reference/admission-webhook.htmlhttps://github.com/kubernetes-sigs/controller-runtime/tree/master/examples/builtins","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"kubebuilder","slug":"kubebuilder","permalink":"https://blazehu.github.io/tags/kubebuilder/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"}]},{"title":"Kubebuilder Best Practices","slug":"cloudnative/kubebuilder","date":"2022-04-09T16:00:00.000Z","updated":"2025-08-15T06:38:22.190Z","comments":true,"path":"2022/04/10/cloudnative/kubebuilder/","link":"","permalink":"https://blazehu.github.io/2022/04/10/cloudnative/kubebuilder/","excerpt":"Kubebuilder is a framework for building Kubernetes APIs using custom resource definitions (CRDs).","text":"Kubebuilder is a framework for building Kubernetes APIs using custom resource definitions (CRDs).Note: kubebuilder can save us a lot of work and make developing CRDs and adminsion webhooks incredibly easy.Installation# download kubebuilder and install locally.curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH)chmod +x kubebuilder &amp;&amp; mv kubebuilder /usr/local/bin/Create a ProjectCreate a directory, and then run the init command inside of it to initialize a new project. Follows an example.[blazehu@MacBook ~]$ mkdir ~/Project/workspace-go/example[blazehu@MacBook ~]$ cd ~/Project/workspace-go/example[blazehu@MacBook ~]$ kubebuilder init --domain blazehu.com --owner \"blazehu\" --repo blazehu.com/exampleWriting kustomize manifests for you to edit...Writing scaffold for you to edit...Get controller runtime:$ go get sigs.k8s.io/controller-runtime@v0.10.0Update dependencies:$ go mod tidyNext: define a resource with:$ kubebuilder create apiIf your project is initialized within GOPATH, the implicitly called go mod init will interpolate the module path for you. Otherwise –repo=must be set.Adding a new API[blazehu@MacBook ~]$ kubebuilder create api --group cos --version v1 --kind BucketCreate Resource [y/n]yCreate Controller [y/n]yWriting kustomize manifests for you to edit...Writing scaffold for you to edit...api/v1/bucket_types.gocontrollers/bucket_controller.goUpdate dependencies:$ go mod tidyRunning make:$ make generatego: creating new go.mod: module tmpDownloading sigs.k8s.io/controller-tools/cmd/controller-gen@v0.7.0go get: added sigs.k8s.io/controller-tools v0.7.0/Users/huyuhan/Project/workspace-go/example/bin/controller-gen object:headerFile=\"hack/boilerplate.go.txt\" paths=\"./...\"Next: implement your new API and generate the manifests (e.g. CRDs,CRs) with:$ make manifestsDesigning an APIapi/v1/bucket_types.go// BucketSpec defines the desired state of Buckettype BucketSpec struct &#123; // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run \"make\" to regenerate code after modifying this file // Foo is an example field of Bucket. Edit bucket_types.go to remove/update Name string `json:\"name,omitempty\"` Region string `json:\"region,omitempty\"` ACL string `json:\"acl,omitempty\"`&#125;Implementing a controllercontrollers/cos.gopackage controllersimport ( \"context\" \"fmt\" \"github.com/tencentyun/cos-go-sdk-v5\" \"net/http\" \"net/url\")type CosStorage struct &#123; client *cos.Client accessKeyId string accessKeySecret string bucket string region string&#125;// NewCosStorage endpoint: https://cloud.tencent.com/document/product/436/6224func NewCosStorage(region, bucketName string) *CosStorage &#123; url, _ := url.Parse(fmt.Sprintf(\"https://%s.cos.%s.myqcloud.com\", bucketName, region)) accessKeyId := \"\" accessKeySecret := \"\" b := &amp;cos.BaseURL&#123;BucketURL: url&#125; client := cos.NewClient(b, &amp;http.Client&#123; Transport: &amp;cos.AuthorizationTransport&#123; SecretID: accessKeyId, SecretKey: accessKeySecret, &#125;, &#125;) return &amp;CosStorage&#123; client: client, accessKeyId: accessKeyId, accessKeySecret: accessKeySecret, region: region, bucket: bucketName, &#125;&#125;func (c *CosStorage) Put(acl string) error &#123; opt := &amp;cos.BucketPutOptions&#123; XCosACL: acl, &#125; _, err := c.client.Bucket.Put(context.Background(), opt) return err&#125;func (c *CosStorage) Delete() error &#123; _, err := c.client.Bucket.Delete(context.Background()) return err&#125;controllers/bucket_controller.gotips: Finalizers allow controllers to implement asynchronous pre-delete hooks. Let’s say you create an external resource (such as a storage bucket) for each object of your API type, and you want to delete the associated external resource on object’s deletion from Kubernetes, you can use a finalizer to do that./*Copyright 2022 blazehu.Licensed under the Apache License, Version 2.0 (the \"License\");you may not use this file except in compliance with the License.You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.*/package controllersimport ( \"context\" \"k8s.io/apimachinery/pkg/runtime\" ctrl \"sigs.k8s.io/controller-runtime\" \"sigs.k8s.io/controller-runtime/pkg/client\" \"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil\" \"sigs.k8s.io/controller-runtime/pkg/log\" cosv1 \"blazehu.com/example/api/v1\")// BucketReconciler reconciles a Bucket objecttype BucketReconciler struct &#123; client.Client Scheme *runtime.Scheme&#125;const ( bucketFinalizerName = \"bucket.cos.blazehu.com/finalizer\")//+kubebuilder:rbac:groups=cos.blazehu.com,resources=buckets,verbs=get;list;watch;create;update;patch;delete//+kubebuilder:rbac:groups=cos.blazehu.com,resources=buckets/status,verbs=get;update;patch//+kubebuilder:rbac:groups=cos.blazehu.com,resources=buckets/finalizers,verbs=update// Reconcile is part of the main kubernetes reconciliation loop which aims to// move the current state of the cluster closer to the desired state.// TODO(user): Modify the Reconcile function to compare the state specified by// the Bucket object against the actual cluster state, and then// perform operations to make the cluster state reflect the state specified by// the user.//// For more details, check Reconcile and its Result here:// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.10.0/pkg/reconcilefunc (r *BucketReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) &#123; logger := log.FromContext(ctx) bucket := &amp;cosv1.Bucket&#123;&#125; if err := r.Get(ctx, req.NamespacedName, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, client.IgnoreNotFound(err) &#125; // examine DeletionTimestamp to determine if object is under deletion if bucket.ObjectMeta.DeletionTimestamp.IsZero() &#123; // The object is not being deleted, so if it does not have our finalizer, // then lets add the finalizer and update the object. This is equivalent // registering our finalizer. if !controllerutil.ContainsFinalizer(bucket, bucketFinalizerName) &#123; controllerutil.AddFinalizer(bucket, bucketFinalizerName) if err := r.Update(ctx, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, err &#125; &#125; else &#123; if err := r.updateExternalResources(bucket); err != nil &#123; logger.Error(err, \"unable to create Bucket\") return ctrl.Result&#123;&#125;, err &#125; logger.Info(\"create Bucket succeed\") &#125; &#125; else &#123; // The object is being deleted if controllerutil.ContainsFinalizer(bucket, bucketFinalizerName) &#123; // our finalizer is present, so lets handle any external dependency if err := r.deleteExternalResources(bucket); err != nil &#123; // if fail to delete the external dependency here, return with error // so that it can be retried logger.Error(err, \"unable to delete Bucket\") return ctrl.Result&#123;&#125;, err &#125; // remove our finalizer from the list and update it. controllerutil.RemoveFinalizer(bucket, bucketFinalizerName) if err := r.Update(ctx, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, err &#125; logger.Info(\"delete Bucket succeed\") &#125; // Stop reconciliation as the item is being deleted return ctrl.Result&#123;&#125;, nil &#125; // bucket reconcile logic return ctrl.Result&#123;&#125;, nil&#125;func (r *BucketReconciler) updateExternalResources(bucket *cosv1.Bucket) error &#123; cosClient := NewCosStorage(bucket.Spec.Region, bucket.Spec.Name) return cosClient.Put(bucket.Spec.ACL)&#125;func (r *BucketReconciler) deleteExternalResources(bucket *cosv1.Bucket) error &#123; cosClient := NewCosStorage(bucket.Spec.Region, bucket.Spec.Name) return cosClient.Delete()&#125;// SetupWithManager sets up the controller with the Manager.func (r *BucketReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; return ctrl.NewControllerManagedBy(mgr). For(&amp;cosv1.Bucket&#123;&#125;). Complete(r)&#125;Test It OutInstall the CRDs into the cluster (make install)[blazehu@MacBook ~]$ make install/Users/huyuhan/Project/workspace-go/example/bin/controller-gen rbac:roleName=manager-role crd webhook paths=\"./...\" output:crd:artifacts:config=config/crd/bases/Users/huyuhan/Project/workspace-go/example/bin/kustomize build config/crd | kubectl apply -f -customresourcedefinition.apiextensions.k8s.io/buckets.cos.blazehu.com createdRun your controller (this will run in the foreground, so switch to a new terminal if you want to leave it running) (make run)[blazehu@MacBook ~]$ make run/Users/huyuhan/Project/workspace-go/example/bin/controller-gen rbac:roleName=manager-role crd webhook paths=\"./...\" output:crd:artifacts:config=config/crd/bases/Users/huyuhan/Project/workspace-go/example/bin/controller-gen object:headerFile=\"hack/boilerplate.go.txt\" paths=\"./...\"go fmt ./...go vet ./...go run ./main.go2022-01-27T22:05:30.207+0800 INFO controller-runtime.metrics metrics server is starting to listen &#123;\"addr\": \":8080\"&#125;2022-01-27T22:05:30.207+0800 INFO setup starting manager2022-01-27T22:05:30.208+0800 INFO starting metrics server &#123;\"path\": \"/metrics\"&#125;2022-01-27T22:05:30.208+0800 INFO controller.bucket Starting EventSource &#123;\"reconciler group\": \"cos.blazehu.com\", \"reconciler kind\": \"Bucket\", \"source\": \"kind source: /, Kind=\"&#125;2022-01-27T22:05:30.208+0800 INFO controller.bucket Starting Controller &#123;\"reconciler group\": \"cos.blazehu.com\", \"reconciler kind\": \"Bucket\"&#125;2022-01-27T22:05:30.309+0800 INFO controller.bucket Starting workers &#123;\"reconciler group\": \"cos.blazehu.com\", \"reconciler kind\": \"Bucket\", \"worker count\": 1&#125;Create Custom Resources (create bucket.cos.blazehu.com/bucket-sample) (cos_v1_bucket.yaml)apiVersion: cos.blazehu.com/v1kind: Bucketmetadata: name: bucket-sample namespace: blazehuspec: # TODO(user): Add fields here name: example-1251762279 region: ap-shanghai acl: privatekubectl apply -f cos_v1_bucket.yaml[blazehu@MacBook ~]$ kubectl apply -f cos_v1_bucket.yamlbucket.cos.blazehu.com/bucket-sample created[blazehu@MacBook ~]$ kubectl get bucket.cos.blazehu.com -n blazehuNAME AGEbucket-sample 17sTencent cloud console view found that the bucket was created normally.Delete Instances of Custom Resources (delete bucket.cos.blazehu.com/bucket-sample)[blazehu@MacBook ~]$ kubectl delete -f cos_v1_bucket.yamlbucket.cos.blazehu.com \"bucket-sample\" deletedTencent Cloud Console view found that the bucket has been deleted.Run It On the ClusterDeploy the controller to the cluster with image specified by IMGmake docker-build docker-push IMG=&lt;some-registry&gt;/&lt;project-name&gt;:tagmake deploy IMG=&lt;some-registry&gt;/&lt;project-name&gt;:tagUninstall CRDsTo delete your CRDs from the cluster, run make uninstallUndeploy controllerUnDeploy the controller to the cluster, run make undeployReference documentationhttps://github.com/kubernetes-sigs/kubebuilderhttps://book.kubebuilder.io/introduction.htmlhttps://kubernetes.io/docs/concepts/extend-kubernetes/operator/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"kubebuilder","slug":"kubebuilder","permalink":"https://blazehu.github.io/tags/kubebuilder/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"}]},{"title":"FluxCD GitOps Toolkit components","slug":"cloudnative/fluxcd","date":"2022-03-31T16:00:00.000Z","updated":"2025-08-15T04:21:23.881Z","comments":true,"path":"2022/04/01/cloudnative/fluxcd/","link":"","permalink":"https://blazehu.github.io/2022/04/01/cloudnative/fluxcd/","excerpt":"Flux is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy.","text":"Flux is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy.InstallInstall CLIFluxCLI安装文档Check your Kubernetes clusterflux check --preDev installFor testing purposes you can install Flux without storing its manifests in a Git repository:flux installOr using kubectl:kubectl apply -f https://github.com/fluxcd/flux2/releases/latest/download/install.yamlQuickStart.├── apps # 应用相关信息│ └── exmaple├── clusters # 集群相关配置│ ├── gitrepo.yaml # gitrepository (CR)│ ├── terraform.yaml # terraform (CR)│ ├── helm.yaml # helmrelease (CR)│ └── notification.yaml # alert &amp; provider (CR)└── infrastructure # iac 相关配置（主要是 terraform hcl 配置） ├── main.tf ├── provider.tf └── variable.tfSource ControllerThe main role of the source management component is to provide a common interface for artifacts acquisition. The source API defines a set of Kubernetes objects that cluster admins and various automated operators can interact with to offload the Git and Helm repositories operations to a dedicated controller.gitrepo.yamlapiVersion: source.toolkit.fluxcd.io/v1beta1kind: GitRepositorymetadata: name: gitrepo namespace: flux-systemspec: secretRef: name: https-credentials interval: 1m url: https://github.com/blazehu/gitops_example.git ref: branch: master---apiVersion: v1kind: Secretmetadata: name: https-credentials namespace: flux-systemtype: Opaquedata: username: xxx password: xxxsecret 主要是做 git 仓库的认证interval 是拉取 git 提交的间隔，每隔一分钟会查看 git 仓库是否会有新的提交TF ControllerTF-controller is an experimental controller for Flux to reconcile Terraform resources in the GitOps way. With the power of Flux together with Terraform, TF-controller allows you to GitOps-ify infrastructure, and application resources, in the Kubernetes and Terraform universe, at your own pace.tf configinfrastructure├── main.tf├── provider.tf└── variable.tfprovider.tfterraform &#123; required_providers &#123; tencentcloud = &#123; source = \"tencentcloudstack/tencentcloud\" version = \"1.60.5\" &#125; &#125;&#125;provider \"tencentcloud\" &#123;&#125;main.tfresource \"tencentcloud_clb_instance\" \"example\" &#123; target_region_info_region = var.region target_region_info_vpc_id = var.vpc vpc_id = var.vpc clb_name = var.clb_name network_type = \"OPEN\" project_id = 0 security_groups = [tencentcloud_security_group.sg1.id] internet_bandwidth_max_out = \"10\" internet_charge_type = \"TRAFFIC_POSTPAID_BY_HOUR\" load_balancer_pass_to_target = \"true\" lifecycle &#123; ignore_changes = [ tags, ] &#125;&#125;resource \"tencentcloud_security_group\" \"sg1\" &#123; description = \"默认安全组\" name = \"example-sg1\" project_id = \"0\"&#125;resource \"tencentcloud_security_group_lite_rule\" \"sglr1\" &#123; egress = [\"ACCEPT#0.0.0.0/0#ALL#ALL\"] ingress = [\"ACCEPT#0.0.0.0/0#80,443#TCP\", \"DROP#0.0.0.0/0#ALL#ALL\"] security_group_id = tencentcloud_security_group.sg1.id&#125;output \"clb_vip\" &#123; value = tencentcloud_clb_instance.example.clb_vips[0]&#125;terraform.yamlapiVersion: infra.contrib.fluxcd.io/v1alpha1kind: Terraformmetadata: name: tf-example namespace: flux-systemspec: interval: 1m approvePlan: \"auto\" destroyResourcesOnDeletion: true path: ./infrastructure sourceRef: kind: GitRepository name: gitrepo namespace: flux-system varsFrom: - kind: Secret name: tf-secret writeOutputsToSecret: name: tf-output---apiVersion: v1kind: Secretmetadata: name: tf-secret namespace: flux-systemtype: Opaquedata: secret_id: xxx secret_key: xxx region: xxxwriteOutputsToSecret 输出相关信息至 secret 便于其他资源引用varsFrom 敏感信息通过该方式在 terraform 中引用Helm ControllerThe Helm Controller is a Kubernetes operator, allowing one to declaratively manage Helm chart releases with Kubernetes manifests.helm.yamlapiVersion: helm.toolkit.fluxcd.io/v2beta1kind: HelmReleasemetadata: name: example namespace: flux-systemspec: interval: 1m targetNamespace: blazehu releaseName: example chart: spec: chart: apps/exmaple version: \"&gt;=0.0.1\" valuesFile: ./apps/exmaple/values.yaml interval: 1m sourceRef: kind: GitRepository name: gitrepo namespace: flux-system upgrade: remediation: remediateLastFailure: true valuesFrom: - kind: Secret name: tf-output valuesKey: clb_vip targetPath: clb.serviceVIPversion: a SemVer range (i.e. &gt;=4.0.0 &lt;5.0.0) to automatically upgrade your releases when a new chart version is available in the release’s referenced HelmRepository.charts: The name or path the Helm chart is available at in the SourceRef.valuesFile: Alternative list of values files to use as the chart values.releaseName: Defaults to a composition of ‘[TargetNamespace-]Name’.targetNamespace: TargetNamespace to target when performing operations for the HelmRelease. Defaults to the namespace of the HelmRelease.Notification ControllerThe Notification Controller is a Kubernetes operator, specialized in handling inbound and outbound events.notification.yamlapiVersion: notification.toolkit.fluxcd.io/v1beta1kind: Alertmetadata: name: example-alert namespace: flux-systemspec: providerRef: name: generic eventSeverity: info eventSources: - kind: GitRepository name: gitrepo namespace: flux-system - kind: HelmRelease name: example namespace: blazehu---apiVersion: notification.toolkit.fluxcd.io/v1beta1kind: Providermetadata: name: generic namespace: flux-systemspec: type: generic address: https://hooks.slack.com/services/YOUR/SLACK/WEBHOOKReference documentationhttps://fluxcd.io/docs/components/https://weaveworks.github.io/tf-controller/","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"},{"name":"fluxcd","slug":"fluxcd","permalink":"https://blazehu.github.io/tags/fluxcd/"},{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"}]},{"title":"Terraform Controller Practices","slug":"cloudnative/terraform-controller","date":"2022-03-10T16:00:00.000Z","updated":"2025-08-15T06:50:44.837Z","comments":true,"path":"2022/03/11/cloudnative/terraform-controller/","link":"","permalink":"https://blazehu.github.io/2022/03/11/cloudnative/terraform-controller/","excerpt":"Terraform Controller is a Kubernetes Controller for Terraform.","text":"Terraform Controller is a Kubernetes Controller for Terraform.ArchitectureGet startedGithub: https://github.com/oam-dev/terraform-controllerStandalone Terraform ControllerInstall Kubernetes Terraform Controller Chart$ helm repo add kubevela-addons https://charts.kubevela.net/addons\"kubevela-addons\" has been added to your repositories$ helm upgrade --install terraform-controller -n terraform --create-namespace kubevela-addons/terraform-controllerRelease \"terraform-controller\" does not exist. Installing it now.NAME: terraform-controllerLAST DEPLOYED: Fri Mar 11 15:08:57 2022NAMESPACE: terraformSTATUS: deployedREVISION: 1TEST SUITE: None[blazehu@MacBook ~]$ kubectl get all -n terraformNAME READY STATUS RESTARTS AGEpod/terraform-controller-557d4b8869-nv28x 1/1 Running 0 22sNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/terraform-controller 1/1 1 1 22sNAME DESIRED CURRENT READY AGEreplicaset.apps/terraform-controller-557d4b8869 1 1 1 22s[blazehu@MacBook ~]$ kubectl get crd | grep terraformconfigurations.terraform.core.oam.dev 2022-03-11T07:08:27Zproviders.terraform.core.oam.dev 2022-03-11T07:08:27ZAuthenticate Cloud Provider and Create a Cloud Resource下面验证腾讯云的 cos bucket 创建和销毁，准备以下文件：.├── provider.yaml # provider 描述文件├── configuration_hcl_example.yaml # cos bucket 描述文件└── tencent-credentials.conf # 腾讯云相关 secret 信息（secretid &amp; secretkey）provider.yamlapiVersion: terraform.core.oam.dev/v1beta1kind: Providermetadata: name: tencentspec: provider: tencent region: ap-nanjing credentials: source: Secret secretRef: namespace: vela-system name: tencent-account-creds key: credentialsconfiguration_hcl_example.yamlapiVersion: terraform.core.oam.dev/v1beta1kind: Configurationmetadata: name: tencent-cos-hclspec: hcl: | terraform &#123; required_providers &#123; tencentcloud = &#123; source = \"tencentcloudstack/tencentcloud\" version = \"1.60.5\" &#125; &#125; &#125; resource \"tencentcloud_cos_bucket\" \"mycos\" &#123; bucket = \"blazehu-test-125834470x\" acl = \"private\" &#125; providerRef: name: tencenttencent-credentials.confsecretID: secretKey:create secret通过 tencent-credentials.conf 文件创建 secret ：kubectl create secret generic tencent-account-creds -n vela-system --from-file=credentials=tencent-credentials.confcreate provider[blazehu@MacBook ~]$ kubectl apply -f provider.yamlprovider.terraform.core.oam.dev/tencent created[blazehu@MacBook ~]$ kubectl get provider.terraform.core.oam.devNAME STATE AGEtencent ready 3m41screate configuration[blazehu@MacBook ~]$ kubectl apply -f configuration_hcl_example.yamlconfiguration.terraform.core.oam.dev/tencent-cos-hcl created[blazehu@MacBook ~]$ kubectl get configuration.terraform.core.oam.devNAME STATE AGEtencent-cos-hcl ProvisioningAndChecking 13sterraform-controller 会拉起 Job 跑 terraform 命令来创建，源码：[blazehu@MacBook ~]$ k get jobNAME COMPLETIONS DURATION AGEtencent-cos-hcl-apply 0/1 3s 3s[blazehu@MacBook ~]$ k get poNAME READY STATUS RESTARTS AGEtencent-cos-hcl-apply-fhpsg 1/1 Running 0 7s......[blazehu@MacBook ~]$ k get configuration.terraform.core.oam.devNAME STATE AGEtencent-cos-hcl Available 4m16s腾讯云控制台可以观测到 cos bucket 成功创建。tip: 执行成功后 state 相关内容写入了 secret 里。delete configuration[blazehu@MacBook ~]$ k delete -f configuration_hcl_example.yamlconfiguration.terraform.core.oam.dev \"tencent-cos-hcl\" deleted[blazehu@MacBook ~]$ k get jobNAME COMPLETIONS DURATION AGEtencent-cos-hcl-apply 1/1 2m55s 5m11stencent-cos-hcl-destroy 0/1 7s 7s[blazehu@MacBook ~]$ k get podNAME READY STATUS RESTARTS AGEtencent-cos-hcl-apply-qnfnx 0/1 Completed 3 3m30stencent-cos-hcl-destroy-vt5b2 0/1 Completed 0 10s腾讯云控制台可以观测到 cos bucket 已经被回收处理。优化因为每一个新的操作都是启动一个新的 Pod 去执行 terraform init...，由于网络问题， Initializing provider plugins 经常失败，于是这里使用 cache ，构建一个新的 job 镜像然后更新 release。FROM oamdev/docker-terraform:1.1.2LABEL maintainer=\"blazehu\"ENV TF_PLUGIN_CACHE_DIR /.terraform.d/plugin-cacheCOPY registry.terraform.io /.terraform.d/plugin-cache/registry.terraform.ioupgrade release[blazehu@MacBook ~]$ helm upgrade --install terraform-controller -n terraform --create-namespace kubevela-addons/terraform-controller --set terraformImage=docker-terraform:2.0tips: 也可以是用 sidecar 注入 pod 来使用 cache （openkruise）Reference documentationhttps://developer.aliyun.com/article/724349https://github.com/oam-dev/terraform-controller/blob/master/getting-started.md","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"}]},{"title":"Terraform Plugin Development","slug":"cloudnative/terraform-plugins","date":"2021-12-28T16:00:00.000Z","updated":"2025-08-15T06:48:08.466Z","comments":true,"path":"2021/12/29/cloudnative/terraform-plugins/","link":"","permalink":"https://blazehu.github.io/2021/12/29/cloudnative/terraform-plugins/","excerpt":"Terraform is an open source resource orchestration tool based on Golang, which allows users to manage and configure any infrastructure, the infrastructure of public and private cloud services, and external services.","text":"Terraform is an open source resource orchestration tool based on Golang, which allows users to manage and configure any infrastructure, the infrastructure of public and private cloud services, and external services.OverviewTerraform is logically split into two main parts:Terraform Core: This is the Terraform binary that communicates with plugins to manage infrastructure resources. It provides a common interface that allows you to leverage many different cloud providers, databases, services, and in-house solutions.Terraform Plugins: These are executable binaries written in Go that communicate with Terraform Core over an RPC interface. Each plugin exposes an implementation for a specific service, such as the AWS provider or the cloud-init provider. Terraform currently supports one type of Plugin called providers.Get StartedClone these template repositories on GitHub: terraform-provider-scaffolding (SDKv2)Steps:clone the terraform-provider-scaffolding (SDKv2).explore development environment, modify GNUmakefile.define the provider、data_source、resource schema.write code for cos bucket CRUD (internal/provider dir) and acceptance tests.test the provider.generate the provider documentation.RequirementsTerraform &gt;= 0.13.xGo &gt;= 1.15Building The ProviderTo compile the provider, run go install. This will build the provider and put the provider binary in the $GOPATH/bin directory.Generate the Provider DocumentationTo generate or update documentation, run go generate.Acceptance testsIn order to run the full suite of Acceptance tests, run make testacc.Note: Acceptance tests create real resources, and often cost money to run.Directory StructureTake cos bucket as an example, modify the directory structure as follows.terraform-provider-cos├── README.md ├── GNUmakefile├── CHANGELOG.md 变更日志├── LICENSE 授权信息 ├── main.go 程序入口文件├── docs 文档目录├── examples 示例配置文件目录├── internal Provider核心目录│ └── provider│ ├── data_source_cos_bucket.go bucket查询│ ├── data_source_cos_bucket_test.go│ ├── provider.go Provider核心文件│ ├── provider_test.go │ ├── resource_cos_bucket.go bucket资源管理│ ├── resource_cos_bucket_test.go│ └── service_cos_bucket.go 封装的bucket相关Service├── go.mod├── go.sum├── terraform-registry-manifest.json└── tools └── tools.goThe structure is mainly divided into five parts:main.go, plugin entry.provider.go, attributes used to describe plugins, such as: configured key, supported resource list, callback - configuration.data_source_*.go, read calls, mainly query interfaces.resource_*.go, write calls, including resource addition, deletion, modification and query interfaces.service_*.go, public methods divided by resource categories.Explore your development environmentTEST?=$$(go list ./... | grep -v 'vendor')HOSTNAME=blazehu.comNAMESPACE=eduNAME=cosBINARY=terraform-provider-$&#123;NAME&#125;_v$&#123;VERSION&#125;OS_ARCH=darwin_amd64VERSION=0.1#BINARY=terraform-provider-$&#123;NAME&#125;_v$&#123;VERSION&#125;.exe#OS_ARCH=windows_amd64default: testaccbuild: go build -o $&#123;BINARY&#125;test: go test -i $(TEST) || exit 1 echo $(TEST) | xargs -t -n4 go test $(TESTARGS) -timeout=30s -parallel=4# Run acceptance tests.PHONY: testacctestacc: TF_ACC=1 go test ./... -v $(TESTARGS) -timeout 120m# Install.PHONY: installinstall: build # Build manager binary. mkdir -p ~/.terraform.d/plugins/$&#123;HOSTNAME&#125;/$&#123;NAMESPACE&#125;/$&#123;NAME&#125;/$&#123;VERSION&#125;/$&#123;OS_ARCH&#125; mv $&#123;BINARY&#125; ~/.terraform.d/plugins/$&#123;HOSTNAME&#125;/$&#123;NAMESPACE&#125;/$&#123;NAME&#125;/$&#123;VERSION&#125;/$&#123;OS_ARCH&#125;Define provider schemafunc New(version string) func() *schema.Provider &#123; return func() *schema.Provider &#123; p := &amp;schema.Provider&#123; DataSourcesMap: map[string]*schema.Resource&#123; \"cos_bucket_data_source\": dataSourceCosBucket(), &#125;, ResourcesMap: map[string]*schema.Resource&#123; \"cos_bucket_resource\": resourceCosBucket(), &#125;, Schema: map[string]*schema.Schema&#123; \"secret_id\": &amp;schema.Schema&#123; Type: schema.TypeString, Required: true, Sensitive: true, DefaultFunc: schema.EnvDefaultFunc(\"SECRET_ID\", nil), &#125;, \"secret_key\": &amp;schema.Schema&#123; Type: schema.TypeString, Required: true, Sensitive: true, DefaultFunc: schema.EnvDefaultFunc(\"SECRET_KEY\", nil), &#125;, \"region\": &amp;schema.Schema&#123; Type: schema.TypeString, Required: true, Sensitive: true, DefaultFunc: schema.EnvDefaultFunc(\"REGION\", nil), &#125;, &#125;, ConfigureContextFunc: providerConfigure, &#125; return p &#125;&#125;func providerConfigure(ctx context.Context, d *schema.ResourceData) (interface&#123;&#125;, diag.Diagnostics) &#123; region := d.Get(\"region\").(string) secretId := d.Get(\"secret_id\").(string) secretKey := d.Get(\"secret_key\").(string) // Warning or errors can be collected in a slice type var diags diag.Diagnostics c := &amp;CosClient&#123; Region: region, SecretId: secretId, SecretKey: secretKey, &#125; return c, diags&#125;Define bucket data resource schemaresource_cos_bucket.gofunc resourceCosBucket() *schema.Resource &#123; return &amp;schema.Resource&#123; // This description is used by the documentation generator and the language server. Description: \"Sample resource in the Terraform provider cos.\", CreateContext: resourceCosBucketCreate, ReadContext: resourceCosBucketRead, UpdateContext: resourceCosBucketUpdate, DeleteContext: resourceCosBucketDelete, Schema: map[string]*schema.Schema&#123; \"name\": &#123; // This description is used by the documentation generator and the language server. Description: \"cos bucket name.\", Type: schema.TypeString, Required: true, &#125;, \"acl\": &#123; Description: \"cos bucket acl.\", Type: schema.TypeString, Default: \"private\", Optional: true, &#125;, \"update_at\": &#123; Description: \"cos bucket create time\", Type: schema.TypeString, Computed: true, &#125;, &#125;, &#125;&#125;data_source_cos_bucket.gofunc dataSourceCosBucket() *schema.Resource &#123; return &amp;schema.Resource&#123; // This description is used by the documentation generator and the language server. Description: \"Sample data source in the Terraform provider cos.\", ReadContext: dataSourceCosBucketRead, Schema: map[string]*schema.Schema&#123; \"name\": &#123; // This description is used by the documentation generator and the language server. Description: \"cos bucket name.\", Type: schema.TypeString, Required: true, &#125;, \"owner\": &#123; // This description is used by the documentation generator and the language server. Description: \"cos bucket owner.\", Type: schema.TypeString, Computed: true, &#125;, &#125;, &#125;&#125;Implement Complex Readfunc dataSourceCosBucketRead(ctx context.Context, d *schema.ResourceData, meta interface&#123;&#125;) diag.Diagnostics &#123; // use the meta value to retrieve your client from the provider configure method client := meta.(*CosClient) var diags diag.Diagnostics name := d.Get(\"name\").(string) owner, err := client.GetACLOwner(name) if err != nil &#123; return diag.Errorf(fmt.Sprintf(\"get cos bucket owner failed. msg: %s\", err.Error())) &#125; d.SetId(name) if err = d.Set(\"owner\", owner); err != nil &#123; tflog.Error(ctx, err.Error()) &#125; return diags&#125;Implement Createfunc resourceCosBucketCreate(ctx context.Context, d *schema.ResourceData, meta interface&#123;&#125;) diag.Diagnostics &#123; // use the meta value to retrieve your client from the provider configure method client := meta.(*CosClient) var diags diag.Diagnostics name := d.Get(\"name\").(string) acl := d.Get(\"acl\").(string) if err := client.Put(name, acl); err != nil &#123; return diag.Errorf(fmt.Sprintf(\"created cos bucket failed. msg: %s\", err.Error())) &#125; d.SetId(name) if err := d.Set(\"update_at\", time.Now().Format(time.RFC3339)); err != nil &#123; tflog.Error(ctx, err.Error()) &#125; tflog.Info(ctx, fmt.Sprintf(\"created a cos bucket, name: %s, region: %s\", name, client.Region)) // write logs using the tflog package // see https://pkg.go.dev/github.com/hashicorp/terraform-plugin-log/tflog // for more information return diags&#125;Implement Updatefunc resourceCosBucketUpdate(ctx context.Context, d *schema.ResourceData, meta interface&#123;&#125;) diag.Diagnostics &#123; // use the meta value to retrieve your client from the provider configure method client := meta.(*CosClient) var diags diag.Diagnostics if d.HasChange(\"acl\") &#123; name := d.Get(\"name\").(string) acl := d.Get(\"acl\").(string) if err := client.PutACL(name, acl); err != nil &#123; return diag.Errorf(fmt.Sprintf(\"update cos bucket acl failed. msg: %s\", err.Error())) &#125; if err := d.Set(\"update_at\", time.Now().Format(time.RFC3339)); err != nil &#123; tflog.Error(ctx, err.Error()) &#125; &#125; return diags&#125;Implement Deletefunc resourceCosBucketDelete(ctx context.Context, d *schema.ResourceData, meta interface&#123;&#125;) diag.Diagnostics &#123; // use the meta value to retrieve your client from the provider configure method client := meta.(*CosClient) var diags diag.Diagnostics name := d.Get(\"name\").(string) if err := client.Delete(name); err != nil &#123; return diag.Errorf(fmt.Sprintf(\"delete cos bucket failed. msg: %s\", err.Error())) &#125; d.SetId(\"\") tflog.Info(ctx, fmt.Sprintf(\"delete a cos bucket, name: %s\", name)) return diags&#125;Implement Cos Bucket Serviceimport ( \"context\" \"fmt\" \"github.com/tencentyun/cos-go-sdk-v5\" \"net/http\" \"net/url\")type CosClient struct &#123; SecretId string SecretKey string Region string&#125;func (c *CosClient) client(name string) *cos.Client &#123; url, _ := url.Parse(fmt.Sprintf(\"https://%s.cos.%s.myqcloud.com\", name, c.Region)) b := &amp;cos.BaseURL&#123;BucketURL: url&#125; return cos.NewClient(b, &amp;http.Client&#123; Transport: &amp;cos.AuthorizationTransport&#123; SecretID: c.SecretId, SecretKey: c.SecretKey, &#125;, &#125;)&#125;func (c *CosClient) Put(name, acl string) error &#123; opt := &amp;cos.BucketPutOptions&#123; XCosACL: acl, &#125; _, err := c.client(name).Bucket.Put(context.Background(), opt) return err&#125;func (c *CosClient) GetACLOwner(name string) (string, error) &#123; acl, _, err := c.client(name).Bucket.GetACL(context.Background()) return acl.Owner.DisplayName, err&#125;func (c *CosClient) PutACL(name, acl string) error &#123; opt := &amp;cos.BucketPutACLOptions&#123; Header: &amp;cos.ACLHeaderOptions&#123; //private，public-read，public-read-write XCosACL: acl, &#125;, &#125; _, err := c.client(name).Bucket.PutACL(context.Background(), opt) return err&#125;func (c *CosClient) Delete(name string) error &#123; _, err := c.client(name).Bucket.Delete(context.Background()) return err&#125;Test the providermake install[blazehu@MacBook ~]$ make installgo build -o terraform-provider-cos_v0.1mkdir -p ~/.terraform.d/plugins/blazehu.com/edu/cos/0.1/darwin_amd64mv terraform-provider-cos_v0.1 ~/.terraform.d/plugins/blazehu.com/edu/cos/0.1/darwin_amd64write demo.tfterraform &#123; required_providers &#123; cos = &#123; source = \"blazehu.com/edu/cos\" version = \"0.1\" &#125; &#125;&#125;provider \"cos\" &#123; region = \"ap-shanghai\"&#125;resource \"cos_bucket_resource\" \"demo\" &#123; name = \"terraform-1251762279\" acl = \"private\" # acl = \"public-read-write\"&#125;data \"cos_bucket_data_source\" \"test\" &#123; name = cos_bucket_resource.demo.id&#125;run terraform initInitializing the backend...Initializing provider plugins...- Finding blazehu.com/edu/cos versions matching \"0.1.0\"...- Installing blazehu.com/edu/cos v0.1.0...- Installed blazehu.com/edu/cos v0.1.0 (unauthenticated)Terraform has created a lock file .terraform.lock.hcl to record the providerselections it made above. Include this file in your version control repositoryso that Terraform can guarantee to make the same selections by default whenyou run \"terraform init\" in the future.Terraform has been successfully initialized!run terraform apply -auto-approve, create a cos bucketTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: + create &lt;= read (data resources)Terraform will perform the following actions: # data.cos_bucket_data_source.test will be read during apply # (config refers to values not yet known) &lt;= data \"cos_bucket_data_source\" \"test\" &#123; + id = (known after apply) + name = (known after apply) + owner = (known after apply) &#125; # cos_bucket_resource.demo will be created + resource \"cos_bucket_resource\" \"demo\" &#123; + acl = \"public-read-write\" + id = (known after apply) + name = \"terraform-1251762279\" + update_at = (known after apply) &#125;Plan: 1 to add, 0 to change, 0 to destroy.cos_bucket_resource.demo: Creating...cos_bucket_resource.demo: Creation complete after 1s [id=terraform-1251762279]data.cos_bucket_data_source.test: Reading...data.cos_bucket_data_source.test: Read complete after 0s [id=terraform-1251762279]Apply complete! Resources: 1 added, 0 changed, 0 destroyed.change acl to public-read-write, run terraform apply -auto-approvecos_bucket_resource.demo: Refreshing state... [id=terraform-1251762279]Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: ~ update in-place &lt;= read (data resources)Terraform will perform the following actions: # data.cos_bucket_data_source.test will be read during apply # (config refers to values not yet known) &lt;= data \"cos_bucket_data_source\" \"test\" &#123; ~ id = \"terraform-1251762279\" -&gt; (known after apply) name = \"terraform-1251762279\" ~ owner = \"qcs::cam::uin/794369159:uin/794369159\" -&gt; (known after apply) &#125; # cos_bucket_resource.demo will be updated in-place ~ resource \"cos_bucket_resource\" \"demo\" &#123; ~ acl = \"public-read-write\" -&gt; \"private\" id = \"terraform-1251762279\" name = \"terraform-1251762279\" # (1 unchanged attribute hidden) &#125;Plan: 0 to add, 1 to change, 0 to destroy.cos_bucket_resource.demo: Modifying... [id=terraform-1251762279]cos_bucket_resource.demo: Modifications complete after 1s [id=terraform-1251762279]data.cos_bucket_data_source.test: Reading... [id=terraform-1251762279]data.cos_bucket_data_source.test: Read complete after 0s [id=terraform-1251762279]Apply complete! Resources: 0 added, 1 changed, 0 destroyed.verify if no changes, run terraform apply -auto-approvecos_bucket_resource.demo: Refreshing state... [id=terraform-1251762279]No changes. Your infrastructure matches the configuration.Terraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.Apply complete! Resources: 0 added, 0 changed, 0 destroyed.destroy the resources, run terraform destroy -auto-approvecos_bucket_resource.demo: Refreshing state... [id=terraform-1251762279]Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: - destroyTerraform will perform the following actions: # cos_bucket_resource.demo will be destroyed - resource \"cos_bucket_resource\" \"demo\" &#123; - acl = \"private\" -&gt; null - id = \"terraform-1251762279\" -&gt; null - name = \"terraform-1251762279\" -&gt; null - update_at = \"2022-01-29T11:28:31+08:00\" -&gt; null &#125;Plan: 0 to add, 0 to change, 1 to destroy.cos_bucket_resource.demo: Destroying... [id=terraform-1251762279]cos_bucket_resource.demo: Destruction complete after 1sDestroy complete! Resources: 1 destroyed.Tip: You can also retrieve detailed Terraform and provider logs by setting the environment variable TF_LOG. Please include a detailed logs with any bug reports so the author can identify and address the bug. To learn more about log levels and how to interpret a crash log, refer to the Debugging Terraform Documentation.Reference documentationhttps://www.terraform.io/pluginhttps://learn.hashicorp.com/collections/terraform/providershttps://cloud.tencent.com/developer/article/1067230","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"}]},{"title":"Terraform Best Practices","slug":"cloudnative/terraform","date":"2021-12-04T16:00:00.000Z","updated":"2025-08-15T07:04:26.153Z","comments":true,"path":"2021/12/05/cloudnative/terraform/","link":"","permalink":"https://blazehu.github.io/2021/12/05/cloudnative/terraform/","excerpt":"Terraform是一种开源工具，用于安全高效地预览，配置和管理云基础架构和资源。","text":"Terraform是一种开源工具，用于安全高效地预览，配置和管理云基础架构和资源。一、安装 Terraform1、下载 Terraform官方提供了最新版本的Terraform 可用下载输入下载及安装命令行：# download terraformwget https://releases.hashicorp.com/terraform/1.0.10/terraform_1.0.10_linux_amd64.zip --no-check-certificate # unzip terraformunzip terraform_1.0.10_linux_amd64.zip2、 配置环境变量添加Terraform的环境变量，或者直接放在 /usr/local/bin/ 目录下二、使用 Terraform 管理腾讯云下面是Terraform管理腾讯云资源的具体方法：1、 Terraform工作流程1、 一次性配置 provider 文件以支持Tencent Cloud的 OpenAPI.2、使用Terraform配置语法生成 .tf 资源文件.3、使用CLI实现腾讯云资源的管理.Terraform会将整个资源部署情况更新在 *.tf.state 文件中，让用户在前端控制台和后端平台都清晰的把控自己的云资源。2、 配置腾讯云 provider 文件官方文档：TencentCloud Provider登录腾讯云，在访问管理中选择API秘钥管理，获得Secret_Id和Secret_Key在新目录下创建 provider.tf 文件，填入秘钥和区域信息$ vim provider.tf terraform &#123; required_providers &#123; tencentcloud = &#123; source = \"tencentcloudstack/tencentcloud\" version = \"1.60.5\" &#125; &#125;&#125; provider \"tencentcloud\" &#123; secret_id = \"*******\" secret_key = \"*******\" region = \"*******\"&#125;保存该文件，执行 terraform init 初始化Terraform。此步骤，Terraform会自动检测 provider.tf 文件中的 provider 字段，发送请求到Terraform官方GitHub下载最新版本腾讯云资源的模块和插件，初始化成功时当前脚本的版本信息也会显示出来。# Initialize$ terraform init当腾讯云脚本有新的版本发布时，可以通过 terraform init -upgrade 指令更新脚本，获取最新的应用。同时，可以通过 terraform plan 预览将要完成的操作，准备好创建资源后，可以通过 terraform apply 进行资源部署，更多有关Terraform CLI 的信息请点击这里。tips: NOTES 将秘钥直接填入到.tf文件中是十分不安全的，在多用户共同管理资源时，不建议把腾讯云API 的秘钥直接写到源代码里，以免一不小心更新到公开的版本中，造成安全风险。腾讯云提供了另一种更为安全可靠的方式，把秘钥信息放在环境变量中配置# Configure the secret key in the environment path$ export TENCENTCLOUD_SECRET_ID=\"your_accessid\"$ export TENCENTCLOUD_SECRET_KEY=\"your_accesskey\"$ export TENCENTCLOUD_REGION=\"ap-shanghai\"这样在 provider.tf 文件中就可以省略掉相关信息$ vim provider.tfprovider \"tencentcloud\" &#123;&#125;3、 部署腾讯云资源下面提供一个创建腾讯云对象存储（COS）存储桶的实际用例。创建实例资源文件resource \"tencentcloud_cos_bucket\" \"mycos\" &#123; bucket = \"mycos-1251762279\" acl = \"private\"&#125;resource \"tencentcloud_cos_bucket_object\" \"myobject\" &#123; bucket = tencentcloud_cos_bucket.mycos.bucket key = \"new_object_key\" content = \"the content that you want to upload.\"&#125;这里可以看到，上传文件至存储桶没有直接填写具体参数信息，而是引用 “tencentcloud_cos_bucket.mycos.bucket” 。执行 terraform plan 查看部署计划，一共有2个资源计划创建这里参数前面的+ 代表新添加的资源，当销毁资源时，参数前面对应的符号会变为- ；更改一些参数需要重新部署资源时，该资源前面的符号为-/+；在旧参数和新参数内容之间有→ 符号标识执行 terraform apply 进行资源创建回到控制台，可以看到刚刚部署的资源已经生效执行 terraform destroy 进行资源销毁（控制台中也同步了销毁操作）三、使用 Terraform 管理 Helm下面是Terraform管理 Helm 的具体方法：1、 配置 Helm provider 文件官方文档：Helm Provider修改 provider.tf 文件并初始化terraform &#123; required_providers &#123; tencentcloud = &#123; source = \"tencentcloudstack/tencentcloud\" version = \"1.60.5\" &#125; helm = &#123; source = \"hashicorp/helm\" version = \"2.4.0\" &#125; &#125;&#125;provider \"tencentcloud\" &#123;&#125;provider \"helm\" &#123; kubernetes &#123; config_path = \"/etc/rancher/k3s/k3s.yaml\" &#125;&#125;2、 部署 Helm Chart这里提供一个 Mysql Chart 的简单用例Helm 官方文档Artifact HubHelm Chart仓库创建实例资源文件resource \"helm_release\" \"mysql\" &#123; name = \"mysql-terraform\" chart = \"mysql\" version = \"8.8.14\" namespace = \"blazehu\" repository = \"https://charts.bitnami.com/bitnami\" set &#123; name = \"auth.rootPassword\" value = \"123456!@#\" &#125;&#125;这里可以看到通过 set 重新设置了 mysql 的 root 密码执行 terraform plan 查看部署计划，一共有3个资源计划创建执行 terraform apply 进行资源创建控制台，可以看到 Helm Chart 部署完成，且相关资源都正常启动反复执行 terraform apply 进行资源更新，可以看到资源没有变更tips：可以通过 ignore_changes 忽略部分变更的更新动作执行 terraform destroy 进行资源销毁（控制台中也同步了销毁操作）参考文档https://www.terraform.io/introhttps://cloud.tencent.com/developer/inventory/2539https://cloud.tencent.com/developer/article/1560534","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"}]},{"title":"TIC Best Practices","slug":"cloudnative/terraform_tic","date":"2021-12-03T16:00:00.000Z","updated":"2025-08-15T07:10:14.581Z","comments":true,"path":"2021/12/04/cloudnative/terraform_tic/","link":"","permalink":"https://blazehu.github.io/2021/12/04/cloudnative/terraform_tic/","excerpt":"TIC 是腾讯云推出的 IaC 开放平台，融合多种业内优秀的开源技术，通过 IaC 的方式解决您在云基础设施管理中面临的效率、成本和安全问题。","text":"TIC 是腾讯云推出的 IaC 开放平台，融合多种业内优秀的开源技术，通过 IaC 的方式解决您在云基础设施管理中面临的效率、成本和安全问题。TIC 提供了资源编排、配置管理和合规检查三大功能模块，支持 HCL（Terraform）格式语法编写，同时提供丰富的基于腾讯云最佳实践的公共模板，有效降低您的学习、使用难度。操作指南产品文档非常详细了，以下就不赘述，下面提供一个创建腾讯云对象存储（COS）存储桶的实际用例。控制台部署腾讯云资源新建资源栈创建 cos 资源描述文件创建 cos.tf 文件文件内容如下：resource \"tencentcloud_cos_bucket\" \"demo\" &#123; bucket = \"demo-1251762279\" acl = \"private\"&#125;预览结果 (terraform plan)发布 (terraform apply)回到控制台，可以看到刚刚部署的资源已经生效销毁资源，控制台对应的资源也会销毁API调用使用 API Explorer 生成代码调试地址Golang Examplepackage mainimport ( \"fmt\" \"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common\" \"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common/errors\" \"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common/profile\" tic \"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/tic/v20201117\" \"time\")func describeStacks(client *tic.Client) []*tic.StackInfo &#123; request := tic.NewDescribeStacksRequest() response, err := client.DescribeStacks(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return nil &#125; if err != nil &#123; panic(err) &#125; return response.Response.Stacks&#125;func createStack(client *tic.Client, name, region, templateUrl string) *string &#123; request := tic.NewCreateStackRequest() request.StackName = common.StringPtr(name) request.StackRegion = common.StringPtr(region) request.TemplateUrl = common.StringPtr(templateUrl) response, err := client.CreateStack(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return nil &#125; if err != nil &#123; panic(err) &#125; return response.Response.StackId&#125;func deleteStack(client *tic.Client, stackId string) &#123; request := tic.NewDeleteStackRequest() request.StackId = common.StringPtr(stackId) _, err := client.DeleteStack(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return &#125; if err != nil &#123; panic(err) &#125;&#125;func describeStackVersions(client *tic.Client) []*tic.VersionInfo &#123; request := tic.NewDescribeStackVersionsRequest() response, err := client.DescribeStackVersions(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return nil &#125; if err != nil &#123; panic(err) &#125; return response.Response.Versions&#125;func planStack(client *tic.Client, stackId, versionId string) *string &#123; request := tic.NewPlanStackRequest() request.StackId = common.StringPtr(stackId) request.VersionId = common.StringPtr(versionId) response, err := client.PlanStack(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return nil &#125; if err != nil &#123; panic(err) &#125; fmt.Printf(\"%s\\n\", response.ToJsonString()) return response.Response.EventId&#125;func applyStack(client *tic.Client, stackId, versionId string) &#123; request := tic.NewApplyStackRequest() request.StackId = common.StringPtr(stackId) request.VersionId = common.StringPtr(versionId) response, err := client.ApplyStack(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return &#125; if err != nil &#123; panic(err) &#125; fmt.Printf(\"%s\", response.ToJsonString())&#125;func describeStackEvent(client *tic.Client, eventId string) string &#123; request := tic.NewDescribeStackEventRequest() request.EventId = common.StringPtr(eventId) response, err := client.DescribeStackEvent(request) if _, ok := err.(*errors.TencentCloudSDKError); ok &#123; fmt.Printf(\"An API error has returned: %s\", err) return \"\" &#125; if err != nil &#123; panic(err) &#125; return *response.Response.Status&#125;func main() &#123; credential := common.NewCredential( \"SecretId\", \"SecretKey\", ) cpf := profile.NewClientProfile() cpf.HttpProfile.Endpoint = \"tic.tencentcloudapi.com\" client, _ := tic.NewClient(credential, \"\", cpf) region := \"ap-shanghai\" //获取资源栈列表 stacks := describeStacks(client) for _, stack := range stacks &#123; //删除资源栈 deleteStack(client, *stack.StackId) &#125; //创建资源栈 createStack(client, \"demo\", region, \"\") //获取版本列表 versions := describeStackVersions(client) for _, version := range versions &#123; fmt.Println(*version.StackId, *version.VersionId, *version.VersionName) //执行Plan事件 planStack(client, *version.StackId, *version.VersionId) //等待事件完成 time.Sleep(time.Second * 30) //执行Apply事件 applyStack(client, *version.StackId, *version.VersionId) &#125;&#125;templateUrl (⽬前仅限 COS URL)这里需要注意的是 templateUrl 参数 （模板 URL，⽬前仅限 COS URL, ⽂件为zip压缩格式），压缩为 zip 文件上传 cos。API 调用执行回到控制台，可以看到刚刚调用生效参考文档https://cloud.tencent.com/document/product/1213https://cloud.tencent.com/document/api/1213/50586","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"}]},{"title":"Helm3 简介","slug":"cloudnative/helm3","date":"2021-12-02T16:00:00.000Z","updated":"2025-08-15T06:36:45.103Z","comments":true,"path":"2021/12/03/cloudnative/helm3/","link":"","permalink":"https://blazehu.github.io/2021/12/03/cloudnative/helm3/","excerpt":"Helm is the best way to find, share, and use software built for Kubernetes.","text":"Helm is the best way to find, share, and use software built for Kubernetes.先决条件想成功和正确地使用Helm，需要以下前置条件。一个 Kubernetes 集群确定你安装版本的安全配置安装和配置Helm。三大概念Chart 代表着 Helm 包。它包含在 Kubernetes 集群内部运行应用程序，工具或服务所需的所有资源定义。你可以把它看作是 Homebrew formula，Apt dpkg，或 Yum RPM 在Kubernetes 中的等价物。Repository（仓库） 是用来存放和共享 charts 的地方。它就像 Perl 的 CPAN 档案库网络 或是 Fedora 的 软件包仓库，只不过它是供 Kubernetes 包所使用的。Release 是运行在 Kubernetes 集群中的 chart 的实例。一个 chart 通常可以在同一个集群中安装多次。每一次安装都会创建一个新的 release。以 MySQL chart为例，如果你想在你的集群中运行两个数据库，你可以安装该chart两次。每一个数据库都会拥有它自己的 release 和 release name。在了解了上述这些概念以后，我们就可以这样来解释 Helm：Helm 安装 charts 到 Kubernetes 集群中，每次安装都会创建一个新的 release。你可以在 Helm 的 chart repositories 中寻找新的 chart。安装我这里直接下载二进制文件，解压后移动到 /usr/local/bin/安装指南下载地址初始化helm repo add bitnami https://charts.bitnami.com/bitnami查看可以安装的charts列表helm search hub 从 Artifact Hub 中查找并列出 helm charts。 Artifact Hub 中存放了大量不同的仓库。helm search repo bitnami安装Chart示例由于我是用的k3s ，而 helm v3 版本不再需要 Tiller，而是直接访问ApiServer来与k8s交互，通过环境变量KUBECONFIG来读取存有ApiServer的地址与token的配置文件地址，默认地址为~/.kube/config ，所以需要配置环境变量export KUBECONFIG=/etc/rancher/k3s/k3s.yaml配置环境变量vim /etc/profileexport KUBECONFIG=/etc/rancher/k3s/k3s.yamlsource /etc/profile安装 mysqlkubectl create namespace blazehuhelm install bitnami/mysql --generate-name -n blazehuhelm show chart bitnami/mysql 获取关于该chart的基本信息helm show all bitnami/mysql 获取关于该chart的所有信息查看发布的版本卸载一个版本该命令会从Kubernetes卸载 mysql-1638628962， 它将删除和该版本相关的所有相关资源（service、deployment、 pod等等）甚至版本历史。helm uninstall 的时候提供 --keep-history 选项， Helm将会保存版本历史。 可以通过命令查看该版本的信息。访问 mysqlROOT_PASSWORD=$(kubectl get secret --namespace blazehu mysql-1638633054 -o jsonpath=\"&#123;.data.mysql-root-password&#125;\" | base64 --decode)kubectl get svc -n blazehumysql -h$&#123;HOST&#125; -uroot -p$&#123;ROOT_PASSWORD&#125;","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"helm","slug":"helm","permalink":"https://blazehu.github.io/tags/helm/"}]},{"title":"查询外网出口IP","slug":"ops/common/ip","date":"2021-12-01T16:00:00.000Z","updated":"2025-03-24T13:09:21.775Z","comments":true,"path":"2021/12/02/ops/common/ip/","link":"","permalink":"https://blazehu.github.io/2021/12/02/ops/common/ip/","excerpt":"","text":"curl ifconfig.mecurl icanhazip.comcurl ipinfo.io/ipcurl ipecho.net/plaincurl www.trackip.net/i","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"PostgreSQL 主从同步","slug":"ops/pgsql/pgsql_master_slave","date":"2020-03-23T16:00:00.000Z","updated":"2025-03-24T13:01:08.281Z","comments":true,"path":"2020/03/24/ops/pgsql/pgsql_master_slave/","link":"","permalink":"https://blazehu.github.io/2020/03/24/ops/pgsql/pgsql_master_slave/","excerpt":"PostgreSQL 9.0 引入了主备流复制机制，流复制每次传输单位是 WAL 日志的 record。通过流复制备库不断的从主库同步相应的数据，并在备库 apply 每个 WAL record 。","text":"PostgreSQL 9.0 引入了主备流复制机制，流复制每次传输单位是 WAL 日志的 record。通过流复制备库不断的从主库同步相应的数据，并在备库 apply 每个 WAL record 。NOTES: PostgreSQL 9.0 之前提供的方法是主库写完一个 WAL 日志文件后，才把 WAL 日志文件传送到备库，这样的方式会导致主备延迟特别大。同时 PostgreSQL 9.0 之后提供了 Hot Standby ，备库在应用 WAL record 的同时也能够提供只读服务，大大提升了用户体验。配置主库pgsql 通过容器部署，这里使用 docker-compose主库： 192.168.0.1从库： 192.168.0.2启动主库pgsql: image: postgres:9.6 restart: always container_name: pgsql ports: - 5432:5432 environment: - POSTGRES_PASSWORD=postgres volumes: - /var/lib/postgresql/data:/var/lib/postgresql/data新建归档日志目录docker exec -ti pgsql bashmkdir -p /var/lib/postgresql/data/pg_archive新建用户create role replica login replication encrypted password 'replica';# 查看是否创建成功\\du修改 pg_hba.conf 文件 (从库ip)host replication replica 192.168.0.2/32 trust修改 postgresql.conflisten_addresses = '*' # 监听所有 IPwal_level = hot_standby # 开启热备max_wal_senders = 32 # 这个设置了可以最多有几个流复制连接，差不多有几个从，就设置几个wal_keep_segments = 64 # 设置流复制保留的最多的 xlog 数目，一份是 16M，注意机器磁盘 16M * 64 = 1Gwal_sender_timeout = 60 # 设置流复制主机发送数据的超时时间max_connections = 500 # 这个设置要注意下，从库的 max_connections 必须要大于主库的archive_mode = on # 允许归档 # 用该命令来归档logfile segmentarchive_command = 'cp %p /var/lib/postgresql/data/pg_archive/%f'重启容器docker restart pgsql配置从库启动从库拷贝 docker-compose 文件, 并拉起容器拷贝主服务器数据# 清除从库数据rm -rf /var/lib/postgresql/data/* pg_basebackup -h 192.168.0.1 -U replica -D /var/lib/postgresql/data -X stream -Pmkdir -p /var/lib/postgresql/data/pg_archive添加 recovery.conf 文件recovery.confstandby_mode = on primary_conninfo = 'host=192.168.0.1 port=5432 user=replica password=replica' recovery_target_timeline = 'latest'修改 postgresql.confwal_level = hot_standbyhot_standby_feedback = on # 如果有错误的数据复制，是否向主进行反馈max_connections = 1000 # 一般查多于写的应用从库的最大连接数要比较大hot_standby = on # 说明这台机器不仅仅是用于数据归档，也用于数据查询max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间wal_receiver_status_interval = 10s # 多久向主报告一次从的状态，当然从每次数据复制都会向主报告状态，这里只是设置最长的间隔时间重启从库docker restart pgsql-slave验证主从select client_addr, sync_state from pg_stat_replication;ps -ef 查看进程是否存在查看状态/usr/lib/postgresql/9.6/bin/pg_ctl -D /var/lib/postgresql/data statuspg_controldata /var/lib/postgresql/data参考资料https://www.runoob.com/postgresql/postgresql-tutorial.htmlhttp://mysql.taobao.org/monthly/2015/10/04/","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"pgsql","slug":"pgsql","permalink":"https://blazehu.github.io/tags/pgsql/"}]},{"title":"PostgreSQL 之 pg_stat_statements","slug":"ops/pgsql/pg_stat_statements","date":"2020-03-22T16:00:00.000Z","updated":"2025-03-24T13:01:10.792Z","comments":true,"path":"2020/03/23/ops/pgsql/pg_stat_statements/","link":"","permalink":"https://blazehu.github.io/2020/03/23/ops/pgsql/pg_stat_statements/","excerpt":"pg_stat_statements 模块提供了一种跟踪执行的所有 SQL 语句的统计信息的方法。","text":"pg_stat_statements 模块提供了一种跟踪执行的所有 SQL 语句的统计信息的方法。安装插件ubuntu 16.04 安装：apt-get -y update &amp;&amp; apt-get install -y postgresql-contrib-9.6 postgresql-plpython-9.6如果 pgsql 是通过容器部署可以更新基础镜像：FROM postgres:9.6RUN apt-get -y update &amp;&amp; apt-get install -y --force-yes postgresql-contrib-9.6 postgresql-plpython-9.6加载模块shared_preload_libraries = 'pg_stat_statements' # 加载 pg_stat_statements 模块以下可选参数：track_io_timing = on # 跟踪 IO 消耗的时间track_activity_query_size = 2048 # 单条 sql 的最长长度，超过截断显示pg_stat_statements.save = on # 重启后是否保留统计信息 pg_stat_statements.max = 10000 # 最多保留统计信息条数，通过 LRU 算法来覆盖老的记录。 pg_stat_statements.track = all # all：所有 sql 包括函数内嵌套的 sql 、 top：直接执行的 sql 不包括函数内嵌套的、 none：不跟踪 pg_stat_statements.track_utility = off # 是否跟踪非 DML 语句 (例如 DDL、DCL)， on 表示跟踪, off 表示不跟踪重启数据库docker restart pgsql加载扩展加载扩展模块create extension pg_stat_statements;卸载扩展模块drop extension pg_stat_statements;常用分析语句单次调用最耗时select query from pg_stat_statements order by mean_time desc limit 1;总最耗时select query from pg_stat_statements order by total_time desc limit 1;响应时间抖动最严重select query from pg_stat_statements order by stddev_time desc limit 1;单次调用最耗 IOselect query from pg_stat_statements order by (blk_read_time + blk_write_time) /calls desc limit 1;总最耗IOselect query from pg_stat_statements order by (blk_read_time + blk_write_time) desc limit 1;最耗共享内存select query from pg_stat_statements order by (shared_blks_hit + shared_blks_dirtied) desc limit 1;最耗临时空间select query from pg_stat_statements order by temp_blks_written desc limit 1;重置统计信息select pg_stat_statements_reset();参考资料https://www.postgresql.org/docs/9.6/pgstatstatements.htmlhttps://yq.aliyun.com/articles/74421","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"pgsql","slug":"pgsql","permalink":"https://blazehu.github.io/tags/pgsql/"}]},{"title":"PostgreSQL 学习笔记","slug":"ops/pgsql/pgsql_study_notes","date":"2020-03-21T16:00:00.000Z","updated":"2025-03-24T13:04:03.887Z","comments":true,"path":"2020/03/22/ops/pgsql/pgsql_study_notes/","link":"","permalink":"https://blazehu.github.io/2020/03/22/ops/pgsql/pgsql_study_notes/","excerpt":"PostgreSQL 是一个免费的对象-关系数据库服务器(ORDBMS)，在灵活的 BSD 许可证下发行。","text":"PostgreSQL 是一个免费的对象-关系数据库服务器(ORDBMS)，在灵活的 BSD 许可证下发行。命令\\d 当前数据库的所有表\\dt 只显示匹配的表 \\di 只显示索引\\ds 只显示序列\\dv 只显示视图\\df 只显示函数\\du 列出所有的数据库用户和角色\\dg 列出所有的数据库用户和角色\\encoding 指定客户端的字符编码，如 \\encoding UTF8\\x 把表中的每一行的每列数据都拆分为单行展示, 与 MySQL 中的 \"\\G\" 的功能类似Loginpsql -U postgrespsql -h 192.168.0.1 -p 5432 -U repuser -d postgres -Wpsql -U postgres -d testset envexport PGDATABASE=postgresexport PGHOST=192.168.0.1export PGPORT=5432export PGUSER=postgres------------------------------------------------------------------------------psqlLogout\\qCreate Databasecreate database test;Use Database\\c postgres\\c testShow Tables\\d\\d \"Table1\"Create Usercreate user repuser REPLICATION LOGIN CONNECTION LIMIT 2 ENCRYPTED PASSWORD 'postgres';Drop Userdrop user repuser;备份pg_dump -U postgres test &gt; test.sql pg_dump -U postgres -d test -s &gt; test.sql # -s, --schema-only dump only the schema, no data查询select \"Name\", \"Age\" from \"Person\" where \"Sex\" = 1 order by \"Age\" desc limit 3; Name| Age ----+------- 张三 | 20 李四 | 18 王五 | 16(3 rows)查看数据库、表、索引大小select pg_size_pretty(pg_database_size('test'));select pg_size_pretty(pg_table_size('test_table')); select pg_size_pretty(pg_indexes_size('test_index'));查询计划explain analyze select \"Name\", \"Age\" from \"Person\" where \"Sex\" = 1 order by \"Age\";创建索引CREATE INDEX person_age ON public.\"Person\" USING btree (\"Age\" COLLATE pg_catalog.\"default\") TABLESPACE pg_default;CREATE INDEX person_name ON public.\"Person\" USING btree (\"Name\") TABLESPACE pg_default;查看索引select * from pg_indexes where tablename='Person';vacuumvacuum 操作可以手动和自动。设置自动 vacuum 注意必须设置 track_counts = true 。具体的设置可以参照官方的文档。（8.3 版本以后）vacuumdb --analyze --verbose -f --dbname=test好处释放，再利用更新或者删除的行所占据的磁盘空间。更新 PostgreSQL 查询计划中使用的统计数据。防止因事务 ID 的重置而使非常老的数据丢失。原因PostgreSQL 数据的插入，更新，删除操作并不是真正放到数据库空间。如果不定期释放空间的话，由于数据太多，查询速度会巨降。PostgreSQL 在做查询处理的时候，为了是查询速度提高，会根据统计数据来确定执行计划。如果不及时更新的话，查询的效果可能不如预期。PostgreSQL 中每一个事务都会产生一个事务 ID，但这个数字是有上限的。当事务 ID 达到最大值后，会重新从最小值开始循环。这样如果不及时把以前的数据释放掉的话，原来的老数据会因为事务 ID 的丢失而丢失掉。参考资料https://www.runoob.com/postgresql/postgresql-tutorial.html","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"pgsql","slug":"pgsql","permalink":"https://blazehu.github.io/tags/pgsql/"}]},{"title":"Rundeck 简介","slug":"ops/common/rundeck_intro","date":"2020-03-19T16:00:00.000Z","updated":"2025-03-24T13:17:00.597Z","comments":true,"path":"2020/03/20/ops/common/rundeck_intro/","link":"","permalink":"https://blazehu.github.io/2020/03/20/ops/common/rundeck_intro/","excerpt":"Rundeck 是一个基于 Java 和 Grails 的开源的运维自动化工具，提供了 Web 管理界面进行操作，同时提供命令行工具和 WebAPI 的访问控制方式。Rundeck 能够帮助开发和运维人员更好地管理各个节点。","text":"Rundeck 是一个基于 Java 和 Grails 的开源的运维自动化工具，提供了 Web 管理界面进行操作，同时提供命令行工具和 WebAPI 的访问控制方式。Rundeck 能够帮助开发和运维人员更好地管理各个节点。安装安装方式比较多，这里使用 war 包来简单介绍安装的步骤。官方下载地址官方文档地址下载官方下载地址下载： rundeck-3.0.7-20181008.war检查依赖# 选择版本sudo update-alternatives --config java启动时会在当前路径初始化一些 rundeck 目录。如果报错可能是 java 版本的问题，可以重新选择 java 版本。环境变量PATH=$PATH:$HOME/bin:/root/rundeck/server/sbinexport RDECK_BASE=/root/rundeckexport PATH修改 linux 服务器的环境变量，将 rundeckd 的路径添加到 PATH 里。rundeckd status配置修改修改登陆密码： server/config/realm.properties# The format is# &lt;username&gt;: &lt;password&gt;[,&lt;rolename&gt; ...]## Passwords may be clear text, obfuscated or checksummed. The class# org.mortbay.util.Password should be used to generate obfuscated# passwords or password checksums## This sets the temporary user accounts for the Rundeck app#admin:admin,user,admin修改默认端口和访问地址： server/config/rundeck-config.propertiesserver.address=192.168.1.2grails.serverURL=http://192.168.1.2etc/framework.properties# ----------------------------------------------------------------# Server connection information# ----------------------------------------------------------------framework.server.name=192.168.1.2framework.server.hostname=192.168.1.2framework.server.port=80framework.server.url=http://192.168.1.2修改 dataSource 为 mysql： server/config/rundeck-config.propertiesdataSource.dbCreate=updatedataSource.url=jdbc:mysql://192.168.1.2/rundeck?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8dataSource.username=rootdataSource.password=passworddataSource.driverClassName=com.mysql.jdbc.Driver修改邮件配置：grails.mail.default.from=viease@foxmail.comgrails.mail.host=grails.mail.port=25grails.mail.username=grails.mail.password=修改 Project Nodes 配置：projects//etcproject.name=project.description=project.jobs.gui.groupExpandLevel=1project.ssh-authentication=privateKeyproject.ssh-keypath=/root/.ssh/id_rsaproject.ssh-command-timeout=0project.ssh-connect-timeout=0project.nodeCache.enabled=trueproject.nodeCache.delay=30service.NodeExecutor.default.provider=jsch-sshservice.FileCopier.default.provider=jsch-scp# node 配置文件为本地文件resources.source.1.type=fileresources.source.1.config.includeServerNode=trueresources.source.1.config.requireFileExists=falseresources.source.1.config.generateFileAutomatically=trueresources.source.1.config.format=resourcexmlresources.source.1.config.file=/root/rundeck/projects/&lt;project&gt;/etc/resources.xml# node 配置文件为 urlresources.source.2.type=urlresources.source.2.config.url=http\\://localhost\\:9998/rundeck_nodes启动服务新建一个新的目录 rundeck，将 war 包放在目录内然后运行如下命令启动服务。java -jar rundeck-3.0.7-20181008.war也可以使用提供的 rundeckd 来管理[root@localhost ~]# rundeckd -hUsage: /root/rundeck/server/sbin/rundeckd &#123;start|stop|restart|condrestart|status&#125;ArchiveRundeck 可以很方便的备份项目的配置信息，在 Project Settings 里提供导入（Import Archive）导出（Export Archive）项目配置的能力。NOTES: 官方文档提供详细的文档参考资料https://docs.rundeck.com/docs/manual/","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"Pyenv + virtualenv 版本管理","slug":"backend/python/pyenv","date":"2019-11-19T16:00:00.000Z","updated":"2025-07-08T03:26:58.259Z","comments":true,"path":"2019/11/20/backend/python/pyenv/","link":"","permalink":"https://blazehu.github.io/2019/11/20/backend/python/pyenv/","excerpt":"不同项目可能需要不同版本的 Python 和独立的依赖环境。Pyenv 可用于管理多个 Python 版本，而 pyenv-virtualenv 是其插件，用于管理虚拟环境。通过 Pyenv + pyenv-virtualenv，可以在同一台主机上切换 Python 版本并为每个项目创建独立的虚拟环境，避免依赖冲突。","text":"不同项目可能需要不同版本的 Python 和独立的依赖环境。Pyenv 可用于管理多个 Python 版本，而 pyenv-virtualenv 是其插件，用于管理虚拟环境。通过 Pyenv + pyenv-virtualenv，可以在同一台主机上切换 Python 版本并为每个项目创建独立的虚拟环境，避免依赖冲突。Pyenv 安装Pyenv 让你可以轻松地在多个 Python 版本之间切换。安装文档Pyenv 常用命令查看可用的 Python 版本pyenv install --list安装指定版本的 Pythonpyenv install 3.6.15设置当前目录下的 Python 环境版本pyenv local 3.6.15查看已安装的 Python 版本pyenv versionsPyenv-virtualenv 安装Pyenv-virtualenv 是 Pyenv 的插件，用于管理虚拟环境。安装文档创建虚拟环境pyenv virtualenv 3.6.15 env3615启用虚拟环境pyenv activate env3615退出虚拟环境pyenv deactivate总结通过 Pyenv + pyenv-virtualenv 的组合，我们可以在同一台主机上轻松管理多个 Python 版本，并为每个项目创建独立的虚拟环境。这不仅解决了不同项目对 Python 版本的需求，还避免了依赖冲突，极大地提高了开发效率。参考资料Pyenv 文档Pyenv-virtualenv 文档","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Golang 消息队列之 RabbitMQ","slug":"backend/golang/golang_rabbitmq","date":"2019-07-20T16:00:00.000Z","updated":"2025-03-24T13:24:25.159Z","comments":true,"path":"2019/07/21/backend/golang/golang_rabbitmq/","link":"","permalink":"https://blazehu.github.io/2019/07/21/backend/golang/golang_rabbitmq/","excerpt":"消息队列（Message Queue）是一种应用间的通信方式，一种应用间的异步协作机制。消息的生产者只需将消息发布到 MQ 中，消息消费者只需要从 MQ 中获取消息消费，消息的可靠性由消息系统来保证。","text":"消息队列（Message Queue）是一种应用间的通信方式，一种应用间的异步协作机制。消息的生产者只需将消息发布到 MQ 中，消息消费者只需要从 MQ 中获取消息消费，消息的可靠性由消息系统来保证。RabbitMQ 简介RabbitMQ 是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ 特点可靠性（Reliability）灵活的路由（Flexible Routing）消息集群（Clustering）高可用（Highly Available Queues）多种协议（Multi-protocol）多语言客户端（Many Clients）管理界面（Management UI）跟踪机制（Tracing）插件机制（Plugin System）Exchange 类型类型描述direct路由键完全匹配，单播topic路由键模式匹配，路由键可以包含通配符：”#”、”*”fanout不处理路由键，广播，转发消息最快headers不处理路由键，根据发送的消息内容中的 headers 属性进行匹配，其他跟 direct 模式完全一致，性能较其他模式差很多部署容器化部署，简单方便docker run -d --hostname rabbit1 --name rabbitmq1 -p 9419:9419 -p 8080:15672 -p 5672:5672 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.7.14-managementdocker run -d --hostname rabbit2 --name rabbitmq2 -p 5673:5672 --link rabbitmq1:rabbit1 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.7.14-managementdocker run -d --hostname rabbit3 --name rabbitmq3 -p 5674:5672 --link rabbitmq1:rabbit1 --link rabbitmq2:rabbit2 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.7.14-managementdocker exec -it rabbitmq1 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_appexitdocker exec -it rabbitmq2 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_appexitdocker exec -it rabbitmq3 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_appexitRabbitMQ Exporterrepo: https://github.com/kbudde/rabbitmq_exporterStart RabbitMQ Exporter:RABBIT_EXPORTERS=exchange,node,queue RABBIT_CAPABILITIES=bert,no_sort RABBIT_USER=guest RABBIT_PASSWORD=guest OUTPUT_FORMAT=JSON PUBLISH_PORT=8082 RABBIT_URL=http://127.0.0.1:8080 MAX_QUEUES=5000 nohup rabbitmq_exporter &amp;Start in container:docker run -d --net=container:my-rabbit kbudde/rabbitmq-exporterGolang 客户端 Demo配置&#123; \"URL\": \"amqp://guest:guest@10.5.124.213:5672/\",&#125;Clientpackage rabbitmqimport ( log \"github.com/sirupsen/logrus\" \"github.com/streadway/amqp\" \"time\")type Config struct &#123; URL string QueueList map[string][]string&#125;type Client struct &#123; Config Connection *amqp.Connection Channel *amqp.Channel&#125;const ( reconnectDelay = 3 * time.Second // reconnectDelay retryNum = 5 // retryNum DefaultExchangeName = \"default\" DefaultQueueName = \"default\")func (c *Client) connect() &#123; var ( err error ) log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", &#125;).Info(\"Attempting to connect.\") c.Connection, err = amqp.Dial(c.URL) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Error(\"Failed to connect to RabbitMQ.\") return &#125; c.Channel, err = c.Connection.Channel() if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Error(\"Failed to open a channel.\") return &#125;&#125;func (c *Client) isConnected() bool &#123; if c.Connection.IsClosed() || c.Channel == nil &#123; return false &#125; return true&#125;func (c *Client) handleConnect() &#123; // retry connect for index := 0; index &lt; retryNum; index++ &#123; c.connect() if c.isConnected() &#123; break &#125; else &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", &#125;).Warn(\"Failed to connect. Retrying...\") time.Sleep(reconnectDelay) &#125; &#125; if c.isConnected() &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", &#125;).Info(\"Connect succeed.\") &#125; else &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", &#125;).Fatal(\"Connect failed.\") &#125;&#125;Producertype Producer struct &#123; Client&#125;func NewProducer() *Producer &#123; rabbitConfig := new(Config) err := util.ReadConfig(\"RabbitMQ\", rabbitConfig) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Fatal(\"Read config error.\") &#125; producer := &amp;Producer&#123;&#125; producer.URL = rabbitConfig.URL producer.handleConnect() return producer&#125;func (p *Producer) UnsafePushExchange(data map[string]string, exchangeName string) error &#123; // check connect if !p.isConnected() &#123; p.handleConnect() p.initExchange() &#125; // parse data var ( bytesData []byte err error ) if data == nil &#123; return nil &#125; publishData := Msg&#123; Data: data, Time: util.DecodeTime(time.Now().UTC()), &#125; bytesData, err = json.Marshal(publishData) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"data\": data, \"err\": err, &#125;).Error(\"Failed to marshal a message.\") return err &#125; err = p.Channel.Publish( exchangeName, // exchange \"\", // routing key false, // mandatory false, // immediate amqp.Publishing&#123; DeliveryMode: amqp.Persistent, ContentType: \"application/json\", Body: bytesData, &#125;) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Error(\"Failed to publish a message.\") &#125; else &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"data\": publishData, &#125;).Info(\"Publish a message.\") &#125; return err&#125;Consumertype Consumer struct &#123; Client&#125;func NewConsumer(queueName string) *Consumer &#123; rabbitConfig := new(Config) err := util.ReadConfig(\"RabbitMQ\", rabbitConfig) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Fatal(\"Read config error.\") &#125; if queueName == \"\" &#123; queueName = DefaultQueueName &#125; consumer := &amp;Consumer&#123; queueName: queueName, &#125; consumer.URL = rabbitConfig.URL consumer.QueueList = rabbitConfig.QueueList consumer.handleConnect() consumer.initQueue() return consumer&#125;func (c *Consumer) Receive(forever chan struct&#123;&#125;) &#123; // check connect if !c.isConnected() &#123; c.handleConnect() &#125; msgs, err := c.Channel.Consume( c.queueName, // queue \"\", // consumer false, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil &#123; log.WithFields(log.Fields&#123; \"module\": \"RabbitMQ\", \"err\": err, &#125;).Info(\"Failed to register a consumer.\") &#125; go func() &#123; for msg := range msgs &#123; if !c.isConnected() &#123; c.handleConnect() &#125; c.handle(msg.Body) msg.Ack(false) &#125; &#125;() &lt;-forever log.Info(\"Consumer is Done.\")&#125;参考资料https://www.jianshu.com/p/79ca08116d57https://github.com/kbudde/rabbitmq_exporterhttps://www.rabbitmq.com/tutorials/tutorial-four-go.html","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://blazehu.github.io/tags/rabbitmq/"}]},{"title":"Golang 单例模式","slug":"backend/golang/golang_singleton","date":"2019-07-12T16:00:00.000Z","updated":"2025-03-24T13:24:14.625Z","comments":true,"path":"2019/07/13/backend/golang/golang_singleton/","link":"","permalink":"https://blazehu.github.io/2019/07/13/backend/golang/golang_singleton/","excerpt":"单例模式是最简单的设计模式之一，这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。意图： 保证一个类型仅有一个实例，并提供一个访问它的全局访问点。主要解决： 一个全局使用的类型频繁地创建与销毁。何时使用： 当您想控制实例数目，节省系统资源的时候。如何解决： 判断系统是否已经有这个单例，如果有则返回，如果没有则创建。","text":"单例模式是最简单的设计模式之一，这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。意图： 保证一个类型仅有一个实例，并提供一个访问它的全局访问点。主要解决： 一个全局使用的类型频繁地创建与销毁。何时使用： 当您想控制实例数目，节省系统资源的时候。如何解决： 判断系统是否已经有这个单例，如果有则返回，如果没有则创建。实现Golang 目前常见的有以下四种方式（懒汉式、 饿汉式、 双重检查、 sync.Once）懒汉式非线程安全package mainimport ( \"fmt\" \"unsafe\")type SingletonInstance struct &#123; value int&#125;var singletonInstance *SingletonInstancefunc GetSingletonInstance() *SingletonInstance &#123; if singletonInstance == nil &#123; singletonInstance = new(SingletonInstance) &#125; return singletonInstance&#125;func main() &#123; s := GetSingletonInstance() b := GetSingletonInstance() c := new(SingletonInstance) fmt.Println(unsafe.Pointer(s)) fmt.Println(unsafe.Pointer(b)) fmt.Println(unsafe.Pointer(c))&#125;线程安全利用 sync.Mutex 进行加锁，保证线程安全。缺点： 加锁有了额外开销。type SingletonInstance struct &#123; value int&#125;var ( lock sync.Mutex singletonInstance *SingletonInstance)func GetSingletonInstance() *SingletonInstance &#123; lock.Lock() defer lock.Unlock() if singletonInstance == nil &#123; singletonInstance = new(SingletonInstance) &#125; return singletonInstance&#125;饿汉式导入包的时候直接创建实例，这样无需判空且线程安全。优点： 简单方便缺点： 不管程序中是否使用都会生成该实例，该实例持续占有在内存中适用场景： 该实例使用频繁，功能简单占用内存少type SingletonInstance struct &#123; value int&#125;var singletonInstance SingletonInstancefunc GetSingletonInstance() *SingletonInstance &#123; return &amp;singletonInstance&#125;双重检查第一次判断不加锁，第二次加锁保证线程安全，实例创建完成后，获取实例就不用加锁了。type SingletonInstance struct &#123; value int&#125;var ( lock sync.Mutex singletonInstance *SingletonInstance)func GetSingletonInstance() *SingletonInstance &#123; if singletonInstance == nil &#123; lock.Lock() if singletonInstance == nil &#123; singletonInstance = new(SingletonInstance) &#125; lock.Unlock() &#125; return singletonInstance&#125;sync.Oncesync.Once 确保创建实例子的函数只执行一次type SingletonInstance struct &#123; value int&#125;var ( one sync.Once singletonInstance *SingletonInstance)func GetSingletonInstance() *SingletonInstance &#123; one.Do(func() &#123; singletonInstance = new(SingletonInstance) &#125;) return singletonInstance&#125;sync.Once 源码分析package syncimport ( \"sync/atomic\")// Once is an object that will perform exactly one action.type Once struct &#123; done uint32 m Mutex&#125;func (o *Once) Do(f func()) &#123; // o.done 初始化为0，双重检查 if atomic.LoadUint32(&amp;o.done) == 0 &#123; o.doSlow(f) &#125;&#125;func (o *Once) doSlow(f func()) &#123; // 加锁 o.m.Lock() defer o.m.Unlock() if o.done == 0 &#123; // o.done 赋值为1，atomic 原子操作 defer atomic.StoreUint32(&amp;o.done, 1) // 执行函数 f() &#125;&#125;参考资料https://www.runoob.com/design-pattern/singleton-pattern.htmlhttps://www.cnblogs.com/wpnine/p/10426105.html","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"}]},{"title":"Golang Sort排序","slug":"backend/golang/golang_sort","date":"2019-07-11T16:00:00.000Z","updated":"2025-03-24T13:24:17.073Z","comments":true,"path":"2019/07/12/backend/golang/golang_sort/","link":"","permalink":"https://blazehu.github.io/2019/07/12/backend/golang/golang_sort/","excerpt":"sort包提供了排序切片和用户自定义数据集以及相关功能的函数。","text":"sort包提供了排序切片和用户自定义数据集以及相关功能的函数。集合排序使用sort包的函数进行排序时，集合需要实现 sort.Inteface 接口，该接口中有三个方法：Len、Less、Swap。// An implementation of Interface can be sorted by the routines in this package.// The methods refer to elements of the underlying collection by integer index.type Interface interface &#123; // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the &lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int)&#125;sort包已经支持的内部数据类型排序sort包原生支持[]int、[]float64 和 []string 三种内建数据类型切片的排序操作，已实现相关的Len()、Less()、Swap()方法。// Convenience types for common casestype IntSlice []inttype Float64Slice []float64type StringSlice []string...例子package mainimport ( \"fmt\" \"sort\")type Student struct &#123; name string age int&#125;func (s *Student) String() string &#123; return fmt.Sprintf(\"(%s, %d)\", s.name, s.age)&#125;type StudentSlice []*Studentfunc (list StudentSlice) Len() int &#123; return len(list)&#125;func (list StudentSlice) Less(i, j int) bool &#123; //排序规则：首先按年龄排序（由小到大），年龄相同时按姓名进行排序（按字符串的自然顺序） if list[i].age &lt; list[j].age &#123; return true &#125; else if list[i].age &gt; list[j].age &#123; return false &#125; else &#123; return list[i].name &lt; list[j].name &#125;&#125;func (list StudentSlice) Swap(i, j int) &#123; list[i], list[j] = list[j], list[i]&#125;func main() &#123; // []int a := []int&#123;1, 2, 9, 0, 5, 7, 6, 3, 4, 8&#125; sort.Sort(sort.IntSlice(a)) fmt.Println(a) // []float b := []float64&#123;1.1, 2.2, 3.4, 2.8, 1.2, 4.5, -6.1, -0.6, -4.0, 2.4&#125; sort.Sort(sort.Float64Slice(b)) fmt.Println(b) // []string c := []string&#123;\"f\", \"c\", \"d\", \"b\", \"a\", \"z\", \"x\", \"y\"&#125; sort.Sort(sort.StringSlice(c)) fmt.Println(c) s := StudentSlice([]*Student&#123; &amp;Student&#123;\"f\", 18&#125;, &amp;Student&#123;\"c\", 17&#125;, &amp;Student&#123;\"d\", 19&#125;, &amp;Student&#123;\"b\", 16&#125;, &amp;Student&#123;\"a\", 15&#125;, &amp;Student&#123;\"z\", 18&#125;, &amp;Student&#123;\"x\", 18&#125;, &amp;Student&#123;\"y\", 17&#125;, &#125;) sort.Sort(s) fmt.Println(s)&#125;执行结果[0 1 2 3 4 5 6 7 8 9][-6.1 -4 -0.6 1.1 1.2 2.2 2.4 2.8 3.4 4.5][a b c d f x y z][(a, 15) (b, 16) (c, 17) (y, 17) (f, 18) (x, 18) (z, 18) (d, 19)]逆排序sort.Reverse()例子package mainimport ( \"fmt\" \"sort\")func main() &#123; // []int a := []int&#123;1, 2, 9, 0, 5, 7, 6, 3, 4, 8&#125; sort.Sort(sort.Reverse(sort.IntSlice(a))) fmt.Println(a)&#125;执行结果[9 8 7 6 5 4 3 2 1 0]Reverse 源码分析sort.Reverse 源码如下，可以发现 sort.Reverse 方法返回的是 reverse 类型的 Interface，而该结构体只是重新实现了 Less 方法。type reverse struct &#123; // This embedded Interface permits Reverse to use the methods of // another Interface implementation. Interface&#125;// Less returns the opposite of the embedded implementation's Less method.func (r reverse) Less(i, j int) bool &#123; return r.Interface.Less(j, i)&#125;// Reverse returns the reverse order for data.func Reverse(data Interface) Interface &#123; return &amp;reverse&#123;data&#125;&#125;IntSlice 的 Less 方法实现如下func (x IntSlice) Less(i, j int) bool &#123; return x[i] &lt; x[j] &#125;上述 []int 类型切片排序的时候，r.Interface.Less(j, i) ，调用了 IntSlice 的 Less 方法，交换了下标 i, j。这样 Less 方法实际如下，这样就实现了逆排序func (x IntSlice) Less(i, j int) bool &#123; return x[j] &lt; x[i] &#125;","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"}]},{"title":"Docker 学习笔记","slug":"cloudnative/docker_introduction","date":"2019-03-17T16:00:00.000Z","updated":"2025-08-15T04:20:30.102Z","comments":true,"path":"2019/03/18/cloudnative/docker_introduction/","link":"","permalink":"https://blazehu.github.io/2019/03/18/cloudnative/docker_introduction/","excerpt":"Build, Ship, and Run Any App, Anywhere.","text":"Build, Ship, and Run Any App, Anywhere.镜像构建Dockerfile# 设置基础镜像为DebianFROM debian# 将软件包emacs.tgz解压到/usr/local/目录下ADD emacs.tgz /usr/local# 将软件包apache.tgz解压到/usr/local/目录下ADD apache.tgz /usr/local# 设置匿名卷目录/dataVOLUME /data# 设置容器的启动命令，该配置可用运行时参数覆盖CMD [\"/usr/local/start.sh\"]构建镜像Dockerfile中的每一条指令都会生成一层新的镜像层从一个父镜像开始构建，docker build 的时候会去检查下一条命令的hash值是否于现有镜像层相等，如果相等，则不执行这条命令，而直接基于现有镜像层来执行接下来的语句。对于ADD或者COPY指令来说，docker 会检查每个文件的校验和（元数据和数据），最后修改时间和最后访问时间不作考虑。对于RUN yum install 来说，docker 不会去检查文件的校验和，只检查指令是否变化。如果需要强制更新镜像，那么需要docker build –no-cache一旦从某一层开始不使用cache，接下来的每一层都不会再检查是否有cache最佳实践FROM尽可能使用当前官方仓库作为你构建镜像的基础。如果公司内部使用，可下载官方仓库镜像，再推送至私有 registry。推荐使用 Alpine 镜像（Alpine Linux 是一个完整的操作系统），因为其被严格控制并保持在最小尺寸（目前大小 5.52M）。基于此基础镜像，再去构建自己的基础镜像，可以有效控制镜像的大小。LABEL通过给镜像添加标签可以帮助组织镜像、记录许可信息、辅助自动化构建等。RUN为了保持 Dockerfile 文件的可读性，可理解性，以及可维护性，过长的或复杂的 RUN 指令使用反斜杠 \\ 分行。RUN yum install -y pip \\ git-1.9.3.1 \\ wget-1.14 &amp;&amp; \\ yum clean all如果将 RUN apt-get update 和 apt-get install 拆解为两条命令，会导致缓存问题记忆后续的 install 失败。下图从左边修改最后一行再次构建镜像是时，Docker 发现 RUN apt-get update 指令一样。这样会导致 apt-get update 不再执行，使用缓存镜像。后面使用 apt-get install 安装的是过时的 curl 和 nginx 版本。EXPOSEEXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P时，会自动随机映射 EXPOSE 的端口。ENV为容器化服务提供必要的环境变量。ADD 和 COPY优先使用 COPY，COPY 语义更明确。ADD 能够将本地 tar 文件自动提取到镜像中，这种场景用 ADD 更合适。如果 Dockerfile 中需要 COPY 多个上下文中的文件，不要一次性 COPY 所有文件，这将保证每个步骤的构建缓存只在特定的文件变化时失效。最好的做法是按文件组织结构以及功能去 COPY 文件。VOLUME建议使用 VOLUME 来管理镜像中的可变部分和用户可以改变的部分，如数据库存储文件、配置文件、容器创建的文件和目录等。WORKDIR用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。为了清晰性和可靠性，应该总是在 WORKDIR 中使用绝对路径。其他# 使用 .dockerignore# 使用多阶段构建# 避免安装不必要的包# 一个容器只运行一个进程# 镜像层数尽可能少# 清除缓存的包 （apt-get clean）# 充分利用构建缓存docker commitdocker commitdocker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]多阶段构建Docker 17.05 or higher# 第一阶段构建生成可执行文件# builderFROM golang:1.16 AS builderCOPY go.mod /src/COPY go.sum /src/RUN cd /src &amp;&amp; go mod downloadCOPY . /src/RUN cd /src &amp;&amp; go build -ldflags '-linkmode \"external\" --extldflags \"-static\"' cmd/ipasd/ipasd.go# 第二阶段构建，使用第一阶段的构建产物# runtimeFROM ineva/alpine:3.10.3LABEL maintainer=\"Steven &lt;s@ineva.cn&gt;\"WORKDIR /appCOPY --from=builder /src/ipasd /appCOPY docker-entrypoint.sh /docker-entrypoint.shRUN chmod +x /docker-entrypoint.shENTRYPOINT /docker-entrypoint.sh镜像的存储和传输docker pull docker push# docker镜像完整路径&lt;registry&gt;/&lt;repository&gt;/&lt;image&gt;:&lt;tag&gt;10.0.0.1:5000/blazehu/myapache:v1# docker默认registrydocker.io(\"dockerhub\")# Insecure-registry配置/etc/docker/daemon.json\"insecure-registries\": [\"10.0.0.0/8\"],#无法访问 registry? docker save –o xxx.tgz $&#123;imageId&#125; 将镜像打包成文件docker load -i xxx.tgz 将镜像从文件中加到本地的docker存储docker run 做了什么？docker 客户端命令行工具dockerd 守护进程，容器的元数据管理、镜像管理、容器运行时及网络、存储等插件containerd 负责容器的生命周期管理，向上为Docker守护进程提供gRPC接口，屏蔽底层细节，向下通过containerd-shim操控RunC，使得上层Docker守护进程和底层容器运行时可独立升级发展containerd-shim 处理 exit code，wait4() 等问题，实现daemonless容器runc 专注于容器实现，包括环境隔离、资源限制、容器安全等Docker Client基础命令总览Docker仓库相关docker searchdocker pulldocker pushdocker login查看镜像和容器信息docker psdocker imagesdocker logsdocker portdocker diffdocker history操作容器和镜像docker rundocker attachdocker startdocker stopdocker rmdocker rmidocker tagdocker commitdocker savedocker builddocker loaddocker exec","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blazehu.github.io/tags/docker/"}]},{"title":"什么是容器？","slug":"cloudnative/container","date":"2019-03-13T16:00:00.000Z","updated":"2025-08-15T04:12:06.123Z","comments":true,"path":"2019/03/14/cloudnative/container/","link":"","permalink":"https://blazehu.github.io/2019/03/14/cloudnative/container/","excerpt":"容器是一种操作系统虚拟化技术，内核功能的集合，提供给应用独立的运行环境，并实现资源的控制和隔离。Docker 不等同于容器，容器历史要比Docker 长得多。","text":"容器是一种操作系统虚拟化技术，内核功能的集合，提供给应用独立的运行环境，并实现资源的控制和隔离。Docker 不等同于容器，容器历史要比Docker 长得多。1. 容器技术发展历史1972 UNIX发布了Chroot(Change Root)工具 2000 FreeBSD发布了Jails，它可以将服务器划分成多个称为Jail的虚拟分区，为⽤用户提供 ⼲干净独立的运⾏行行时环境 2005 SWsoft基于Linux 2.6.15 内核发布了OpenVZ，实现了操作系统层面的虚拟化 2006 Google发布了Process containers进程容器内核补丁，可以隔离进程 的CPU，内存， 磁盘IO，网络IO等资源; 2008更更名为 Cgroup(Control Groups )，Cgroup可以对进 程分组配置，从⽽而可以以组为单位来隔离资源2008 Linux社区合作开发了LXC (Linux Containers)容器器，利用Namespace来为容器提供 独立的名字空间，包括进程树、网络、用户组及文件系统等，再利用Capabilities限 制容器器内敏敏感系统调⽤用。 2011 CloudFoundry基于LXC构建了Warden容器器(后放弃LXC⾃自自研) 2013 Google开源了了其鼎鼎有名的Borg平台使用的容器技术lmctfy (Let me contain that for you) 2013 DotCloud开源了Docker容器，最初基于LXC构建，定义了Docker分层镜像格式2014 CoreOS推出了了了RKT(Rocket)容器 2015 OCI (Open Container Initiative)组织成立，旨在推进容器技术的标准化工作2015 Docker的libcontainer演化出了RunC项目 2016 Docker在架构上分离出了容器器运⾏行行时环境Containered，原数据管理和运行时环境分离2017 Docker社区开源项目重命名为Moby，基于Moby开源项⽬目构建Docker社区版，在社 区版基础上构建 Docker企业版。从此Docker成为商业产品名字，而原Docker项目化 身Moby继续发展2. 容器与传统虚拟机的区别更高效的利用系统资源一致的运行环境持续交付和部署更轻松的迁移更轻松的维护和扩展容器相比传统的虚拟机有如下几点优势：是容器比虚拟机要小的多，镜像小，传统的一个虚拟机的镜像小的几G，大的上百G，而容器的镜像往往都是几十MB，轻量级的容器镜像意味着可以更方便的进行传输。是可以更细粒度的划分CPU和内存等计算资源，虚拟机最小的也是1C1G，而容器可以划分成更小的单位比如 0.1核，128 MiB，非常适用于平时资源使用率不高的业务。因为容器做好了资源的隔离，通过容器在一台机器上混布，可以极大的提高资源利用率，降低成本。是容器启动时间比虚拟机要快，虚拟机的启动时间是分钟级的，而容器理论上在1秒之内能启动成百上千个。非常适用于业务量动态变化快的业务。容器技术改变应用交付，在以前应用程序的交付是通过源码或可执行文件交付，同时必须包含一个如何部署应用程序的说明文档。往往部署一个稍复杂点的程序，都需要两到三天的时间。容器可以将应用程序和依赖环境打包起来，只要应用程序的容器在一个环境运行起来，在其他任何环境下也能运行，从交付代码变成交付容器，从两到三天的时间缩短到5分钟，极大提高交付效率。3. Why Docker？Build Once, Run Anywhere创新性地解决了应用打包和分发技术难题。通过友好的设计和封装，大大降低了容器技术的使用门槛。","categories":[{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blazehu.github.io/tags/docker/"}]},{"title":"1154. 一年中的第几天","slug":"leetcode-cn/1154","date":"2018-07-09T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/07/10/leetcode-cn/1154/","link":"","permalink":"https://blazehu.github.io/2018/07/10/leetcode-cn/1154/","excerpt":"题目描述给你一个字符串 date ，按 YYYY-MM-DD 格式表示一个 现行公元纪年法 日期。请你计算并返回该日期是当年的第几天。通常情况下，我们认为 1 月 1 日是每年的第 1 天，1 月 2 日是每年的第 2 天，依此类推。每个月的天数与现行公元纪年法（格里高利历）一致。说明date.length == 10date[4] == date[7] == '-'，其他的 date[i] 都是数字date 表示的范围从 1900 年 1 月 1 日至 2019 年 12 月 31 日示例输入：date = \"2019-01-09\"输出：9输入：date = \"2019-02-10\"输出：41输入：date = \"2003-03-01\"输出：60输入：date = \"2004-03-01\"输出：61","text":"题目描述给你一个字符串 date ，按 YYYY-MM-DD 格式表示一个 现行公元纪年法 日期。请你计算并返回该日期是当年的第几天。通常情况下，我们认为 1 月 1 日是每年的第 1 天，1 月 2 日是每年的第 2 天，依此类推。每个月的天数与现行公元纪年法（格里高利历）一致。说明date.length == 10date[4] == date[7] == '-'，其他的 date[i] 都是数字date 表示的范围从 1900 年 1 月 1 日至 2019 年 12 月 31 日示例输入：date = \"2019-01-09\"输出：9输入：date = \"2019-02-10\"输出：41输入：date = \"2003-03-01\"输出：60输入：date = \"2004-03-01\"输出：61四年一闰，百年不闰，四百年再闰是否闰年：isLeap := year%400 == 0 || (year%4 == 0 &amp;&amp; year%100 != 0)func dayOfYear(date string) int &#123; res := strings.Split(date, \"-\") year, _ := strconv.Atoi(res[0]) month, _ := strconv.Atoi(res[1]) day, _ := strconv.Atoi(res[2]) isLeap := year%400 == 0 || (year%4 == 0 &amp;&amp; year%100 != 0) monthDay := []int&#123;0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31&#125; for i := 0; i &lt; month; i++ &#123; day += monthDay[i] if isLeap &amp;&amp; i == 2 &#123; day += 1 &#125; &#125; return day&#125;本地测试package mainimport ( \"fmt\")func main() &#123; fmt.Println(dayOfYear(\"2019-01-09\")) fmt.Println(dayOfYear(\"2019-02-10\")) fmt.Println(dayOfYear(\"2003-03-01\")) fmt.Println(dayOfYear(\"2004-03-01\"))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/day-of-the-year","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"475. 供暖器","slug":"leetcode-cn/475","date":"2018-06-09T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/06/10/leetcode-cn/475/","link":"","permalink":"https://blazehu.github.io/2018/06/10/leetcode-cn/475/","excerpt":"题目描述冬季已经来临。 你的任务是设计一个有固定加热半径的供暖器向所有房屋供暖。在加热器的加热半径范围内的每个房屋都可以获得供暖。现在，给出位于一条水平线上的房屋 houses 和供暖器 heaters 的位置，请你找出并返回可以覆盖所有房屋的最小加热半径。说明：所有供暖器都遵循你的半径标准，加热的半径也一样。说明1 &lt;= houses.length, heaters.length &lt;= 3 * 1041 &lt;= houses[i], heaters[i] &lt;= 109示例输入: houses = [1,2,3], heaters = [2]输出: 1解释: 仅在位置2上有一个供暖器。如果我们将加热半径设为1，那么所有房屋就都能得到供暖。输入: houses = [1,2,3,4], heaters = [1,4]输出: 1解释: 在位置1, 4上有两个供暖器。我们需要将加热半径设为1，这样所有房屋就都能得到供暖。输入：houses = [1,5], heaters = [2]输出：3","text":"题目描述冬季已经来临。 你的任务是设计一个有固定加热半径的供暖器向所有房屋供暖。在加热器的加热半径范围内的每个房屋都可以获得供暖。现在，给出位于一条水平线上的房屋 houses 和供暖器 heaters 的位置，请你找出并返回可以覆盖所有房屋的最小加热半径。说明：所有供暖器都遵循你的半径标准，加热的半径也一样。说明1 &lt;= houses.length, heaters.length &lt;= 3 * 1041 &lt;= houses[i], heaters[i] &lt;= 109示例输入: houses = [1,2,3], heaters = [2]输出: 1解释: 仅在位置2上有一个供暖器。如果我们将加热半径设为1，那么所有房屋就都能得到供暖。输入: houses = [1,2,3,4], heaters = [1,4]输出: 1解释: 在位置1, 4上有两个供暖器。我们需要将加热半径设为1，这样所有房屋就都能得到供暖。输入：houses = [1,5], heaters = [2]输出：3暴力解法分析：排序后从左开始遍历每一个房屋，求每个房屋到最近供暖器的距离，然后找出最大的值。求每个房屋到最近供暖器的距离：相邻的左边供暖器和右边供暖器距离里取小的值。func findRadius(houses []int, heaters []int) int &#123; var ( radius int i int j int ) // sort sort.Ints(houses) sort.Ints(heaters) t := 0 for j = 0; j &lt; len(houses); j++ &#123; tmp := 0 for i = t; i &lt; len(heaters); i++ &#123; if heaters[i] &lt; houses[j] &#123; tmp = houses[j] - heaters[i] &#125; else if tmp != 0 &#123; tmp = int(math.Min(float64(tmp), float64(heaters[i]-houses[j]))) if i != 0 &#123; t = i - 1 &#125; break &#125; else &#123; tmp = heaters[i] - houses[j] if i != 0 &#123; t = i - 1 &#125; break &#125; &#125; radius = int(math.Max(float64(radius), float64(tmp))) &#125; return radius&#125;本地测试package mainimport ( \"fmt\")func main() &#123; var a, b []int a = []int&#123;1, 2, 3&#125; b = []int&#123;2&#125; fmt.Println(findRadius(a, b)) a = []int&#123;1, 2, 3, 4&#125; b = []int&#123;1, 4&#125; fmt.Println(findRadius(a, b)) a = []int&#123;1, 5&#125; b = []int&#123;2&#125; fmt.Println(findRadius(a, b)) a = []int&#123;282475249, 622650073, 984943658, 144108930, 470211272, 101027544, 457850878, 458777923&#125; b = []int&#123;823564440, 115438165, 784484492, 74243042, 114807987, 137522503, 441282327, 16531729, 823378840, 143542612&#125; fmt.Println(findRadius(a, b))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/heaters","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"34. 在排序数组中查找元素的第一个和最后一个位置","slug":"leetcode-cn/34","date":"2018-04-03T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/04/04/leetcode-cn/34/","link":"","permalink":"https://blazehu.github.io/2018/04/04/leetcode-cn/34/","excerpt":"题目描述给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回 [-1, -1]。说明0 &lt;= nums.length &lt;= 105-109 &lt;= nums[i] &lt;= 109nums 是一个非递减数组-109 &lt;= target &lt;= 109示例输入：nums = [5,7,7,8,8,10], target = 8输出：[3,4]输入：nums = [5,7,7,8,8,10], target = 6输出：[-1,-1]输入：nums = [], target = 0输出：[-1,-1]","text":"题目描述给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回 [-1, -1]。说明0 &lt;= nums.length &lt;= 105-109 &lt;= nums[i] &lt;= 109nums 是一个非递减数组-109 &lt;= target &lt;= 109示例输入：nums = [5,7,7,8,8,10], target = 8输出：[3,4]输入：nums = [5,7,7,8,8,10], target = 6输出：[-1,-1]输入：nums = [], target = 0输出：[-1,-1]二分查找通过二分查找找到目标数字在数组中的下标，然后向该下标左右两边搜索func searchRange(nums []int, target int) []int &#123; var i, j int targetIndex := searchIndex(nums, 0, len(nums)-1, target) if targetIndex == -1 &#123; return []int&#123;-1, -1&#125; &#125; for j = targetIndex; j &lt; len(nums) &amp;&amp; nums[j] == target; j++ &#123; &#125; for i = targetIndex; i &gt;= 0 &amp;&amp; nums[i] == target; i-- &#123; &#125; return []int&#123;i + 1, j - 1&#125;&#125;func searchIndex(nums []int, i, j, target int) int &#123; index := (i + j) / 2 if nums[index] == target &amp;&amp; i &lt; j &#123; return index &#125; else if nums[index] &gt; target &amp;&amp; i &lt; j &#123; j = index &#125; else if nums[index] &lt; target &amp;&amp; i &lt; j &#123; i = index + 1 &#125; else &#123; return -1 &#125; return searchIndex(nums, i, j, target)&#125;本地测试package mainimport ( \"fmt\")func main() &#123; fmt.Println(\"ans is : \", searchRange([]int&#123;5, 7, 7, 8, 8, 10&#125;, 8)) fmt.Println(\"ans is : \", searchRange([]int&#123;5, 7, 7, 8, 8, 10&#125;, 6))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"29. 两数相除","slug":"leetcode-cn/29","date":"2018-03-28T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/29/leetcode-cn/29/","link":"","permalink":"https://blazehu.github.io/2018/03/29/leetcode-cn/29/","excerpt":"题目描述给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。返回被除数 dividend 除以除数 divisor 得到的商。整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2说明被除数和除数均为 32 位有符号整数。 除数不为 0。假设我们的环境只能存储 32 位有符号整数，其数值范围是 [−231, 231 − 1]。本题中，如果除法结果溢出，则返回 231 − 1。示例输入: dividend = 10, divisor = 3输出: 3解释: 10/3 = truncate(3.33333..) = truncate(3) = 3输入: dividend = 7, divisor = -3输出: -2解释: 7/-3 = truncate(-2.33333..) = -2","text":"题目描述给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。返回被除数 dividend 除以除数 divisor 得到的商。整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2说明被除数和除数均为 32 位有符号整数。 除数不为 0。假设我们的环境只能存储 32 位有符号整数，其数值范围是 [−231, 231 − 1]。本题中，如果除法结果溢出，则返回 231 − 1。示例输入: dividend = 10, divisor = 3输出: 3解释: 10/3 = truncate(3.33333..) = truncate(3) = 3输入: dividend = 7, divisor = -3输出: -2解释: 7/-3 = truncate(-2.33333..) = -2解法使用递归和位运算。除数以指数形式增长，计算速度快。1. 每次找到最大的n保证 x &gt;= y * pow(2, n)2. divide(x, y) = pow(2, n) + divide(x - y * pow(2, n), y) 3. if x &lt; y: divide(x, y) = 0比如 ：divide(14, 3) = divide(14 - 12, 3) + pow(2, 2) = divide(2, 3) + 4 = 0 + 4 = 4func divide(dividend int, divisor int) int &#123; abs := func(x int) int &#123; if x &lt; 0 &#123; return x * -1 &#125; return x &#125; pow := func(n int) int &#123; s := 1 for i := 0; i &lt; n; i++ &#123; s *= 2 &#125; return s &#125; min := func(x, y int) int &#123; if x &gt; y &#123; return y &#125; return x &#125; i, a, b := 0, abs(dividend), abs(divisor) if a == 0 || a &lt; b &#123; return 0 &#125; for b &lt;= a &#123; b = b &lt;&lt; 1 i = i + 1 &#125; res := pow(i-1) + divide(a-(b&gt;&gt;1), abs(divisor)) if (dividend ^ divisor) &lt; 0 &#123; res = -res &#125; return min(res, (1&lt;&lt;31)-1)&#125;本地测试package mainimport ( \"fmt\")func main() &#123; fmt.Println(divide(10, 3)) fmt.Println(divide(12, -3)) fmt.Println(divide(14, 3)) fmt.Println(divide(-1, -1)) fmt.Println(divide(-1, 1)) fmt.Println(divide(0, -1)) fmt.Println(divide(-2147483648, -1))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/divide-two-integers","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"28. 实现 strStr()","slug":"leetcode-cn/28","date":"2018-03-27T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/28/leetcode-cn/28/","link":"","permalink":"https://blazehu.github.io/2018/03/28/leetcode-cn/28/","excerpt":"题目描述实现 strStr() 函数。说明给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。示例输入: haystack = \"hello\", needle = \"ll\"输出: 2输入: haystack = \"aaaaa\", needle = \"bba\"输出: -1","text":"题目描述实现 strStr() 函数。说明给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。示例输入: haystack = \"hello\", needle = \"ll\"输出: 2输入: haystack = \"aaaaa\", needle = \"bba\"输出: -1解法func strStr(haystack string, needle string) int &#123; l1, l2 := len(haystack), len(needle) if l2 &lt; 1 &#123; return 0 &#125; else if l1 &lt; 1 &#123; return -1 &#125; if l1 &lt; l2 &#123; return -1 &#125; i, j := 0, 0 x := i for &#123; if i &gt;= l1 || j &gt;= l2 &#123; break &#125; if haystack[i] == needle[j] &#123; if j == l2-1 &#123; return i - l2 + 1 &#125; else &#123; i++ j++ &#125; &#125; else &#123; i = x + 1 x++ j = 0 &#125; &#125; return -1&#125;本地测试package mainimport ( \"fmt\")func main() &#123; a, b := \"hello\", \"ll\" fmt.Println(strStr(a, b)) a, b = \"aaaaa\", \"bba\" fmt.Println(strStr(a, b)) a, b = \"helllllo\", \"ll\" fmt.Println(strStr(a, b)) a, b = \"mississippi\", \"issip\" fmt.Println(strStr(a, b))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/implement-strstr","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"27. 移除元素","slug":"leetcode-cn/27","date":"2018-03-26T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/27/leetcode-cn/27/","link":"","permalink":"https://blazehu.github.io/2018/03/27/leetcode-cn/27/","excerpt":"题目描述给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。说明不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。示例给定 nums = [3,2,2,3], val = 3,函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。给定 nums = [0,1,2,2,3,0,4,2], val = 2,函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。","text":"题目描述给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。说明不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。示例给定 nums = [3,2,2,3], val = 3,函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。给定 nums = [0,1,2,2,3,0,4,2], val = 2,函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。解法func removeElement(nums []int, val int) int &#123; length := len(nums) if length &lt; 1 &#123; return 0 &#125; index := 0 for i := 0; i &lt; len(nums); i++ &#123; if val != nums[i] &#123; nums[index] = nums[i] index++ &#125; &#125; nums = nums[:index] return index&#125;本地测试package mainimport ( \"fmt\")func main() &#123; n, k := []int&#123;3, 2, 2, 3&#125;, 3 fmt.Println(removeElement(n, k)) n, k = []int&#123;0, 1, 2, 2, 3, 0, 4, 2&#125;, 2 fmt.Println(removeElement(n, k))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/remove-element","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"26. 删除排序数组中的重复项","slug":"leetcode-cn/26","date":"2018-03-25T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/26/leetcode-cn/26/","link":"","permalink":"https://blazehu.github.io/2018/03/26/leetcode-cn/26/","excerpt":"题目描述给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。说明不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。示例给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。你不需要考虑数组中超出新长度后面的元素。","text":"题目描述给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。说明不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。示例给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。你不需要考虑数组中超出新长度后面的元素。解法func removeDuplicates(nums []int) int &#123; length := len(nums) if length &lt; 1 &#123; return 0 &#125; else if length == 1 &#123; return 1 &#125; pre, index := nums[0], 0 for i := 1; i &lt; length; i++ &#123; if pre != nums[i] &#123; pre = nums[i] index++ nums[index] = nums[i] &#125; &#125; nums = nums[:index+1] return index + 1&#125;本地测试package mainimport ( \"fmt\")func main() &#123; n := []int&#123;1, 1, 1, 1, 1, 2, 3, 4, 5&#125; fmt.Println(removeDuplicates(n)) n = []int&#123;1, 1, 1, 1, 1, 2, 2, 2, 3, 4, 5&#125; fmt.Println(removeDuplicates(n)) n = []int&#123;1, 1, 1, 1, 1, 2, 3&#125; fmt.Println(removeDuplicates(n))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"25. K 个一组翻转链表","slug":"leetcode-cn/25","date":"2018-03-24T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/25/leetcode-cn/25/","link":"","permalink":"https://blazehu.github.io/2018/03/25/leetcode-cn/25/","excerpt":"题目描述给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。 k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。示例给你这个链表：1-&gt;2-&gt;3-&gt;4-&gt;5当 k = 2 时，应当返回: 2-&gt;1-&gt;4-&gt;3-&gt;5当 k = 3 时，应当返回: 3-&gt;2-&gt;1-&gt;4-&gt;5说明你的算法只能使用常数的额外空间。你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。","text":"题目描述给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。 k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。示例给你这个链表：1-&gt;2-&gt;3-&gt;4-&gt;5当 k = 2 时，应当返回: 2-&gt;1-&gt;4-&gt;3-&gt;5当 k = 3 时，应当返回: 3-&gt;2-&gt;1-&gt;4-&gt;5说明你的算法只能使用常数的额外空间。你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。解法空间换时间， 暴力解法func reverseKGroup(head *ListNode, k int) *ListNode &#123; if k &lt;= 1 &#123; return head &#125; var ( lists []ListNode newLists []ListNode ) p := head for p != nil &#123; lists = append(lists, *p) p = p.Next &#125; length := len(lists) if length &lt;= 1 || length &lt; k &#123; return head &#125; newLists = make([]ListNode, length) reverse := func(s []ListNode, x int) &#123; for i, j := 0, len(s)-1; i &lt;= j; i, j = i+1, j-1 &#123; newLists[x+i], newLists[x+j] = s[j], s[i] &#125; &#125; for i := 0; i &lt; length/k; i ++ &#123; x := i * k reverse(lists[x:k+x], x) &#125; for i := (length / k) * k; i &lt; length; i++ &#123; newLists[i] = lists[i] &#125; head = &amp;newLists[0] point := head for i := 1; i &lt; len(newLists); i++ &#123; point.Next = &amp;newLists[i] point = point.Next &#125; point.Next = nil return head&#125;本地测试package mainimport ( \"fmt\")type ListNode struct &#123; Val int Next *ListNode&#125;func createListNode(a []int) *ListNode &#123; var head *ListNode if len(a) &lt; 1 &#123; return head &#125; head = &amp;ListNode&#123;Val: a[0]&#125; p := head a = a[1:] for _, item := range a &#123; n := ListNode&#123;Val: item&#125; p.Next = &amp;n p = p.Next &#125; return head&#125;func printListNode(head *ListNode) &#123; if head == nil &#123; fmt.Println(\"nil\") return &#125; for head.Next != nil &#123; fmt.Print(head.Val, \" -&gt; \") head = head.Next &#125; if head != nil &#123; fmt.Print(head.Val, \" -&gt; nil\\n\") &#125;&#125;func main() &#123; n, k := createListNode([]int&#123;1, 2, 3, 4, 5, 6&#125;), 3 printListNode(reverseKGroup(n, k)) n, k = createListNode([]int&#123;1, 2, 3, 4, 5&#125;), 3 printListNode(reverseKGroup(n, k)) n, k = createListNode([]int&#123;1, 2, 3, 4, 5, 6&#125;), 2 printListNode(reverseKGroup(n, k)) n, k = createListNode([]int&#123;&#125;), 2 printListNode(reverseKGroup(n, k))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/reverse-nodes-in-k-group","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"24. 两两交换链表中的节点","slug":"leetcode-cn/24","date":"2018-03-23T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/24/leetcode-cn/24/","link":"","permalink":"https://blazehu.github.io/2018/03/24/leetcode-cn/24/","excerpt":"题目描述给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。示例给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3.","text":"题目描述给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。示例给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3.解法空间换时间， 暴力解法func swapPairs(head *ListNode) *ListNode &#123; if head == nil || head.Next == nil &#123; return head &#125; var lists []ListNode p := head for p != nil &#123; lists = append(lists, *p) p = p.Next &#125; for i := 0; i &lt; len(lists)-1; i += 2 &#123; lists[i], lists[i+1] = lists[i+1], lists[i] &#125; head = &amp;lists[0] point := head for i := 1; i &lt; len(lists); i++ &#123; point.Next = &amp;lists[i] point = point.Next &#125; point.Next = nil return head&#125;本地测试package mainimport ( \"fmt\")type ListNode struct &#123; Val int Next *ListNode&#125;func createListNode(a []int) *ListNode &#123; var head *ListNode if len(a) &lt; 1 &#123; return head &#125; head = &amp;ListNode&#123;Val: a[0]&#125; p := head a = a[1:] for _, item := range a &#123; n := ListNode&#123;Val: item&#125; p.Next = &amp;n p = p.Next &#125; return head&#125;func printListNode(head *ListNode) &#123; if head == nil &#123; fmt.Println(\"nil\") return &#125; for head.Next != nil &#123; fmt.Print(head.Val, \" -&gt; \") head = head.Next &#125; if head != nil &#123; fmt.Print(head.Val, \" -&gt; nil\\n\") &#125;&#125;func main() &#123; n := createListNode([]int&#123;1, 2, 3, 4, 5, 6&#125;) printListNode(swapPairs(n))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/swap-nodes-in-pairs","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"23. 合并K个排序链表","slug":"leetcode-cn/23","date":"2018-03-22T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/23/leetcode-cn/23/","link":"","permalink":"https://blazehu.github.io/2018/03/23/leetcode-cn/23/","excerpt":"题目描述合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。示例输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6","text":"题目描述合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。示例输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6解法func mergeKLists(lists []*ListNode) *ListNode &#123; if len(lists) &lt; 1 &#123; return nil &#125; if len(lists) == 1 &#123; return lists[0] &#125; var ( mix int nilNum int length int l *ListNode p *ListNode pre *ListNode ) length = len(lists) l = &amp;ListNode&#123;&#125; p = l pre = p const MaxNum = 999999999 for nilNum &lt; length &#123; mix = MaxNum nilNum = 0 for i := 0; i &lt; length; i++ &#123; if lists[i] == nil &#123; nilNum++ &#125; else if mix &gt; lists[i].Val &#123; mix = lists[i].Val &#125; &#125; for i := 0; i &lt; length; i++ &#123; if lists[i] != nil &amp;&amp; mix == lists[i].Val &#123; p.Val = mix lists[i] = lists[i].Next break &#125; &#125; if nilNum &lt; length &amp;&amp; mix != MaxNum &#123; p.Next = &amp;ListNode&#123;&#125; pre = p p = p.Next &#125; else if mix == MaxNum &#123; pre.Next = nil &#125; else &#123; p.Next = nil &#125; if nilNum == length &amp;&amp; mix == MaxNum &amp;&amp; p == pre &#123; return nil &#125; &#125; return l&#125;本地测试package mainimport ( \"fmt\")type ListNode struct &#123; Val int Next *ListNode&#125;func createListNode(a []int) *ListNode &#123; var head *ListNode if len(a) &lt; 1 &#123; return head &#125; head = &amp;ListNode&#123;Val: a[0]&#125; p := head a = a[1:] for _, item := range a &#123; n := ListNode&#123;Val: item&#125; p.Next = &amp;n p = p.Next &#125; return head&#125;func printListNode(head *ListNode) &#123; if head == nil &#123; fmt.Println(\"nil\") return &#125; for head.Next != nil &#123; fmt.Print(head.Val, \" -&gt; \") head = head.Next &#125; if head != nil &#123; fmt.Print(head.Val, \" -&gt; nil\\n\") &#125;&#125;func main() &#123; n := []*ListNode&#123;createListNode([]int&#123;1, 4, 5&#125;), createListNode([]int&#123;1, 3, 4&#125;), createListNode([]int&#123;2, 6&#125;)&#125; printListNode(mergeKLists(n)) n = []*ListNode&#123;createListNode([]int&#123;1&#125;), createListNode([]int&#123;&#125;),&#125; printListNode(mergeKLists(n)) n = []*ListNode&#123;createListNode([]int&#123;&#125;), createListNode([]int&#123;1, 2&#125;),&#125; printListNode(mergeKLists(n)) n = []*ListNode&#123;createListNode([]int&#123;1, 2, 3&#125;), createListNode([]int&#123;4, 5, 6, 7&#125;),&#125; printListNode(mergeKLists(n)) n = []*ListNode&#123;createListNode([]int&#123;&#125;), createListNode([]int&#123;&#125;),&#125; printListNode(mergeKLists(n))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/merge-k-sorted-lists","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"22. 括号生成","slug":"leetcode-cn/22","date":"2018-03-21T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/22/leetcode-cn/22/","link":"","permalink":"https://blazehu.github.io/2018/03/22/leetcode-cn/22/","excerpt":"题目描述数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。示例输入：n = 3输出：[ \"((()))\", \"(()())\", \"(())()\", \"()(())\", \"()()()\" ]","text":"题目描述数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。示例输入：n = 3输出：[ \"((()))\", \"(()())\", \"(())()\", \"()(())\", \"()()()\" ]解法： 递归func backtrack(l, r, n int, str string, strList *[]string) &#123; if l &lt; r &#123; return &#125; if len(str) == 2*n &#123; *strList = append(*strList, str) &#125; if l &lt; n &#123; backtrack(l+1, r, n, str+\"(\", strList) &#125; if r &lt; n &#123; backtrack(l, r+1, n, str+\")\", strList) &#125;&#125;func generateParenthesis(n int) []string &#123; strList := &amp;[]string&#123;&#125; backtrack(0, 0, n, \"\", strList) return *strList&#125;本地测试package mainimport ( \"fmt\")func main() &#123; fmt.Println(generateParenthesis(1)) fmt.Println(generateParenthesis(2)) fmt.Println(generateParenthesis(3)) fmt.Println(generateParenthesis(4))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/generate-parentheses","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"21. 合并两个有序链表","slug":"leetcode-cn/21","date":"2018-03-20T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/21/leetcode-cn/21/","link":"","permalink":"https://blazehu.github.io/2018/03/21/leetcode-cn/21/","excerpt":"题目描述将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。示例输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4","text":"题目描述将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。示例输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4解法func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode &#123; var ( l *ListNode p *ListNode ) if l1 == nil &amp;&amp; l2 == nil &#123; return nil &#125; l = &amp;ListNode&#123;&#125; p = l for l1 != nil || l2 != nil &#123; if l1 == nil &#123; p.Val = l2.Val l2 = l2.Next &#125; else if l2 == nil &#123; p.Val = l1.Val l1 = l1.Next &#125; else if l1.Val &gt; l2.Val &#123; p.Val = l2.Val l2 = l2.Next &#125; else &#123; p.Val = l1.Val l1 = l1.Next &#125; if l1 == nil &amp;&amp; l2 == nil &#123; p.Next = nil &#125; else &#123; p.Next = &amp;ListNode&#123;&#125; p = p.Next &#125; &#125; return l&#125;本地测试package mainimport ( \"fmt\")type ListNode struct &#123; Val int Next *ListNode&#125;func createListNode(a []int) *ListNode &#123; var head *ListNode if len(a) &lt; 1 &#123; return head &#125; head = &amp;ListNode&#123;Val: a[0]&#125; p := head a = a[1:] for _, item := range a &#123; n := ListNode&#123;Val: item&#125; p.Next = &amp;n p = p.Next &#125; return head&#125;func printListNode(head *ListNode) &#123; for head.Next != nil &#123; fmt.Print(head.Val, \" -&gt; \") head = head.Next &#125; if head != nil &#123; fmt.Print(head.Val, \"\\n\") &#125;&#125;func main() &#123; a, b := createListNode([]int&#123;1, 2, 4&#125;), createListNode([]int&#123;1, 3, 4&#125;) printListNode(a) printListNode(b) printListNode(mergeTwoLists(a, b))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/merge-two-sorted-lists","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"20. 有效的括号","slug":"leetcode-cn/20","date":"2018-03-19T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/20/leetcode-cn/20/","link":"","permalink":"https://blazehu.github.io/2018/03/20/leetcode-cn/20/","excerpt":"题目描述给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。说明有效字符串需满足：左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。示例输入: \"()\"输出: true输入: \"()[]&#123;&#125;\"输出: true输入: \"(]\"输出: false输入: \"([)]\"输出: false输入: \"&#123;[]&#125;\"输出: true","text":"题目描述给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。说明有效字符串需满足：左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。示例输入: \"()\"输出: true输入: \"()[]&#123;&#125;\"输出: true输入: \"(]\"输出: false输入: \"([)]\"输出: false输入: \"&#123;[]&#125;\"输出: true解法： 栈func isValid(s string) bool &#123; var ( stack *list.List ) stack = list.New() for _, item := range s &#123; if item == 40 || item == 91 || item == 123 &#123; stack.PushBack(item) continue &#125; x := stack.Back() if x == nil &#123; return false &#125; r := x.Value.(int32) if item == 41 &amp;&amp; r == 40 &#123; stack.Remove(x) &#125; else if item == 93 &amp;&amp; r == 91 &#123; stack.Remove(x) &#125; else if item == 125 &amp;&amp; r == 123 &#123; stack.Remove(x) &#125; else &#123; return false &#125; &#125; return stack.Len() == 0&#125;本地测试package mainimport ( \"fmt\" \"container/list\")func main() &#123; s := \"()\" fmt.Println(isValid(s)) s = \"[()]\" fmt.Println(isValid(s)) s = \"(&#123;)&#125;\" fmt.Println(isValid(s)) s = \"()[]\" fmt.Println(isValid(s)) s = \"([&#123;&#125;])\" fmt.Println(isValid(s)) s = \"]\" fmt.Println(isValid(s)) s = \"(])\" fmt.Println(isValid(s))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/valid-parentheses","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"19. 删除链表的倒数第N个节点","slug":"leetcode-cn/19","date":"2018-03-18T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/19/leetcode-cn/19/","link":"","permalink":"https://blazehu.github.io/2018/03/19/leetcode-cn/19/","excerpt":"题目描述给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。给定的 n 保证是有效的。示例给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2.当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.","text":"题目描述给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。给定的 n 保证是有效的。示例给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2.当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.解法暴力解法扫描一遍，使用数组存储所有节点func removeNthFromEnd(head *ListNode, n int) *ListNode &#123; var ( p *ListNode pList []*ListNode ) p = head for p != nil &#123; pList = append(pList, p) p = p.Next &#125; l := len(pList) if l == 1 &amp;&amp; n == 1 &#123; return nil &#125; pre := l - n - 1 next := l - n + 1 if next &gt;= l &#123; pList[pre].Next = nil &#125; else if pre &lt; 0 &#123; head = head.Next &#125; else &#123; pList[pre].Next = pList[next] &#125; return head&#125;双指针i, j 双指针初始化为表头和表头后 n 个节点。i 和 j 双指针保持窗口大小为 n （间距）同时向后移动，当 j 移动到表尾， i 指向的就是我们要找的倒数第 n 个节点。本地测试package mainimport ( \"fmt\")type ListNode struct &#123; Val int Next *ListNode&#125;func createListNode(a []int) *ListNode &#123; var head *ListNode if len(a) &lt; 1 &#123; return head &#125; head = &amp;ListNode&#123;Val: a[0]&#125; p := head a = a[1:] for _, item := range a &#123; n := ListNode&#123;Val: item&#125; p.Next = &amp;n p = p.Next &#125; return head&#125;func printListNode(head *ListNode) &#123; for head.Next != nil &#123; fmt.Print(head.Val, \" -&gt; \") head = head.Next &#125; if head != nil &#123; fmt.Print(head.Val, \"\\n\") &#125;&#125;func main() &#123; a := createListNode([]int&#123;1, 2, 3, 4, 5&#125;) printListNode(a) printListNode(removeNthFromEnd(a, 5))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/remove-nth-node-from-end-of-list","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"18. 四数之和","slug":"leetcode-cn/18","date":"2018-03-17T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/18/leetcode-cn/18/","link":"","permalink":"https://blazehu.github.io/2018/03/18/leetcode-cn/18/","excerpt":"题目描述：给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。说明：答案中不可以包含重复的四元组。示例：给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。满足要求的四元组集合为：[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]]","text":"题目描述：给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。说明：答案中不可以包含重复的四元组。示例：给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。满足要求的四元组集合为：[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]]解法func fourSum(nums []int, target int) [][]int &#123; sort.Ints(nums) retNum := make([][]int, 0) retMiddleNums := make(map[string]string, 0) retNumStr := make([]string, 0) numLength := len(nums) for x := 0; x &lt; numLength-3; x++ &#123; for i := x + 1; i &lt; numLength-2; i++ &#123; k := i + 1 j := numLength - 1 for k &lt; j &#123; a, b, c, d := nums[i], nums[k], nums[j], nums[x] if a+b+c+d &lt; target &#123; k++ &#125; else if a+b+c+d &gt; target &#123; j-- &#125; else &#123; subRet := append([]int&#123;&#125;, a, b, c, d) sort.Ints(subRet) var numStrList []string var numStr string for i := 0; i &lt; len(subRet); i++ &#123; numStrList = append(numStrList, strconv.Itoa(subRet[i])) &#125; numStr = strings.Join(numStrList, \",\") retMiddleNums[numStr] = \"\" for (k &lt; j) &amp;&amp; (b == nums[k+1]) &#123; k++ &#125; for (k &lt; j) &amp;&amp; (c == nums[j-1]) &#123; j-- &#125; k++ j-- &#125; &#125; &#125; &#125; for numStr := range retMiddleNums &#123; retNumStr = append(retNumStr, numStr) &#125; for index := 0; index &lt; len(retNumStr); index++ &#123; strNumList := strings.Split(retNumStr[index], \",\") var retNumItem []int for i := 0; i &lt; len(strNumList); i++ &#123; numItem, _ := strconv.Atoi(strNumList[i]) retNumItem = append(retNumItem, numItem) &#125; retNum = append(retNum, retNumItem) &#125; return retNum&#125;本地测试package mainimport ( \"fmt\" \"sort\" \"strconv\" \"strings\")func main() &#123; nums, target := []int&#123;0, 0, 0, 0&#125;, 0 fmt.Println(fourSum(nums, target)) nums, target = []int&#123;1, 0, -1, 0, -2, 2&#125;, 0 fmt.Println(fourSum(nums, target)) nums, target = []int&#123;1, 1, 1, 1, 0, -1, 0, -2, 2, -1, -1, -1, -1&#125;, 0 fmt.Println(fourSum(nums, target)) nums, target = []int&#123;1, 1, 1, 1, 0, -1, 0, -2, 2, -1, -1, -1, -1&#125;, 4 fmt.Println(fourSum(nums, target))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/4sum","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"17. 电话号码的字母组合","slug":"leetcode-cn/17","date":"2018-03-16T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/17/leetcode-cn/17/","link":"","permalink":"https://blazehu.github.io/2018/03/17/leetcode-cn/17/","excerpt":"题目描述给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。给出数字到字母的映射如下（与电话按键相同）。说明1 不对应任何字母。示例输入：\"23\"输出：[\"ad\", \"ae\", \"af\", \"bd\", \"be\", \"bf\", \"cd\", \"ce\", \"cf\"].","text":"题目描述给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。给出数字到字母的映射如下（与电话按键相同）。说明1 不对应任何字母。示例输入：\"23\"输出：[\"ad\", \"ae\", \"af\", \"bd\", \"be\", \"bf\", \"cd\", \"ce\", \"cf\"].解法（递归求解）func letterCombinations(digits string) []string &#123; var ( all []string ) if len(digits) &lt; 1 &#123; return []string&#123;&#125; &#125; numMap := map[string][]string&#123; \"2\": &#123;\"a\", \"b\", \"c\"&#125;, \"3\": &#123;\"d\", \"e\", \"f\"&#125;, \"4\": &#123;\"g\", \"h\", \"i\"&#125;, \"5\": &#123;\"j\", \"k\", \"l\"&#125;, \"6\": &#123;\"m\", \"n\", \"o\"&#125;, \"7\": &#123;\"p\", \"q\", \"r\", \"s\"&#125;, \"8\": &#123;\"t\", \"u\", \"v\"&#125;, \"9\": &#123;\"w\", \"x\", \"y\", \"z\"&#125;, &#125; getTwoLetterCombinations := func(num1, num2 []string) []string &#123; var ( strList []string ) l1, l2 := len(num1), len(num2) i := 0 for i &lt; l1 &#123; j := 0 for j &lt; l2 &#123; strList = append(strList, num1[i]) j++ &#125; i++ &#125; i = 0 for i &lt; l2*l1 &#123; strList[i] += num2[i%l2] i++ &#125; return strList &#125; numStr := string(digits[0]) all = numMap[numStr] for index := 1; index &lt; len(digits); index++ &#123; numStr := string(digits[index]) numStrList := numMap[numStr] all = getTwoLetterCombinations(all, numStrList) &#125; return all&#125;本地测试package mainimport ( \"fmt\")func main() &#123; s := \"23\" fmt.Println(letterCombinations(s)) s = \"2\" fmt.Println(letterCombinations(s)) s = \"27\" fmt.Println(letterCombinations(s)) s = \"234\" fmt.Println(letterCombinations(s)) s = \"34\" fmt.Println(letterCombinations(s))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"16. 最接近的三数之和","slug":"leetcode-cn/16","date":"2018-03-15T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/16/leetcode-cn/16/","link":"","permalink":"https://blazehu.github.io/2018/03/16/leetcode-cn/16/","excerpt":"题目描述给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。示例给定数组 nums = [-1，2，1，-4], 和 target = 1.与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2).","text":"题目描述给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。示例给定数组 nums = [-1，2，1，-4], 和 target = 1.与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2).解法func threeSumClosest(nums []int, target int) int &#123; var ( l int r int t int sumList []int sum int ) abs := func(x int) (int, bool) &#123; if x &lt; 0 &#123; return x * -1, true &#125; return x, false &#125; length := func(x, y int) int &#123; if x &gt;= 0 &amp;&amp; y &lt;= 0 &#123; return x - y &#125; else if x &lt;= 0 &amp;&amp; y &gt;= 0 &#123; return y - x &#125; else &#123; if x &gt; y &#123; return x - y &#125; else &#123; return y - x &#125; &#125; &#125; l, r = 0, len(nums)-1 if r &lt; 2 &#123; return 0 &#125; if r == 2 &#123; return nums[0] + nums[1] + nums[2] &#125; sort.Ints(nums) for &#123; if l &gt;= r &#123; break &#125; m := nums[l] + nums[r] perfectValue := target - m dValue, direction := -1, true for index := 0; index &lt; len(nums); index++ &#123; if index == l || index == r &#123; continue &#125; if nums[index] == perfectValue &#123; return target &#125; x, y := abs(nums[index] - perfectValue) if dValue &lt; 0 &#123; dValue, direction, t = x, y, nums[index] continue &#125; if dValue &gt; x &#123; dValue, direction, t = x, y, nums[index] &#125; &#125; sumList = append(sumList, m+t) if direction &#123; l++ &#125; else &#123; r-- &#125; &#125; sort.Ints(sumList) if len(sumList) &lt; 1 &#123; return 0 &#125; else if len(sumList) == 1 &#123; return sumList[0] &#125; else &#123; sum = sumList[0] dValue := length(sum, target) index := 1 for index &lt; len(sumList) &#123; if dValue &gt; length(sumList[index], target) &#123; sum = sumList[index] dValue = length(sum, target) &#125; index++ &#125; &#125; return sum&#125;本地测试package mainimport ( \"fmt\" \"sort\")func main() &#123; nums, target := []int&#123;-1, 2, 1, -4&#125;, 1 fmt.Println(threeSumClosest(nums, target)) nums, target = []int&#123;-1, 0, 1, 1, 55&#125;, 3 fmt.Println(threeSumClosest(nums, target)) nums, target = []int&#123;1, 2, 5, 10, 11&#125;, 12 fmt.Println(threeSumClosest(nums, target))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/3sum-closest","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"15. 三数之和","slug":"leetcode-cn/15","date":"2018-03-14T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/15/leetcode-cn/15/","link":"","permalink":"https://blazehu.github.io/2018/03/15/leetcode-cn/15/","excerpt":"题目描述给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。说明答案中不可以包含重复的三元组。示例给定数组 nums = [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]]","text":"题目描述给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。说明答案中不可以包含重复的三元组。示例给定数组 nums = [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]]解法func threeSum(nums []int) [][]int &#123; sort.Ints(nums) retNum := make([][]int, 0) numLength := len(nums) for i := 0; (i &lt; numLength-2) &amp;&amp; (nums[i] &lt;= 0); i++ &#123; k := i + 1 j := numLength - 1 if (i &gt; 0) &amp;&amp; (nums[i] == nums[i-1]) &#123; continue &#125; for k &lt; j &#123; a, b, c := nums[i], nums[k], nums[j] if a+b+c &lt; 0 &#123; k++ &#125; else if a+b+c &gt; 0 &#123; j-- &#125; else &#123; subRet := append([]int&#123;&#125;, a, b, c) retNum = append(retNum, subRet) for (k &lt; j) &amp;&amp; (b == nums[k+1]) &#123; k++ &#125; for (k &lt; j) &amp;&amp; (c == nums[j-1]) &#123; j-- &#125; k++ j-- &#125; &#125; &#125; return retNum&#125;本地测试package mainimport ( \"fmt\" \"sort\")func main() &#123; nums := []int&#123;-1, 0, 1, 2, -1, -4&#125; fmt.Println(threeSum(nums)) nums = []int&#123;&#125; fmt.Println(threeSum(nums)) nums = []int&#123;1, 1, -2&#125; fmt.Println(threeSum(nums)) nums = []int&#123;0, 0, 0&#125; fmt.Println(threeSum(nums)) nums = []int&#123;-4, -2, -2, -2, 0, 1, 2, 2, 2, 3, 3, 4, 4, 6, 6&#125; fmt.Println(threeSum(nums)) nums = []int&#123;0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0&#125; fmt.Println(threeSum(nums))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/3sum","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"14. 最长公共前缀","slug":"leetcode-cn/14","date":"2018-03-13T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/14/leetcode-cn/14/","link":"","permalink":"https://blazehu.github.io/2018/03/14/leetcode-cn/14/","excerpt":"题目描述编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串 “”。说明所有输入只包含小写字母 a-z。示例示例 1:输入: [\"flower\",\"flow\",\"flight\"]输出: \"fl\"示例 2:输入: [\"dog\",\"racecar\",\"car\"]输出: \"\"解释: 输入不存在公共前缀。","text":"题目描述编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串 “”。说明所有输入只包含小写字母 a-z。示例示例 1:输入: [\"flower\",\"flow\",\"flight\"]输出: \"fl\"示例 2:输入: [\"dog\",\"racecar\",\"car\"]输出: \"\"解释: 输入不存在公共前缀。解法func longestCommonPrefix(strs []string) string &#123; var ( index int prefixStr uint8 ) if len(strs) &lt; 1 &#123; return \"\" &#125; else if len(strs) == 1 &#123; return strs[0] &#125; if len(strs[0]) &lt; 1 &#123; return \"\" &#125; index = 0 for &#123; if index &gt;= len(strs[0]) &#123; return strs[0][:index] &#125; for strIndex := 1; strIndex &lt; len(strs); strIndex++ &#123; if index &gt;= len(strs[strIndex]) &#123; return strs[0][:index] &#125; prefixStr = strs[0][index] if strs[strIndex][index] != prefixStr &#123; return strs[0][:index] &#125; &#125; index++ &#125; return strs[0][:index]&#125;本地测试package mainimport \"fmt\"func main() &#123; s := []string&#123;\"flower\", \"flow\", \"flight\"&#125; fmt.Println(longestCommonPrefix(s)) s = []string&#123;\"dog\", \"area\", \"car\"&#125; fmt.Println(longestCommonPrefix(s)) s = []string&#123;\"a\", \"a\", \"ab\"&#125; fmt.Println(longestCommonPrefix(s)) s = []string&#123;\"abcd\", \"a\", \"ab\"&#125; fmt.Println(longestCommonPrefix(s)) s = []string&#123;\"a\"&#125; fmt.Println(longestCommonPrefix(s)) s = []string&#123;\"a\", \"ac\"&#125; fmt.Println(longestCommonPrefix(s))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-common-prefix","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"13. 罗马数字转整数","slug":"leetcode-cn/13","date":"2018-03-12T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/13/leetcode-cn/13/","link":"","permalink":"https://blazehu.github.io/2018/03/13/leetcode-cn/13/","excerpt":"题目描述罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。","text":"题目描述罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。示例示例 1:输入: \"III\"输出: 3示例 2:输入: \"IV\"输出: 4示例 3:输入: \"LVIII\"输出: 58解释: L = 50, V= 5, III = 3.示例 4:输入: \"MCMXCIV\"输出: 1994解释: M = 1000, CM = 900, XC = 90, IV = 4.解法func romanToInt(s string) int &#123; var ( num int b int e int flag bool // 用来判断最后一位有效罗马数字是否计算过 ) numMap := map[string]int&#123; \"I\": 1, \"II\": 2, \"III\": 3, \"IV\": 4, \"V\": 5, \"VI\": 6, \"VII\": 7, \"VIII\": 8, \"IX\": 9, \"X\": 10, \"XX\": 20, \"XXX\": 30, \"XL\": 40, \"L\": 50, \"LX\": 60, \"LXX\": 70, \"LXXX\": 80, \"XC\": 90, \"C\": 100, \"CC\": 200, \"CCC\": 300, \"CD\": 400, \"D\": 500, \"DC\": 600, \"DCC\": 700, \"DCCC\": 800, \"CM\": 900, \"M\": 1000, \"MM\": 2000, \"MMM\": 3000, &#125; flag = true for b, e = 0, 1; e &lt;= len(s); e++ &#123; if numMap[s[b:e]] == 0 &#123; flag = false num += numMap[s[b:e-1]] b = e - 1 &#125; else if e == len(s) &#123; flag = true num += numMap[s[b:e]] &#125; &#125; if !flag &#123; num += numMap[s[b:e-1]] &#125; return num&#125;本地测试package mainimport \"fmt\"func main() &#123; s := \"III\" fmt.Println(romanToInt(s)) s = \"IV\" fmt.Println(romanToInt(s)) s = \"IX\" fmt.Println(romanToInt(s)) s = \"LVIII\" fmt.Println(romanToInt(s)) s = \"MCMXCIV\" fmt.Println(romanToInt(s)) s = \"DCXXI\" fmt.Println(romanToInt(s)) s = \"XIII\" fmt.Println(romanToInt(s)) s = \"XI\" fmt.Println(romanToInt(s))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/roman-to-integer","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"12. 整数转罗马数字","slug":"leetcode-cn/12","date":"2018-03-11T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/12/leetcode-cn/12/","link":"","permalink":"https://blazehu.github.io/2018/03/12/leetcode-cn/12/","excerpt":"题目描述罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。","text":"题目描述罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。字符 数值I 1V 5X 10L 50C 100D 500M 1000例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。示例示例 1:输入: 3输出: \"III\"示例 2:输入: 4输出: \"IV\"示例 3:输入: 9输出: \"IX\"示例 4:输入: 58输出: \"LVIII\"解释: L = 50, V = 5, III = 3.示例 5:输入: 1994输出: \"MCMXCIV\"解释: M = 1000, CM = 900, XC = 90, IV = 4.解法func intToRoman(num int) string &#123; var ( numStr string k int ) numMap := map[int][]string&#123; 0: &#123;\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"&#125;, 1: &#123;\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"&#125;, 2: &#123;\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"&#125;, 3: &#123;\"\", \"M\", \"MM\", \"MMM\"&#125;, &#125; if num &lt; 1 || num &gt; 3999 &#123; return \"\" &#125; else &#123; for num &gt; 0 &#123; numStr = numMap[k][num%10] + numStr num /= 10 k++ &#125; &#125; return numStr&#125;本地测试package mainimport \"fmt\"func main() &#123; n := 3 fmt.Println(intToRoman(n)) n = 4 fmt.Println(intToRoman(n)) n = 9 fmt.Println(intToRoman(n)) n = 58 fmt.Println(intToRoman(n)) n = 1994 fmt.Println(intToRoman(n))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/integer-to-roman","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"11. 盛最多水的容器","slug":"leetcode-cn/11","date":"2018-03-10T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/11/leetcode-cn/11/","link":"","permalink":"https://blazehu.github.io/2018/03/11/leetcode-cn/11/","excerpt":"题目描述给你 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。说明你不能倾斜容器，且 n 的值至少为 2。示例输入：[1,8,6,2,5,4,8,3,7]输出：49","text":"题目描述给你 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。说明你不能倾斜容器，且 n 的值至少为 2。示例输入：[1,8,6,2,5,4,8,3,7]输出：49解法func maxArea(height []int) int &#123; var ( b int e int area int ) getArea := func(x1, x2 int) int &#123; x := x1 - x2 if x &lt; 0 &#123; x *= -1 &#125; if height[x1] &gt; height[x2] &#123; return height[x2] * x &#125; else &#123; return height[x1] * x &#125; &#125; getMax := func(x, y int) int &#123; if x &gt; y &#123; return x &#125; return y &#125; b, e = 0, len(height)-1 for b &lt; e &#123; area = getMax(getArea(b, e), area) if height[b] &lt; height[e] &#123; b++ &#125; else &#123; e-- &#125; &#125; return area&#125;本地测试package mainimport \"fmt\"func main() &#123; n := []int&#123;2, 3, 4, 5, 18, 17, 6&#125; fmt.Println(maxArea(n)) n = []int&#123;1, 8, 6, 2, 5, 4, 8, 3, 7&#125; fmt.Println(maxArea(n))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/container-with-most-water","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"10. 正则表达式匹配","slug":"leetcode-cn/10","date":"2018-03-09T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/10/leetcode-cn/10/","link":"","permalink":"https://blazehu.github.io/2018/03/10/leetcode-cn/10/","excerpt":"题目描述给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 ‘.’ 和 ‘*’ 的正则表达式匹配。‘.’ 匹配任意单个字符‘*’ 匹配零个或多个前面的那一个元素所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。说明s 可能为空，且只包含从 a-z 的小写字母。p 可能为空，且只包含从 a-z 的小写字母，以及字符 . 和 *。","text":"题目描述给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 ‘.’ 和 ‘*’ 的正则表达式匹配。‘.’ 匹配任意单个字符‘*’ 匹配零个或多个前面的那一个元素所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。说明s 可能为空，且只包含从 a-z 的小写字母。p 可能为空，且只包含从 a-z 的小写字母，以及字符 . 和 *。示例示例 1:输入:s = \"aa\"p = \"a\"输出: false解释: \"a\" 无法匹配 \"aa\" 整个字符串。示例 2:输入:s = \"aa\"p = \"a*\"输出: true解释: 因为 '*' 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 'a'。因此，字符串 \"aa\" 可被视为 'a' 重复了一次。示例 3:输入:s = \"ab\"p = \".*\"输出: true解释: \".*\" 表示可匹配零个或多个（'*'）任意字符（'.'）。示例 4:输入:s = \"aab\"p = \"c*a*b\"输出: true解释: 因为 '*' 表示零个或多个，这里 'c' 为 0 个, 'a' 被重复一次。因此可以匹配字符串 \"aab\"。示例 5:输入:s = \"mississippi\"p = \"mis*is*p*.\"输出: false解法func isMatch(s string, p string) bool &#123; strList := regexp.MustCompile(p).FindAllString(s, -1) for index := 0; index &lt; len(strList); index++ &#123; if strList[index] == s &#123; return true &#125; &#125; return false&#125;func isMatch(s string, p string) bool &#123; m, n := len(s), len(p) matches := func(i, j int) bool &#123; if i == 0 &#123; return false &#125; if p[j-1] == '.' &#123; return true &#125; return s[i-1] == p[j-1] &#125; f := make([][]bool, m + 1) for i := 0; i &lt; len(f); i++ &#123; f[i] = make([]bool, n + 1) &#125; f[0][0] = true for i := 0; i &lt;= m; i++ &#123; for j := 1; j &lt;= n; j++ &#123; if p[j-1] == '*' &#123; f[i][j] = f[i][j] || f[i][j-2] if matches(i, j - 1) &#123; f[i][j] = f[i][j] || f[i-1][j] &#125; &#125; else if matches(i, j) &#123; f[i][j] = f[i][j] || f[i-1][j-1] &#125; &#125; &#125; return f[m][n]&#125;本地测试package mainimport ( \"fmt\" \"regexp\")func main() &#123; // . 46, * 42 s, p := \"aa\", \"a\" fmt.Println(isMatch(s, p) == false) s, p = \"aa\", \"a*\" fmt.Println(isMatch(s, p) == true) s, p = \"ab\", \".*\" fmt.Println(isMatch(s, p) == true) s, p = \"ab\", \".*c\" fmt.Println(isMatch(s, p) == false) s, p = \"aab\", \"c*a*b\" fmt.Println(isMatch(s, p) == true) s, p = \"mississippi\", \"mis*is*p*.\" fmt.Println(isMatch(s, p) == false) s, p = \"bbcacbabbcbaaccabc\", \"b*a*a*.c*bb*b*.*.*\" fmt.Println(isMatch(s, p) == true) s, p = \"aaacb\", \"a*acb\" fmt.Println(isMatch(s, p) == true) s, p = \"aaa\", \"a*a\" fmt.Println(isMatch(s, p) == true) s, p = \"aaa\", \"ab*a*c*a\" fmt.Println(isMatch(s, p) == true)&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/regular-expression-matching","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"9. 回文数","slug":"leetcode-cn/9","date":"2018-03-08T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/09/leetcode-cn/9/","link":"","permalink":"https://blazehu.github.io/2018/03/09/leetcode-cn/9/","excerpt":"题目描述判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。示例示例 1:输入: 121输出: true示例 2:输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。示例 3:输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。","text":"题目描述判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。示例示例 1:输入: 121输出: true示例 2:输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。示例 3:输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。解法func isPalindrome(x int) bool &#123; if x &lt; 0 &#123; return false &#125; if x == 0 &#123; return true &#125; str := strconv.Itoa(x) strLength := len(str) for index := 0; index &lt; strLength; index++ &#123; if str[index] != str[strLength-index-1] &#123; return false &#125; &#125; return true&#125;本地测试package mainimport ( \"fmt\" \"strconv\")func main() &#123; n := 121 fmt.Println(isPalindrome(n), true) n = -121 fmt.Println(isPalindrome(n), false) n = 10 fmt.Println(isPalindrome(n), false)&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/palindrome-number","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"8. 字符串转换整数 (atoi)","slug":"leetcode-cn/8","date":"2018-03-07T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/08/leetcode-cn/8/","link":"","permalink":"https://blazehu.github.io/2018/03/08/leetcode-cn/8/","excerpt":"题目描述请你来实现一个 atoi 函数，使其能将字符串转换成整数。首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下：如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。在任何情况下，若函数不能进行有效的转换时，请返回 0 。说明本题中的空白字符只包括空格字符 ‘ ‘ 。假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，请返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。","text":"题目描述请你来实现一个 atoi 函数，使其能将字符串转换成整数。首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下：如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。在任何情况下，若函数不能进行有效的转换时，请返回 0 。说明本题中的空白字符只包括空格字符 ‘ ‘ 。假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，请返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。示例示例 1:输入: \"42\"输出: 42示例 2:输入: \" -42\"输出: -42解释: 第一个非空白字符为 '-', 它是一个负号。 我们尽可能将负号与后面所有连续出现的数字组合起来，最后得到 -42 。示例 3:输入: \"4193 with words\"输出: 4193解释: 转换截止于数字 '3' ，因为它的下一个字符不为数字。示例 4:输入: \"words and 987\"输出: 0解释: 第一个非空字符是 'w', 但它不是数字或正、负号。 因此无法执行有效的转换。示例 5:输入: \"-91283472332\"输出: -2147483648解释: 数字 \"-91283472332\" 超过 32 位有符号整数范围。 因此返回 INT_MIN (−231) 。解法func myAtoi(str string) int &#123; var ( f int numStr string num int k int ) for &#123; if len(str) &lt; 1 &#123; return 0 &#125; ch := str[0] if ch == 32 &#123; str = str[1:] &#125; else &#123; break &#125; &#125; ch := str[0] if ch == 45 &#123; str = str[1:] f = -1 &#125; else if ch == 43 &#123; str = str[1:] f = 1 &#125; else if ch &gt;= 48 &amp;&amp; ch &lt;= 57 &#123; f = 1 &#125; else &#123; f = 0 &#125; if f == 0 &#123; return 0 &#125; else &#123; for index := 0; index &lt; len(str); index++ &#123; if str[index] &gt;= 48 &amp;&amp; str[index] &lt;= 57 &#123; numStr += string(str[index]) &#125; else &#123; break &#125; &#125; &#125; newNumLength := len(numStr) for index := 0; index &lt; newNumLength; index++ &#123; if k != 0 &#123; num *= 10 &#125; num += int(numStr[index]) - 48 k++ if num*f &gt;= 2147483648 &#123; return 2147483647 &#125; if num*f &lt; -2147483648 &#123; return -2147483648 &#125; &#125; num = num * f return num&#125;本地测试package mainimport ( \"fmt\")func main() &#123; s := \"42\" fmt.Println(myAtoi(s), 42) s = \" \" fmt.Println(myAtoi(s), 0) s = \" \" fmt.Println(myAtoi(s), 0) s = \"\" fmt.Println(myAtoi(s), 0) s = \"-42\" fmt.Println(myAtoi(s), -42) s = \" -42\" fmt.Println(myAtoi(s), -42) s = \"+42\" fmt.Println(myAtoi(s), 42) s = \"0\" fmt.Println(myAtoi(s), 0) s = \"9\" fmt.Println(myAtoi(s), 9) s = \"4193 with words\" fmt.Println(myAtoi(s), 4193) s = \"words and 987\" fmt.Println(myAtoi(s), 0) s = \"-91283472332\" fmt.Println(myAtoi(s), -2147483648) s = \"2147483648\" fmt.Println(myAtoi(s), 2147483647) s = \"9223372036854775808\" fmt.Println(myAtoi(s), 2147483647)&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/string-to-integer-atoi","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"7. 整数反转","slug":"leetcode-cn/7","date":"2018-03-06T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/07/leetcode-cn/7/","link":"","permalink":"https://blazehu.github.io/2018/03/07/leetcode-cn/7/","excerpt":"题目描述给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。示例示例 1:输入: 123输出: 321 示例 2:输入: -123输出: -321示例 3:输入: 120输出: 21","text":"题目描述给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。示例示例 1:输入: 123输出: 321 示例 2:输入: -123输出: -321示例 3:输入: 120输出: 21解法func reverse(x int) int &#123; var ( n int k int f int ) f = 1 if x &lt; 0 &#123; f = -1 x *= f &#125; for x &gt; 0 &#123; if k != 0 &#123; n *= 10 &#125; n += x % 10 x /= 10 k++ &#125; n *= f if n &gt; 2147483648 || n &lt; -2147483648 &#123; n = 0 &#125; return n&#125;本地测试package mainimport ( \"fmt\")func main() &#123; n := 123 fmt.Println(reverse(n), n) n = -123 fmt.Println(reverse(n), n) n = 120 fmt.Println(reverse(n), n) n = 1534236469 fmt.Println(reverse(n), n) n = 1563847412 fmt.Println(reverse(n), n)&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/reverse-integer","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"6. Z 字形变换","slug":"leetcode-cn/6","date":"2018-03-05T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/06/leetcode-cn/6/","link":"","permalink":"https://blazehu.github.io/2018/03/06/leetcode-cn/6/","excerpt":"题目描述将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下：L C I RE T O E S I I GE D H N之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。请你实现这个将字符串进行指定行数变换的函数：string convert(string s, int numRows);示例示例 1:输入: s = \"LEETCODEISHIRING\", numRows = 3输出: \"LCIRETOESIIGEDHN\"示例 2:输入: s = \"LEETCODEISHIRING\", numRows = 4输出: \"LDREOEIIECIHNTSG\"解释:L D RE O E I IE C I H NT S G","text":"题目描述将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下：L C I RE T O E S I I GE D H N之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。请你实现这个将字符串进行指定行数变换的函数：string convert(string s, int numRows);示例示例 1:输入: s = \"LEETCODEISHIRING\", numRows = 3输出: \"LCIRETOESIIGEDHN\"示例 2:输入: s = \"LEETCODEISHIRING\", numRows = 4输出: \"LDREOEIIECIHNTSG\"解释:L D RE O E I IE C I H NT S G解法func convert(s string, numRows int) string &#123; var ( convertStr = \"\" convertSubStrList = make([]string, numRows) ) if numRows &lt; 1 &#123; return \"\" &#125; else if numRows == 1 &#123; return s &#125; for index := 0; index &lt; len(s); index++ &#123; k := index % (2*numRows - 2) y := 2*numRows - 2 - k if k &gt;= 0 &amp;&amp; k &lt; numRows &#123; convertSubStrList[k] += string(s[index]) &#125; else if y &gt;= 0 &amp;&amp; y &lt; numRows &#123; convertSubStrList[y] += string(s[index]) &#125; &#125; convertStr = strings.Join(convertSubStrList, \"\") return convertStr&#125;本地测试package mainimport ( \"fmt\" \"strings\")func main() &#123; s, l := \"LEETCODEISHIRING\", 3 fmt.Println(convert(s, l), \"LCIRETOESIIGEDHN\") s, l = \"LEETCODEISHIRING\", 4 fmt.Println(convert(s, l), \"LDREOEIIECIHNTSG\")&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/zigzag-conversion","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"5. 最长回文子串","slug":"leetcode-cn/5","date":"2018-03-04T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/05/leetcode-cn/5/","link":"","permalink":"https://blazehu.github.io/2018/03/05/leetcode-cn/5/","excerpt":"题目描述给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。示例示例 1：输入: \"babad\"输出: \"bab\"注意: \"aba\" 也是一个有效答案。示例 2：输入: \"cbbd\"输出: \"bb\"","text":"题目描述给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。示例示例 1：输入: \"babad\"输出: \"bab\"注意: \"aba\" 也是一个有效答案。示例 2：输入: \"cbbd\"输出: \"bb\"解法func longestPalindrome(s string) string &#123; var ( subStr = \"\" lenS int index int subK int maxLeftIndex int maxRightIndex int ) lenS = 2*len(s) - 1 for index &lt; lenS &#123; subK = 0 for &#123; leftIndex, rightIndex := index-subK, index+subK if leftIndex%2 != 0 &#123; leftIndex-- &#125; if rightIndex%2 != 0 &#123; rightIndex++ &#125; if leftIndex &lt; 0 || rightIndex &gt;= lenS &#123; break &#125; if s[leftIndex/2] == s[rightIndex/2] &#123; if maxRightIndex-maxLeftIndex &lt; rightIndex/2-leftIndex/2 &#123; maxLeftIndex, maxRightIndex = leftIndex/2, rightIndex/2 &#125; subK++ &#125; else &#123; break &#125; &#125; index++ &#125; if maxRightIndex &lt; len(s) &#123; subStr = s[maxLeftIndex:maxRightIndex+1] &#125; return subStr&#125;本地测试package mainimport \"fmt\"func main() &#123; s := \"babad\" fmt.Println(longestPalindrome(s)) s = \"cbbd\" fmt.Println(longestPalindrome(s)) s = \"abcd\" fmt.Println(longestPalindrome(s)) s = \"cbbb\" fmt.Println(longestPalindrome(s)) s = \"bbbc\" fmt.Println(longestPalindrome(s)) s = \"ababa\" fmt.Println(longestPalindrome(s)) s = \"bbbb\" fmt.Println(longestPalindrome(s))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-palindromic-substring","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"4. 寻找两个正序数组的中位数","slug":"leetcode-cn/4","date":"2018-03-03T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/04/leetcode-cn/4/","link":"","permalink":"https://blazehu.github.io/2018/03/04/leetcode-cn/4/","excerpt":"题目描述给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出这两个正序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。你可以假设 nums1 和 nums2 不会同时为空。示例nums1 = [1, 3]nums2 = [2]则中位数是 2.0示例 2:nums1 = [1, 2]nums2 = [3, 4]则中位数是 (2 + 3)/2 = 2.5","text":"题目描述给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出这两个正序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。你可以假设 nums1 和 nums2 不会同时为空。示例nums1 = [1, 3]nums2 = [2]则中位数是 2.0示例 2:nums1 = [1, 2]nums2 = [3, 4]则中位数是 (2 + 3)/2 = 2.5解法func findMedianSortedArrays(nums1 []int, nums2 []int) float64 &#123; var ( nums []int minNum int index int index1 int index2 int m float64 ) nums1Len, nums2Len := len(nums1), len(nums2) numsTotal := nums1Len + nums2Len for index = 0; index &lt; numsTotal; index++ &#123; if index &gt; numsTotal/2 &#123; break &#125; if index1 &lt; nums1Len &amp;&amp; index2 &lt; nums2Len &#123; if nums1[index1] &lt; nums2[index2] &#123; minNum = nums1[index1] index1++ &#125; else &#123; minNum = nums2[index2] index2++ &#125; &#125; else if index1 &lt; nums1Len &#123; minNum = nums1[index1] index1++ &#125; else if index2 &lt; nums2Len &#123; minNum = nums2[index2] index2++ &#125; else &#123; &#125; nums = append(nums, minNum) &#125; if numsTotal%2 != 0 &#123; m = float64(nums[index-1]) &#125; else &#123; m = float64(nums[index-1]+nums[index-2]) / 2 &#125; return m&#125;本地测试package mainimport \"fmt\"func main() &#123; a, b := []int&#123;1, 3&#125;, []int&#123;2&#125; fmt.Println(findMedianSortedArrays(a, b)) a, b = []int&#123;1, 2&#125;, []int&#123;3, 4, 5&#125; fmt.Println(findMedianSortedArrays(a, b)) a, b = []int&#123;1, 4&#125;, []int&#123;2, 3&#125; fmt.Println(findMedianSortedArrays(a, b)) a, b = []int&#123;1, 4, 5, 9&#125;, []int&#123;2, 3, 8, 10&#125; fmt.Println(findMedianSortedArrays(a, b))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/median-of-two-sorted-arrays","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"3. 无重复字符的最长子串","slug":"leetcode-cn/3","date":"2018-03-02T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/03/leetcode-cn/3/","link":"","permalink":"https://blazehu.github.io/2018/03/03/leetcode-cn/3/","excerpt":"题目描述给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。示例输入: \"abcabcbb\"输出: 3 解释: 因为无重复字符的最长子串是 \"abc\"，所以其长度为 3。示例 2:输入: \"bbbbb\"输出: 1解释: 因为无重复字符的最长子串是 \"b\"，所以其长度为 1。示例 3:输入: \"pwwkew\"输出: 3解释: 因为无重复字符的最长子串是 \"wke\"，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，\"pwke\" 是一个子序列，不是子串。","text":"题目描述给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。示例输入: \"abcabcbb\"输出: 3 解释: 因为无重复字符的最长子串是 \"abc\"，所以其长度为 3。示例 2:输入: \"bbbbb\"输出: 1解释: 因为无重复字符的最长子串是 \"b\"，所以其长度为 1。示例 3:输入: \"pwwkew\"输出: 3解释: 因为无重复字符的最长子串是 \"wke\"，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，\"pwke\" 是一个子序列，不是子串。解法func lengthOfLongestSubstring(s string) int &#123; if s == \"\" &#123; return 0 &#125; var ( maxX = 0 maxY = 1 x = 0 y = 1 ) charList := []byte(s) for x &lt;= y &amp;&amp; y &lt; len(charList) &#123; isIn := false for _, i := range charList[x:y] &#123; if i == charList[y] &#123; isIn = true break &#125; &#125; if isIn &#123; x += 1 &#125; else &#123; y += 1 &#125; if y-x &gt; maxY-maxX &#123; maxY, maxX = y, x &#125; &#125; return maxY - maxX&#125;本地测试package mainimport \"fmt\"func main() &#123; a := \"abcabcbb\" fmt.Println(lengthOfLongestSubstring(a)) b := \"bbbbb\" fmt.Println(lengthOfLongestSubstring(b)) c := \"pwwkew\" fmt.Println(lengthOfLongestSubstring(c))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-substring-without-repeating-characters","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"2. 两数相加","slug":"leetcode-cn/2","date":"2018-03-01T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/02/leetcode-cn/2/","link":"","permalink":"https://blazehu.github.io/2018/03/02/leetcode-cn/2/","excerpt":"题目描述给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。您可以假设除了数字 0 之外，这两个数都不会以 0 开头。示例输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 原因：342 + 465 = 807","text":"题目描述给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。您可以假设除了数字 0 之外，这两个数都不会以 0 开头。示例输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 原因：342 + 465 = 807解法func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode &#123; h := &amp;ListNode&#123;&#125; for s := h; l1 != nil; l1 = l1.Next &#123; s.Val = l1.Val if l1.Next != nil &#123; s.Next = &amp;ListNode&#123;&#125; &#125; s = s.Next &#125; k := 0 s, e := h, h for l2 != nil &#123; s.Val += l2.Val + k k = 0 if s.Val &gt;= 10 &#123; s.Val -= 10 k = 1 &#125; if s.Next == nil &#123; s.Next = &amp;ListNode&#123;&#125; &#125; e = s s = s.Next l2 = l2.Next &#125; for k != 0 &amp;&amp; s != nil &#123; s.Val += k k = 0 if s.Val &gt;= 10 &#123; s.Val -= 10 k = 1 &#125; s = s.Next e = e.Next &#125; if k != 0 &#123; if s != nil &#123; e.Next.Val += 1 &#125; else &#123; e.Next = &amp;ListNode&#123;Val: 1&#125; &#125; &#125; for s != nil &#123; if s.Val == 0 &amp;&amp; s.Next == nil &#123; e.Next = nil &#125; s = s.Next e = e.Next &#125; return h&#125;本地测试package mainimport \"fmt\"type ListNode struct &#123; Val int Next *ListNode&#125;func print(h *ListNode) &#123; for h != nil &#123; fmt.Print(h.Val) h = h.Next &#125; fmt.Println()&#125;func main() &#123; l1 := ListNode&#123;Val: 2, Next: &amp;ListNode&#123;Val: 4, Next: &amp;ListNode&#123;Val: 3&#125;&#125;&#125; l2 := ListNode&#123;Val: 5, Next: &amp;ListNode&#123;Val: 6, Next: &amp;ListNode&#123;Val: 4&#125;&#125;&#125; print(addTwoNumbers(&amp;l1, &amp;l2)) l1 = ListNode&#123;Val: 0&#125; l2 = ListNode&#123;Val: 5, Next: &amp;ListNode&#123;Val: 6, Next: &amp;ListNode&#123;Val: 4&#125;&#125;&#125; print(addTwoNumbers(&amp;l1, &amp;l2)) l1 = ListNode&#123;Val: 9, Next: &amp;ListNode&#123;Val: 9&#125;&#125; l2 = ListNode&#123;Val: 9&#125; print(addTwoNumbers(&amp;l1, &amp;l2)) l1 = ListNode&#123;Val: 8, Next: &amp;ListNode&#123;Val: 9, Next: &amp;ListNode&#123;Val: 9&#125;&#125;&#125; l2 = ListNode&#123;Val: 2&#125; print(addTwoNumbers(&amp;l1, &amp;l2))&#125;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/add-two-numbers","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"1. 两数之和","slug":"leetcode-cn/1","date":"2018-02-28T16:00:00.000Z","updated":"2022-06-21T06:59:55.000Z","comments":true,"path":"2018/03/01/leetcode-cn/1/","link":"","permalink":"https://blazehu.github.io/2018/03/01/leetcode-cn/1/","excerpt":"题目描述给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。示例给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1]","text":"题目描述给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。示例给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1]解法暴力解法func twoSum(nums []int, target int) []int &#123; var ret []int for index1, num1 := range nums &#123; for index2, num2 := range nums &#123; if index1 != index2 &amp;&amp; num1+num2 == target &#123; ret = []int&#123;index2, index1&#125; return ret &#125; &#125; &#125; return ret&#125;时间复杂度： O(n^2)空间复杂度： O(1)一遍哈希表func twoSum(nums []int, target int) []int &#123; var ( ret []int numsMap map[int][]int ) numsMap = make(map[int][]int, len(nums)) for index, num := range nums &#123; if _, ok := numsMap[num]; ok &#123; numsMap[num] = append(numsMap[num], index) &#125; else &#123; numsMap[num] = []int&#123;index&#125; &#125; if indexList, ok := numsMap[target-num]; ok &#123; for _, i := range indexList &#123; if i != index &#123; ret = []int&#123;i, index&#125; return ret &#125; &#125; &#125; &#125; return ret&#125;时间复杂度： O(n)空间复杂度： O(n)来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/two-sum","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"}]},{"title":"API 网关 - Kong 简介","slug":"backend/common/kong_study","date":"2017-09-11T16:00:00.000Z","updated":"2025-03-25T02:49:56.186Z","comments":true,"path":"2017/09/12/backend/common/kong_study/","link":"","permalink":"https://blazehu.github.io/2017/09/12/backend/common/kong_study/","excerpt":"简介Kong 是由 Mashape 公司开源的，基于 Nginx 的 API Gateway （ Nginx 中运行的 Lua 应用程序 ）。","text":"简介Kong 是由 Mashape 公司开源的，基于 Nginx 的 API Gateway （ Nginx 中运行的 Lua 应用程序 ）。特点功能：授权、日志、IP 限制、限流、API 统计分析、请求转化、跨域（CORS）等等。可扩展： 支持分布式术语术语描述Upstream负载均衡策略Target处理请求的 Backend 服务Service多个 Upstream 的集合Route转发规则，将请求转发给 ServiceConsumer用户，里面记录用户的一些信息CertificateHttps 证书Sni域名与 Certificate 的绑定Plugin插件环境搭建测试服务器：192.168.0.1Create a Docker networkdocker network create kong-netStart Databasedocker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e \"POSTGRES_USER=kong\" \\ -e \"POSTGRES_DB=kong\" \\ postgres:9.6Prepare Databasedocker run --rm \\ --network=kong-net \\ -e \"KONG_DATABASE=postgres\" \\ -e \"KONG_PG_HOST=kong-database\" \\ -e \"KONG_CASSANDRA_CONTACT_POINTS=kong-database\" \\ kong:latest kong migrations upStart Kongdocker run -d --name kong \\ --network=kong-net \\ -e \"KONG_DATABASE=postgres\" \\ -e \"KONG_PG_HOST=kong-database\" \\ -e \"KONG_CASSANDRA_CONTACT_POINTS=kong-database\" \\ -e \"KONG_PROXY_ACCESS_LOG=/dev/stdout\" \\ -e \"KONG_ADMIN_ACCESS_LOG=/dev/stdout\" \\ -e \"KONG_PROXY_ERROR_LOG=/dev/stderr\" \\ -e \"KONG_ADMIN_ERROR_LOG=/dev/stderr\" \\ -e \"KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\" \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 8001:8001 \\ -p 8444:8444 \\ kong:latestCheckcurl -i http://192.168.0.1:8001/API 调用官网文档背景Kong 部署在 192.168.0.1 机器上另有 2 台机器部署了 web 服务： 192.168.0.2 192.168.0.3web 服务地址测试接口： http://192.168.0.2:9100/api/v1/test/http://192.168.0.3:9100/api/v1/test/创建 Upstreamcurl -i -X POST \\--url http://192.168.0.1:8001/upstreams/ \\--data \"name=backend1\"给 Upstream 添加 Targetscurl -i -X POST \\--url http://192.168.0.1:8001/upstreams/backend1/targets \\--data \"target=192.168.0.2:9100\"curl -i -X POST \\--url http://192.168.0.1:8001/upstreams/backend1/targets \\--data \"target=192.168.0.3:9100\"查看 Upstream 的 Targets 是否添加成功curl -i -X GET \\--url http://10.25.98.128:8001/upstreams/backend1/targets创建 Servicecurl -i -X POST \\--url http://192.168.0.1:8001/services/ \\--data \"name=backend1\" \\--data \"host=backend1\"查看 Servicecurl -i -X GET \\--url http://192.168.0.1:8001/services/backend1给 Service 添加 Routescurl -i -X POST --url http://192.168.0.1:8001/routes/ -d &#123; \"service\": &#123; \"id\": \"2bc5f78b-02f8-4109-96c0-0888cbee7ccb\" &#125;, \"methods\": [\"GET\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\"]&#125;查看 Service 下的 Routescurl -i -X GET \\--url http://192.168.0.1:8001/services/manageone-cmdb/routes通过 Kong API 访问 backend1 服务curl -i -X GET http://192.168.0.1:8000/api/v1/test/参考资料https://docs.konghq.com/2.0.x/getting-started/configuring-a-service/","categories":[],"tags":[]},{"title":"Nginx location 匹配规则","slug":"ops/nginx/nginx_location","date":"2017-08-14T16:00:00.000Z","updated":"2025-03-24T13:17:30.621Z","comments":true,"path":"2017/08/15/ops/nginx/nginx_location/","link":"","permalink":"https://blazehu.github.io/2017/08/15/ops/nginx/nginx_location/","excerpt":"匹配命令~ 正则匹配，区分大小写~* 正则匹配，不区分大小写= 普通字符精确匹配，如果找到，停止搜索^~ 普通字符匹配（如果该选项匹配，只匹配该选项，一般用来匹配目录）/ 通用匹配，如果没有其它匹配，任何请求都会匹配到@ 定义命名的 location，使用在内部定向时，例如：error_page、try_files匹配优先级（与在配置文件中的顺序无关）1. 精确匹配 ”=“ 会第一个被处理。如果发现精确匹配，停止搜索。2. 匹配最长的规则，如果这个规则带有 ^~ 修饰符，停止搜索。3. 存储 #2 的最长匹配规则，然后按在配置文件中的定义顺序匹配正则表达，若匹配到正则表达式，停止搜索。4. 若没有匹配到正则表达式，使用存储的 #2 的最长匹配。","text":"匹配命令~ 正则匹配，区分大小写~* 正则匹配，不区分大小写= 普通字符精确匹配，如果找到，停止搜索^~ 普通字符匹配（如果该选项匹配，只匹配该选项，一般用来匹配目录）/ 通用匹配，如果没有其它匹配，任何请求都会匹配到@ 定义命名的 location，使用在内部定向时，例如：error_page、try_files匹配优先级（与在配置文件中的顺序无关）1. 精确匹配 ”=“ 会第一个被处理。如果发现精确匹配，停止搜索。2. 匹配最长的规则，如果这个规则带有 ^~ 修饰符，停止搜索。3. 存储 #2 的最长匹配规则，然后按在配置文件中的定义顺序匹配正则表达，若匹配到正则表达式，停止搜索。4. 若没有匹配到正则表达式，使用存储的 #2 的最长匹配。官方文档Directives with the = prefix that match the query exactly. If found, searching stops.All remaining directives with conventional strings, longest match first. If this match used the ^~ prefix, searching stops.Regular expressions, in order of definition in the configuration file.If #3 yielded a match, that result is used. Else the match from #2 is used.= 前缀的指令严格匹配这个查询。如果找到，停止搜索。所有剩下的常规字符串，最长的匹配。如果这个匹配使用 ^〜 前缀，搜索停止。正则表达式，在配置文件中定义的顺序。如果第三条规则产生匹配的话，结果被使用。否则，使用第二条规则的结果。例子# @location 例子error_page 404 = @fetch;location @fetch &#123; [ configuration X ]&#125;location = / &#123; # 精确匹配 / [ configuration A ] &#125;location / &#123; # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] &#125;location /documents/ &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ] &#125;location ~ /documents/Abc &#123; [ configuration CC ] &#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索，采用这一条 [ configuration D ] &#125;location ~* \\.(gif|jpg|jpeg)$ &#123; # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ] &#125;location /images/ &#123; # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ] &#125;location /images/abc &#123; # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F 与 G 的放置顺序是没有关系的 [ configuration G ] &#125;location ~ /images/abc/ &#123; # 只有去掉 config D 才有效 # 先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ] &#125;location ~* /js/.*/\\.js常用例子静态文件处理静态文件请求，这是 nginx 作为 http 服务器的强项，有两种配置模式，目录匹配或后缀匹配，任选其一或搭配使用# 目录匹配location ^~ /static/ &#123; root /webroot/static/;&#125;# 后缀匹配location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; alias /webroot/res/;&#125;参考资料https://www.nginx.cn/115.html","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blazehu.github.io/tags/nginx/"}]},{"title":"Nginx 长连接","slug":"ops/nginx/keepalive","date":"2017-08-13T16:00:00.000Z","updated":"2025-03-24T13:01:30.885Z","comments":true,"path":"2017/08/14/ops/nginx/keepalive/","link":"","permalink":"https://blazehu.github.io/2017/08/14/ops/nginx/keepalive/","excerpt":"","text":"什么是长连接？HTTP请求是基于TCP协议的，客户端向服务器发送一个 TCP 请求需要三次握手，服务端响应完毕后断开连接。 HTTP请求请求是应答式的，如果能知道每个请求头与响应体的长度，那么就可以在一个连接上面执行多个请求的，这就是所谓的长连接。 但前提条件是我们先得确定请求头与响应体的长度。相关配置Nginx 使用 keepalive_timeout 来指定客户端和 Nginx 之间的超时时间。指定每个 TCP 连接最多可以保持多长时间。Nginx 的默认值是 75 秒，有些浏览器最多只保持 60 秒，所以可以设定为 60 秒。若将它设置为 0，就禁止了 keepalive 连接。# 配置段: http, server, locationkeepalive_timeout 75s;通常 keepalive_timeout 应该比 client_body_timeout 大。","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blazehu.github.io/tags/nginx/"}]},{"title":"Nginx 超时配置","slug":"ops/nginx/timeout","date":"2017-08-12T16:00:00.000Z","updated":"2025-03-24T13:17:38.171Z","comments":true,"path":"2017/08/13/ops/nginx/timeout/","link":"","permalink":"https://blazehu.github.io/2017/08/13/ops/nginx/timeout/","excerpt":"client_header_timeout客户端向服务端发送一个完整的 request header 的超时时间。如果客户端在指定时间内没有发送一个完整的 request header，Nginx 返回 HTTP 408（Request Timed Out）。Defines a timeout for reading client request header. If a client does not transmit the entire header within this time,the 408 (Request Time-out) error is returned to the client.","text":"client_header_timeout客户端向服务端发送一个完整的 request header 的超时时间。如果客户端在指定时间内没有发送一个完整的 request header，Nginx 返回 HTTP 408（Request Timed Out）。Defines a timeout for reading client request header. If a client does not transmit the entire header within this time,the 408 (Request Time-out) error is returned to the client.client_body_timeout指定客户端与服务端建立连接后发送 request body 的超时时间。如果客户端在指定时间内没有发送任何内容，Nginx 返回 HTTP 408（Request Timed Out）。Defines a timeout for reading client request body. The timeout is set only for a period between two successive read operations, not for the transmission of the whole request body.If a client does not transmit anything within this time,the 408 (Request Time-out) error is returned to the client.send_timeout服务端向客户端传输数据的超时时间，是连续两次发送数据的间隔时间，非整个请求传输时间。Sets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations,not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed.proxy_connect_timeoutNginx 与 upstream server 的连接超时时间。Defines a timeout for establishing a connection with a proxied server. It should be noted that this timeout cannot usually exceed 75 seconds.proxy_read_timeoutNginx 接收 upstream server 数据超时， 默认60s， 如果连续的60s内没有收到1个字节， 连接关闭。Defines a timeout for reading a response from the proxied server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxied server does not transmit anything within this time, the connection is closed.proxy_send_timeoutNginx 发送数据至 upstream server 超时，默认60s， 如果连续的60s内没有发送1个字节， 连接关闭。Sets a timeout for transmitting a request to the proxied server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxied server does not receive anything within this time, the connection is closed.keepalive_timeoutNginx 和客户端之间的长连接保持时间，指定每个 TCP 连接最多可以保持多长时间。Nginx 的默认值是75秒，若将它设置为0，就禁止了 keepalive 连接。The first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections.The optional second parameter sets a value in the “Keep-Alive: timeout=time” response header field. Two parameters may differ.","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blazehu.github.io/tags/nginx/"}]},{"title":"Nginx 负载均衡","slug":"ops/nginx/study_notes","date":"2017-08-11T16:00:00.000Z","updated":"2025-03-24T13:17:35.690Z","comments":true,"path":"2017/08/12/ops/nginx/study_notes/","link":"","permalink":"https://blazehu.github.io/2017/08/12/ops/nginx/study_notes/","excerpt":"简介nginx 通过 upstream 实现负载均衡， upstream 目前支持5种方式。","text":"简介nginx 通过 upstream 实现负载均衡， upstream 目前支持5种方式。轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。upstream backserver &#123; server 192.168.0.14; server 192.168.0.15; &#125;指定权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。upstream backserver &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10; &#125;IP 绑定 ip_hash每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。upstream backserver &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125;fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。upstream backserver &#123; server server1; server server2; fair; &#125;url_hash（第三方）按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效。upstream backserver &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125;其他upstream 还可以为每个设备设置状态值，这些状态值的含义分别如下：状态值含义down表示单前的 server 暂时不参与负载weight默认为1， weight 越大负载的权重就越大max_fails允许请求失败的次数默认为1，当超过最大次数时返回 proxy_next_upstream 模块定义的错误fail_timeoutmax_fails 次失败后，暂停的时间backup其它所有的非 backup 机器 down 或者忙的时候，请求 backup 机器，所以这台机器压力会最轻例如：upstream bakend&#123; # 定义负载均衡设备的 Ip 及设备状态 ip_hash; server 10.0.0.11:9090 down; server 10.0.0.11:8080 weight=2; server 10.0.0.11:6060; server 10.0.0.11:7070 backup; &#125;超时时间设置django + uwsgi + nginx 部署的 web 站点运行时报504 ， 可能是超时时间设置有问题。nginx 和 uwsgi 整合时有三个参数可以用于设置超时时间，在 nginx 配置文件 http -&gt; server -&gt; location 中设置。uwsgi_connect_timeout ：默认60秒，与 uwsgi-server 连接的超时时间，该值不能超过75秒.若在超时时间内未能成功连接则断开连接尝试。 uwsgi_read_timeout ：默认60秒，nginx等待 uwsgi 进程发送响应数据的超时时间。若有需要长时间运行才能产生输出结果的uwsgi进程则需将此参数调高。若在错误日志文件中看到 upstream timed out 需将此参数调高。若超过超时时间还未收到响应则 nginx 关闭连接。 uwsgi_send_timeout ：默认60秒，nginx 向 uwsgi 进程发送请求的超时时间。超时时间由两次写操作的时间间隔算，而非整个请求。若超过超时时间仍没写入动作则 nginx 关闭连接。注：这里还需要排除其他原因，根据具体环境而定，如使用 aws 的 LB 就会有空闲时间的限制响应状态码504 网关超时 Gateway timeout（例如nginx正在处理但是程序执行过程太长，nginx配置的等待时间较短，于是时间到了超时返回504，排查超时时间等因素）502 网关错误 Bad Gateway 服务不给nginx任何响应 （例如uwsgi最多只能处理300个请求，但nginx转发了600个请求，uwsgi不给nginx任何响应，502）500 服务器内部错误，可能是服务内部有问题（例如代码内部有问题）404 找不到该网页（可能web 路径有问题 ）200 正常状态","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blazehu.github.io/tags/nginx/"}]},{"title":"CSRF 简介","slug":"frontend/csrf","date":"2017-06-13T16:00:00.000Z","updated":"2025-03-25T02:49:50.037Z","comments":true,"path":"2017/06/14/frontend/csrf/","link":"","permalink":"https://blazehu.github.io/2017/06/14/frontend/csrf/","excerpt":"CSRF 是什么？CSRF（Cross-site Request Forgery）跨站请求伪造，缩写为：CSRF/XSRF。 也被称为：one click attack/session riding。","text":"CSRF 是什么？CSRF（Cross-site Request Forgery）跨站请求伪造，缩写为：CSRF/XSRF。 也被称为：one click attack/session riding。攻击原理利用了 web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。例子背景：有网站 a, b1. a网站通过标签 &lt;img src=\"http://b?xx=xx&amp;x=x\"&gt; 构造了一个 get 请求,这个请求为 b 的地址并且携带了一些请求参数2. 浏览器发起请求的时候看到的域名是 b 的域名就会携带 b 网站下的 cookie3. 如果 cookie 里携带了一些认证信息，b 网站就会认为这是一个正常的请求从而导致了一些安全问题该攻击可以实施的点在于：1. 浏览器在发起 get 请求的时候会默认携带该请求域名下的 cookie2. 一般而言浏览器有同源策略的限制，但是通过标签 &lt;img src=\"\"&gt; 或者 script 所构造的请求不会有这个限制3. b 网站允许 get 请求去执行一些操作防御措施检查 Referer添加校验 Token","categories":[],"tags":[]},{"title":"siege 压测工具","slug":"ops/common/siege","date":"2017-05-20T16:00:00.000Z","updated":"2025-03-24T13:05:35.344Z","comments":true,"path":"2017/05/21/ops/common/siege/","link":"","permalink":"https://blazehu.github.io/2017/05/21/ops/common/siege/","excerpt":"简介siege 是一款高性能的 http 压力测试工具。siege 支持身份验证、 cookies、 http、 https 和 ftp 协议。应用举例1. 对指定站点进行压测siege -c 300 -t 5s URL2.文件中包含的若干URL进行批量测试siege -c 300 -t 5s -f URL_File_Name3. 支持多个Header参数siege -c 300 -t 5s -H \"Authorization: XXXX\" -H \"SX: 1212\" URL4. 支持application/json方式请求siege -c 300 -t 5s 'URL POST &lt; data.json' siege -c 300 -t 5s 'URL PUT &lt; data.json'","text":"简介siege 是一款高性能的 http 压力测试工具。siege 支持身份验证、 cookies、 http、 https 和 ftp 协议。应用举例1. 对指定站点进行压测siege -c 300 -t 5s URL2.文件中包含的若干URL进行批量测试siege -c 300 -t 5s -f URL_File_Name3. 支持多个Header参数siege -c 300 -t 5s -H \"Authorization: XXXX\" -H \"SX: 1212\" URL4. 支持application/json方式请求siege -c 300 -t 5s 'URL POST &lt; data.json' siege -c 300 -t 5s 'URL PUT &lt; data.json'常用参数参数描述-c并发数-t压力测试时间，可以在时间后加单位-r重复次数。与-t含义相同，设一个即可-f包含URL的文本名字-bBENCHMARK模式，请求之间无需延迟-p打印整个页面的内容-H给请求添加头，支持多个-A给请求设置User-Agent-T给请求设置Content-Type性能参数性能参数描述Transactions总共测试次数Availability成功次数百分比Elapsed time总共耗时多少秒Data transferred总共数据传输Response time等到响应耗时Transaction rate平均每秒处理请求数Throughput吞吐率Concurrency最高并发Successful transactions成功的请求数Failed transactions失败的请求数参考资料https://www.joedog.org/siege-manual/https://www.jianshu.com/p/74c465ff136f/","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"Sanic 实践（0.6.0）","slug":"backend/python/Sanic初识","date":"2016-12-20T16:00:00.000Z","updated":"2025-08-15T04:00:27.821Z","comments":true,"path":"2016/12/21/backend/python/Sanic初识/","link":"","permalink":"https://blazehu.github.io/2016/12/21/backend/python/Sanic%E5%88%9D%E8%AF%86/","excerpt":"OverviewSanic is a Python 3.7+ web server and web framework that’s written to go fast. It allows the usage of the async/await syntax added in Python 3.5, which makes your code non-blocking and speedy.","text":"OverviewSanic is a Python 3.7+ web server and web framework that’s written to go fast. It allows the usage of the async/await syntax added in Python 3.5, which makes your code non-blocking and speedy.Example下面是一个简单的例子，使用到如下库：sanic (sanic is a flask-like python3.5+ web server)peewee (simple and small ORM)PyMySQL (mysql database driver)marshmallow (serialize and deserialize models)AoikLiveReload (automatic reload app in development)目录结构启动服务(sanic) [blazehu@MacBook ~]$ python3 app.py2018-12-21 10:53:50 - (sanic)[INFO]: Goin' Fast @ http://0.0.0.0:80002018-12-21 10:53:50 - (sanic)[INFO]: Starting worker [44832]访问测试create a new employeelist employeeslogs(sanic) [blazehu@MacBook ~]$ python3 app.py2018-12-21 10:53:50 - (sanic)[INFO]: Goin' Fast @ http://0.0.0.0:80002018-12-21 10:53:50 - (sanic)[INFO]: Starting worker [44832]2018-12-21 10:59:54 - (network)[INFO][127.0.0.1:55817]: GET http://127.0.0.1:8000/employee/ 200 2672018-12-21 11:00:03 - (network)[INFO][127.0.0.1:55865]: GET http://127.0.0.1:8000/employee/ 200 2672018-12-21 11:01:05 - (network)[INFO][127.0.0.1:56135]: GET http://127.0.0.1:8000/employee/ 200 382018-12-21 11:01:44 - (network)[INFO][127.0.0.1:56325]: POST http://127.0.0.1:8000/employee/ 200 282018-12-21 11:02:38 - (network)[INFO][127.0.0.1:56562]: GET http://127.0.0.1:8000/employee/ 200 95具体实现models.py# -*- coding: utf-8 -*-from peewee import *from playhouse.pool import MySQLDatabasefrom playhouse.shortcuts import RetryOperationalErrorimport configclass RetryMysqlDatabase(RetryOperationalError, MySQLDatabase): def __init__(self, database, **kwargs): super(MySQLDatabase, self).__init__(database, **kwargs) def sequence_exists(self, seq): passdb = RetryMysqlDatabase( database=config.DB_NAME, host=config.DB_HOST, user=config.DB_USER, passwd=config.DB_PASSWORD, port=config.DB_PORT,)class BaseModel(Model): \"\"\"A base model that will use our MySQL database\"\"\" is_deleted = BooleanField(u'是否删除', default=False) class Meta: database = dbclass Employee(BaseModel): # base info number = CharField(verbose_name=u'编号', unique=True) name = CharField(verbose_name=u'姓名', null=True) email = CharField(verbose_name=u'邮箱', null=True)serialize.py# -*- coding: utf-8 -*-from marshmallow import Schema, fields, post_loadimport modelsclass EmployeeSchema(Schema): # 基本信息 number = fields.String() name = fields.String() email = fields.Email() @post_load def make_employee(self, data): return models.Employee(**data)views.py# -*- coding: utf-8 -*-from sanic.views import HTTPMethodViewfrom sanic import Blueprint, responsefrom models import Employeeimport serializeemployee_bp = Blueprint(\"employee_bp\")class EmployeeView(HTTPMethodView): async def get(self, request): employees = Employee.select().where(Employee.is_deleted == 0) schema = serialize.EmployeeSchema() data = schema.dump(employees, many=True).data return response.json(&#123;\"code\": 200, \"msg\": \"success\", \"data\": data&#125;) async def post(self, request): data = request[\"POST\"] employee_schema = serialize.EmployeeSchema() _, error = employee_schema.load(data) if error: msg = \"\" for error_item in error: error_detail = error.get(error_item) if isinstance(error_detail, list): error_detail = ','.join(error_detail) else: error_detail = str(error_detail) msg += \"&#123;0&#125;: &#123;1&#125;\".format(error_item, error_detail) return response.json(&#123;\"code\": 500, \"msg\": msg&#125;) else: number = data.get(\"number\") try: Employee.get(Employee.number == number) return response.json(&#123;\"code\": 500, \"msg\": \"the number is uniq\"&#125;) except Employee.DoesNotExist: employee = Employee() for key in data: value = data.get(key) if hasattr(employee, key): setattr(employee, key, value) employee.save() return response.json(&#123;\"code\": 201, \"msg\": \"success\"&#125;)employee_bp.add_route(EmployeeView.as_view(), \"/\")app.py# -*- coding: utf-8 -*-from sanic import Sanicfrom sanic_cors import CORSfrom aoiklivereload import LiveReloaderfrom views import employee_bpfrom models import db, Employeeimport configapp = Sanic(__name__)app.blueprint(employee_bp, url_prefix='/employee')CORS(app, automatic_options=True)@app.middleware('request')async def transform_data_request(request): try: request['POST'] = request.json if request.json else &#123;&#125; request['GET'] = request.args if request.args else &#123;&#125; except Exception as e: print(repr(e))@app.middleware('response')async def close_db(request, response): if not db.is_closed(): db.close()# application configapp.config.from_object(config)# init the databasedb.create_tables([Employee, ], safe=True)if __name__ == '__main__': # reload the app reloader = LiveReloader() reloader.start_watcher_thread() # run server debug app.run(host='0.0.0.0', port=8000, debug=True)config.py# -*- coding: utf-8 -*-# 关闭长连接KEEP_ALIVE = False# 关闭启动logoLOGO = None# Mysql Database for devDB_HOST = '127.0.0.1'DB_PORT = 3306DB_NAME = 'sanic'DB_USER = 'root'DB_PASSWORD = '123456'requirements.txt# python 3.7.2PyMySQL==0.7.11AoikLiveReload==0.1.0peewee==2.8.5marshmallow==2.13.6sanic-crud==0.2.4Sanic-Cors==0.6.0.0sanic==0.6.0start.sh# dev, demo debug python3 app.py# deploygunicorn app:app --bind 0.0.0.0:8000 --worker-class sanic.worker.GunicornWorker","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"ansible 简介","slug":"ops/common/ansible_intro","date":"2016-10-09T16:00:00.000Z","updated":"2025-08-15T07:13:10.500Z","comments":true,"path":"2016/10/10/ops/common/ansible_intro/","link":"","permalink":"https://blazehu.github.io/2016/10/10/ops/common/ansible_intro/","excerpt":"Ansible 是基于python开发的，对于客户端的要求是需要有SSH和Python(如果python版本过低则 需要安装python-simplejson module)。","text":"Ansible 是基于python开发的，对于客户端的要求是需要有SSH和Python(如果python版本过低则 需要安装python-simplejson module)。配置定义配置⽂件，配置⽂文件可以从多个地⽅方加载，其优先级顺序为:- ANSIBLE_CONFIG (环境变量量) - ansible.cfg (当前⽬目录)- .ansible.cfg (home⽬目录)- /etc/ansible/ansible.cfg参考: http://docs.ansible.com/ansible/intro_configuration.htmlansible命令ansible 执⾏行行简单的临时命令 (ad-hoc命令)ansible-playbook 执⾏行行playbook，playbook是yaml⽂文件ansible-doc 查询ansible module ⽂文档ad-hoc命令参数:-i 指定hosts⽂文件的位置，hosts是yaml⽂文件，all表示hosts⽂文件中的所有的组-m 指定ansible的module，这⾥里里的command表示ansible的command模块，还有很多其他的模块例例如shell -a 指定args参数-u 指定⽤用户(因为这⾥里里是基于SSH认证的)ansible-playbook执行结果如下：# test.yml 文件中 hosts: 指定设备组 user: 指定ssh⽤用户 tasks: 关键词指明执⾏行行动作 name: 给动作命名 yum: ansible指定模块role使⽤用roles可以更更好的组织框架，如下:.├── roles│ ├── copy│ │ └── tasks│ │ └── main.yml│ └── dmcrypt│ └── tasks│ └── main.yml└── site.yml5 directories, 3 filessite.yml⽂件是⼊口 tasks下⽂件名必须为main.ymlrole下有很多结构，ansible会⾃自动按照⽂文件结构进⾏行行加载解析。具体⽬目录结构如下:.├── defaults├── files├── handlers├── meta├── tasks├── templates└── varspython调用ansible模块ansible.runner模块import ansible.runnerr = ansible.runner.Runner( host_list=\"/etc/ansible/hosts\", module_name=\"command\", module_args=\"ls\", forks=10, pattern=\"cmdb\")res = r.run()print resansible.playbook模块import ansible.playbookfrom ansible import callbacksfrom ansible import utilsimport jsonexample_host = ansible.inventory.host.Host(name='10.204.186.92', port=22)example_group = ansible.inventory.group.Group(name='simple_group_name')example_group.add_host(example_host)example_inventory = ansible.inventory.Inventory()example_inventory.add_group(example_group)stats = callbacks.AggregateStats()playbook_cb = = callbacks.PlaybookCallbacks(verbose=1)runner_cb = callbacks.PlaybookRunnerCallbacks(stats, verbose=1)vars = &#123;'ID': 39&#125;pb = ansible.playbook.PlayBook( playbook='playbook.yml', stats=stats, callbacks=playbook_cb, runner_callbacks=runner_cb, inventory=example_inventory, subset='simple_group_name', extra_vars=vars)res = pb.run()具体可以查看ansible的源码yaml模块import yamlf = open('C:/Users/sks/Desktop/project/test/1.yml', 'r')str_1 = f.read()str_2 = yaml.load(str_1)f.close()str_3 = yaml.dump(str_2)f = open('C:/Users/sks/Desktop/project/test/2.yml', 'w')f.write(str_3)f.close()","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://blazehu.github.io/tags/ansible/"}]},{"title":"Python 高阶函数","slug":"backend/python/base/高阶函数","date":"2016-05-20T16:00:00.000Z","updated":"2025-03-24T13:23:39.727Z","comments":true,"path":"2016/05/21/backend/python/base/高阶函数/","link":"","permalink":"https://blazehu.github.io/2016/05/21/backend/python/base/%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0/","excerpt":"简介高阶函数是一种将函数作为参数，或者把函数作为结果返回的函数。map 、 reduce 、 filter 、 sorted 就是高阶函数的典型例子。","text":"简介高阶函数是一种将函数作为参数，或者把函数作为结果返回的函数。map 、 reduce 、 filter 、 sorted 就是高阶函数的典型例子。map 函数map 函数的作用是将一个列表映射到另一个列表。# map(function, sequence)def function1(x): return x*2def function2(x, y): return x * ydef function3(t): return t[0] + t[1] + t[2]def function4(x): return x, x**2s1 = [1, 2, 3, 4]s2 = [2, 3, 4, 5]s3 = [3, 4, 5, 6]print(map(function1, s1))# [2, 4, 6, 8]print(map(function2, s1, s2))# [2, 6, 12, 20]print(map(function3, zip(s1, s2, s3)))# [6, 9, 12, 15]print(map(function4, s1))# [(1, 1), (2, 4), (3, 9), (4, 16)]上面的四个函数，根据参数的个数，参数的类型，返回值的个数，返回值的类型来测试map函数。reduce 函数reduce 的作用是将一个列表归纳为一个输出。有三个参数分别是 fucntion 、 sequence 、 startValue 。function 必须是带有两个参数的函数。startValue 可以不设置，初始化值，如果不设置那么初始化运算使用 sequence 的 s[0] 和 s[1] 进行运算，设置则是startValue 和 s[0] 运算，然后依次计算 fucntion(s[1], s[2]) ……# reduce(function, sequence, startValue)def function1(x): return x*2def function2(x, y): return x * ydef function3(t): return t[0] + t[1] + t[2]def function4(x): return x, x**2s1 = [1, 2, 3, 4]s2 = [2, 3, 4, 5]s3 = [3, 4, 5, 6]print(reduce(function2, s1))# 24print(reduce(function2, s1, 2))# 48filter 函数filter 函数是过滤掉列表中的一些元素。这里要注意的是 filter 通过函数的返回的 bool 值来判断是否过滤，最好设置为 true or false。def function5(x): return x % 2s1 = [1, 2, 3, 4]print(filter(function5, s1))# [1, 3]sorted 函数接收一个 key 函数来实现自定义的排序。普通排序# sorted(iterable, key=None, reverse=False) &gt;&gt;&gt; sorted([36, 5, -12, 9, -21])[-21, -12, 5, 9, 36]绝对值排序&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36]参考资料https://www.liaoxuefeng.com/wiki/1016959663602400/1017328655674400","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 匿名函数","slug":"backend/python/base/匿名函数","date":"2016-05-19T16:00:00.000Z","updated":"2025-03-24T13:23:49.913Z","comments":true,"path":"2016/05/20/backend/python/base/匿名函数/","link":"","permalink":"https://blazehu.github.io/2016/05/20/backend/python/base/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/","excerpt":"前言有些时候我们只是为了定义一些简单的操作，显式地定义函数略显麻烦，这时候我们可以直接使用匿名函数。","text":"前言有些时候我们只是为了定义一些简单的操作，显式地定义函数略显麻烦，这时候我们可以直接使用匿名函数。lambda 表达式lambda 表达式又称为匿名函数，通常和其他高阶函数配合使用。匿名函数不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数。# lambda &lt;参数&gt;: 函数体def function1(x): return x*2def function2(x, y): return x * ydef function3(x): return x**2def function4(x): return x % 2f1 = lambda x: x*2f2 = lambda x, y: x * yf3 = lambda x: x**2f4 = lambda x: x%2print(f1(2))# 4print(f2(2, 3))# 6print(f3(3))# 9print(f4(4), f4(7))# 0, 1参考资料https://www.liaoxuefeng.com/wiki/1016959663602400/1017451447842528","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 内置函数","slug":"backend/python/base/内置函数","date":"2016-05-17T16:00:00.000Z","updated":"2025-03-24T13:23:47.414Z","comments":true,"path":"2016/05/18/backend/python/base/内置函数/","link":"","permalink":"https://blazehu.github.io/2016/05/18/backend/python/base/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/","excerpt":"简介Python 解释器内置了很多函数和类型，以便于我们使用。","text":"简介Python 解释器内置了很多函数和类型，以便于我们使用。内置函数abs()delattr()hash()memoryview()set()all()dict()help()min()setattr()any()dir()hex()next()slice()ascii()divmod()id()object()sorted()bin()enumerate()input()oct()staticmethod()bool()eval()int()open()str()breakpoint()exec()isinstance()ord()sum()bytearray()filter()issubclass()pow()super()bytes()float()iter()print()tuple()callable()format()len()property()type()chr()frozenset()list()range()vars()classmethod()getattr()locals()repr()zip()compile()globals()map()reversed()__import__()complex()hasattr()max()round()常用函数介绍数学计算abs()返回一个数的绝对值。实参可以是整数或浮点数。如果实参是一个复数，返回它的模。pow()pow() 方法返回 xy（x的y次方） 的值。min()min() 方法返回给定参数的最小值，参数可以为序列。max()max() 方法返回给定参数的最大值，参数可以为序列。sum()sum() 方法对系列进行求和计算。对象操作getattr()getattr() 函数用于返回一个对象属性值。hasattr()hasattr() 函数用于判断对象是否包含对应的属性。setattr()setattr() 函数对应函数 getattr()，用于设置属性值，该属性不一定是存在的。delattr()delattr 函数用于删除属性。delattr(x, ‘foobar’) 相等于 del x.foobar。字符操作chr()chr() 用一个整数作参数，返回一个对应的字符。ord()ord() 函数是 chr() 函数（对于 8 位的 ASCII 字符串）的配对函数，它以一个字符串（Unicode 字符）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。可迭代对象sorted()sorted() 函数对所有可迭代的对象进行排序操作。enumerate()enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。zip()zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，这样做的好处是节约了不少的内存。通用type()type() 函数如果你只有第一个参数则返回对象的类型，三个参数返回新的类型对象。isinstance()isinstance() 函数来判断一个对象是否是一个已知的类型，类似 type()。id()id() 函数返回对象的唯一标识符，标识符是一个整数。eval()eval() 函数用来执行一个字符串表达式，并返回表达式的值。参考资料https://docs.python.org/zh-cn/3.7/library/functions.htmlhttps://www.runoob.com/python3/python3-built-in-functions.html","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 正则表达式","slug":"backend/python/base/正则表达式","date":"2016-05-11T16:00:00.000Z","updated":"2025-03-24T13:23:52.240Z","comments":true,"path":"2016/05/12/backend/python/base/正则表达式/","link":"","permalink":"https://blazehu.github.io/2016/05/12/backend/python/base/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"简介正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它 “匹配” 了，否则，该字符串就是不合法的。re 模块Python 自1.5版本起增加了 re 模块，它提供 Perl 风格的正则表达式模式。 re 模块使 Python 语言拥有全部的正则表达式功能。","text":"简介正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它 “匹配” 了，否则，该字符串就是不合法的。re 模块Python 自1.5版本起增加了 re 模块，它提供 Perl 风格的正则表达式模式。 re 模块使 Python 语言拥有全部的正则表达式功能。模式描述.可以匹配任意单个字符除了 \\n*匹配前一个字符0次或者n次?匹配前一个字符0次或者1次^表示匹配的字符必须在最前面$表示匹配的字符必须在最后面+表示匹配前一个字符1次或者n次\\d+匹配数字\\d匹配单个数字.*贪心算法，提取最多的内容.*?非贪心算法，提取内容x\\y[abc]表示匹配 abc 当中的任意一个字符，可以使用连接符- ：例如 [a-z][^abc]表示匹配除了列出字符以外的所有字符，是[abc]的补集{n}表示匹配前面n个字符{n,}表示匹配至少n个前面的字符{n, m}表示匹配至少n个最多m个前面的字符使用括号的话，括号内的是返回的结果。re 函数re.S : 正则匹配的时候包括 \\nfindall() : 返回匹配的所有结果列表search() : 返回匹配到的第一个结果sub() ： 替换匹配的结果compile() ： 把正则表达式编译为正则表达式对象例子#encoding=utf-8import resecret_code = 'hadkfalifexxIxxasdasdaxxsdasdxxasadasdaxxsdaxxs'# . 的使用举例a = 'xz123'b = re.findall('x.', a)# 匹配前一个字符0次或无限次# * 的使用举例a = 'xyxy123'b = re.findall('x*', a)# 匹配前一个字符0次或者1次# ? 的使用举例a = 'xyx123'b = re.findall('x?', a)# 组合方式# .* 贪心算法，提取最多的内容b = re.findall('xx.*xx', secret_code)# .*? 非贪心算法，提取内容b = re.findall('xx.*?xx', secret_code)# 使用括号和不适用括号的区别b = re.findall('xx(.*)xx', secret_code)# .*? 非贪心算法，提取内容b = re.findall('xx(.*?)xx', secret_code)# re.S 的作用是使 find 包括 \\nsecret_code = '''hadkfalifexxIxxasdasdaxxsdasdxxasadasdaxxsdaxxs'''b = re.findall('xx(.*?)xx', secret_code)b = re.findall('xx(.*?)xx', secret_code, re.S)# 对比 findall 和 search 的区别b = re.findall('xx(.*?)xx', secret_code)b = re.search('xx(.*?)xx(.*?)xx', secret_code).group(2)# sub 的使用举例#替换b = re.sub('xx(.*?)xx(.*?)xx', \"123%d123\", secret_code)b = re.sub('xx(.*?)xx(.*?)xx', \"123%d123\" % 789, secret_code)# compile 的用法pattern = 'xx(.*?)xx'new_pattern = re.compile(pattern, re.S)b = re.findall(new_pattern, secret_code)# ['I', 's\\ndasd', 'sda']# 匹配数字( \\d+ 匹配数字连续的依旧连续, \\d 匹配数字分成一个一个数字)a = 'asdasd123123vvvdsdfsd76989aowoie'b = re.findall('(\\d+)', a)# ['123123', '76989']参考资料https://www.runoob.com/python/python-reg-expressions.htmlhttps://www.liaoxuefeng.com/wiki/1016959663602400/1017639890281664","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 列表推导式","slug":"backend/python/base/列表推导式","date":"2016-05-09T16:00:00.000Z","updated":"2025-03-24T13:23:42.527Z","comments":true,"path":"2016/05/10/backend/python/base/列表推导式/","link":"","permalink":"https://blazehu.github.io/2016/05/10/backend/python/base/%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC%E5%BC%8F/","excerpt":"简介列表推导式即 List Comprehensions ，简单却强大。列表推导式的格式[x for item in sequence &lt;if (conditions)&gt;] # 这里的x是对 item进行的操作[表达式 for 变量 in 列表 if 条件] # 列表推导式会比for循环快很多","text":"简介列表推导式即 List Comprehensions ，简单却强大。列表推导式的格式[x for item in sequence &lt;if (conditions)&gt;] # 这里的x是对 item进行的操作[表达式 for 变量 in 列表 if 条件] # 列表推导式会比for循环快很多例子In [1]: [x**2 for x in range(5) if x &lt; 2]Out[1]: [0, 1]# 省略条件语句In [2]: [x**2 for x in range(5)]Out[2]: [0, 1, 4, 9, 16]# 自定义表达式和条件语句In [3]: [(x, x**2) for x in (1, 2, 3, 4, 5, 6) if x % 3]Out[3]: [(1, 1), (2, 4), (4, 16), (5, 25)]# 多个 for 和多个 if In [4]: [(x, y) for x in range(5) if not x % 3 for y in range(5) if not y % 2]Out[4]: [(0, 0), (0, 2), (0, 4), (3, 0), (3, 2), (3, 4)]# 表达式可以是函数In [7]: [sum([x, y]) for x in range(5) for y in range(2)]Out[7]: [0, 1, 1, 2, 2, 3, 3, 4, 4, 5]In [8]: [sum([x, y]) for (x, y) in zip([1, 2, 3, 4], [2, 3, 4, 5])]Out[8]: [3, 5, 7, 9]参考资料https://www.liaoxuefeng.com/wiki/1016959663602400/1017317609699776","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 动态类型","slug":"backend/python/base/动态类型","date":"2016-05-07T16:00:00.000Z","updated":"2025-03-24T13:23:36.395Z","comments":true,"path":"2016/05/08/backend/python/base/动态类型/","link":"","permalink":"https://blazehu.github.io/2016/05/08/backend/python/base/%E5%8A%A8%E6%80%81%E7%B1%BB%E5%9E%8B/","excerpt":"简介Python 的数据类型分为 mutable 和 immutable ， mutable 和 immutable 字面意思理解就是说数据可变和数据不可变。mutable: list、dictinmutable: int、 string、 float、 tuple…","text":"简介Python 的数据类型分为 mutable 和 immutable ， mutable 和 immutable 字面意思理解就是说数据可变和数据不可变。mutable: list、dictinmutable: int、 string、 float、 tuple…动态类型由于 Python 的变量 (variable) 不需要声明，而在赋值的时候，变量可以重新赋值为任意值，这就涉及到 Python 的一个重要的核心概念： 动态类型 (dynamic typing) 。一切皆对象在这里重复强调一下在 Python 中一切皆对象，Python 是纯血统的面向对象的编程语言，与 java 不同。我们知道 Java 中有装箱和拆箱，基本数据类型 int 在持久化的过程中是需要封装为 Integer 的。但是在 Python 中，一切皆对象。什么都是对象，包括你的代码，对象是存储在内存中的实体，我们在程序中使用的都是对象名，只是指向这个对象的一个引用 (reference)。引用引用和对象分离，是动态类型的核心，引用可以随时的指向一个新的对象。 这不同于 C++ 中的指针和引用的概念，在 C++ 中指针在逻辑上是独立存在的，但是引用是和对象绑定在一起的。例子a = 'blazehu'a = 2第一行：在内存中建立了对象 ‘blazehu’(字符串类型)，通过赋值让引用 a 指向它。第二行：2是在内存中存在的整数对象，将引用 a 指向2，于是 ‘blazehu’ 就没有引用指向它， Python 会自动的将这种没有引用指向的垃圾销毁掉，释放相应的内存空间。immutable（不可变数据类型）&gt;&gt;&gt; def func(x):... x = 1... print(x)...&gt;&gt;&gt; x = 2&gt;&gt;&gt; func(x)1&gt;&gt;&gt; print(x)2&gt;&gt;&gt;这样类似于 C/C++ 中的值传递，即传递的引用不能改变自身，只是改变了引用的指向。mutable（可变数据类型）&gt;&gt;&gt; def func(x):... x[0] = 4... print(x)...&gt;&gt;&gt; x = [1]&gt;&gt;&gt; func(x)[4]&gt;&gt;&gt; print(x)[4]这就类似于 C/C++ 中的指针传递，即传递的引用可以引用自身的元素改变自身，改变了引用的值。 但是元组 (tuple) ，尽管可以调用引用元素，但不可以赋值，因此不能改变对象自身，所以也算是 immutable object 。Tips对于较小的整数和短字符 Python 会缓存这些对象，而不是频繁的创建和销毁。256 is an existing object but 257 isn’t. When you start up python the numbers from -5 to 256 will be allocated. These numbers are used a lot, so it makes sense just to have them ready.&gt;&gt;&gt; id(256)10922528&gt;&gt;&gt; a = 256&gt;&gt;&gt; b = 256&gt;&gt;&gt; id(a)10922528&gt;&gt;&gt; id(b)10922528&gt;&gt;&gt; id(257)140084850247312&gt;&gt;&gt; x = 257&gt;&gt;&gt; y = 257&gt;&gt;&gt; id(x)140084850247440&gt;&gt;&gt; id(y)140084850247344总结对于 inmutable object 我们在函数参数传递是值传递对于 mutable object 我们在函数参数传递是指针传递参考资料https://github.com/satwikkansal/wtfpythonhttps://www.cnblogs.com/vamei/archive/2012/07/10/2582795.html","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 包裹传递和解包裹","slug":"backend/python/base/包裹传递和解包裹","date":"2016-05-06T16:00:00.000Z","updated":"2025-03-24T13:24:50.383Z","comments":true,"path":"2016/05/07/backend/python/base/包裹传递和解包裹/","link":"","permalink":"https://blazehu.github.io/2016/05/07/backend/python/base/%E5%8C%85%E8%A3%B9%E4%BC%A0%E9%80%92%E5%92%8C%E8%A7%A3%E5%8C%85%E8%A3%B9/","excerpt":"包裹传递在定义函数时，我们有时候并不知道调用的时候会传递多少个参数。 这时候，包裹 (packing) 位置参数，或者包裹关键字参数，来进行参数传递，会非常有用。","text":"包裹传递在定义函数时，我们有时候并不知道调用的时候会传递多少个参数。 这时候，包裹 (packing) 位置参数，或者包裹关键字参数，来进行参数传递，会非常有用。例子一&gt;&gt;&gt; def func(*name):... print(type(name))... print(name)...&gt;&gt;&gt; func(1, 2, 3)&lt;class 'tuple'&gt;(1, 2, 3)&gt;&gt;&gt; func(1, 2, 3, 5, 6, 9)&lt;class 'tuple'&gt;(1, 2, 3, 5, 6, 9)两次调用，尽管参数个数不同，都基于同一个 func 定义。在 func 的参数表中，所有的参数被 name 收集，根据位置合并成一个元组 (tuple) ，这就是包裹位置传递。name 是包裹位置传递所用的元组名，在定义 func 时，在 name 前加 * 号。例子二&gt;&gt;&gt; def func(**x):... print(type(x))... print(x)...&gt;&gt;&gt; func(a=1, b=2)&lt;class 'dict'&gt;&#123;'a': 1, 'b': 2&#125;&gt;&gt;&gt; func(a=1, b=2, c=3)&lt;class 'dict'&gt;&#123;'a': 1, 'b': 2, 'c': 3&#125;与上面一个例子类似， dict 是一个字典，收集所有的关键字，传递给函数 func 。参数 dict 是包裹关键字传递所用的字典，在 dict 前加 **。解包裹* 和 ** ，也可以在调用的时候使用，即解包裹 (unpacking) ，下面为例：&gt;&gt;&gt; def func(a, b ,c):... print(a, b, c)...&gt;&gt;&gt; args = (1, 2, 3)&gt;&gt;&gt; func(*args)1 2 3&gt;&gt;&gt; kwargs = &#123;'a': 1, 'b': 2, 'c': 3&#125;&gt;&gt;&gt; func(**kwargs)1 2 3总结包裹传递在定义函数时，元组前加 * 、字典前加 ** 。包裹和解包裹并不是相反操作，是两个相对独立的过程。","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 执行系统命令","slug":"backend/python/base/执行系统命令","date":"2016-05-01T16:00:00.000Z","updated":"2025-03-24T13:23:54.577Z","comments":true,"path":"2016/05/02/backend/python/base/执行系统命令/","link":"","permalink":"https://blazehu.github.io/2016/05/02/backend/python/base/%E6%89%A7%E8%A1%8C%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4/","excerpt":"简介Python 执行系统命令有很多种方法，下面给出了常见的四种方式。","text":"简介Python 执行系统命令有很多种方法，下面给出了常见的四种方式。os.systemos.system 直接调用标准 C 的 system() 函数，仅仅在一个子终端运行系统命令，而不能获取命令执行后的返回信息，返回脚本的退出状态码。用于测试的 shell 脚本 test.shecho \"Hello World!!!\"exit 3测试&gt;&gt;&gt; import os&gt;&gt;&gt; status = os.system(\"bash test.sh\")Hello World!!!&gt;&gt;&gt; status768&gt;&gt;&gt; status &gt;&gt; 83该方法在调用完 shell 脚本后，返回一个16位的二进制数，低位为杀死所调用脚本的信号号码，高位为脚本的退出状态码。 返回的结果都是0（使用位运算向右位移8位得到的结果就是高位值），代表代码正常退出。我们如果需要的到脚本执行后返回的状态码，可以使用位运算得到。os.popen这种调用方法是通过管道的方式来实现的，函数返回一个 file-like 的对象，里面的内容是脚本输出的内容（可以简单的理解为 echo 的输出内容）。用于测试的 shell 脚本 test.shecho \"Hello World!!!\"测试&gt;&gt;&gt; import os&gt;&gt;&gt; output = os.popen(\"bash test.sh\")&gt;&gt;&gt; output&lt;open file 'bash test.sh', mode 'r' at 0x1031bd780&gt;&gt;&gt;&gt; output.read()'Hello World!!!\\n'&gt;&gt;&gt;commands 模块1. getstatusoutput(cmd)使用 os.popen() 执行命令 cmd ，然后返回两个元素的元组（status, result）。执行方式： { cmd; } 2&gt;&amp;1 ，返回结果里包含标准输出和标准错误。2. getoutput(cmd)只返回执行的结果，忽略状态码。3. getstatus(file)返回 ls -ld file 执行的结果测试&gt;&gt;&gt; import commands&gt;&gt;&gt; status, output = commands.getstatusoutput(\"bash test.sh\")&gt;&gt;&gt; status768&gt;&gt;&gt; output'Hello World!!!'subprocess 模块功能强大的子进程管理模块。测试&gt;&gt;&gt; import subprocess&gt;&gt;&gt; p = subprocess.Popen(\"bash test.sh\", stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)&gt;&gt;&gt; p.stdout.read()'Hello World!!!\\n'&gt;&gt;&gt; p.stderr.read()''","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"Python 第三方模块","slug":"backend/python/base/模块安装","date":"2016-04-30T16:00:00.000Z","updated":"2025-03-24T13:23:44.890Z","comments":true,"path":"2016/05/01/backend/python/base/模块安装/","link":"","permalink":"https://blazehu.github.io/2016/05/01/backend/python/base/%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85/","excerpt":"安装第三方模块在 Python 中，安装第三方模块，是通过包管理工具 pip 完成的。Mac 或 Linux 预安装了 pip 和 Python。","text":"安装第三方模块在 Python 中，安装第三方模块，是通过包管理工具 pip 完成的。Mac 或 Linux 预安装了 pip 和 Python。Linuxpip 安装# 安装 pika 模块easy_install pikapip install pika源码安装Linux 上如果没有安装 pip 工具的话可以在官网上下载 pip 的源码包安装。tar -zxvf XXXX.tar.gz (or tar jxvf XXXX.tar.bz2) cd XXXX./configuremakemake installWindows如果 Windows 提示未找到命令，需要配置环境变量。即将 C:\\Python27\\Scripts 配置到 path 里。然后在 cmd 命令行使用 pip 或者 easy_install 命令安装需要的模块。可执行文件在官网上下载对应版本的 module 模块，直接安装。pip 安装easy_install 安装第三方模块安装路径Python 默认将三方模块安装到 site-packages ，但是如果使用 Debian 软件管理器安装，模块将被安装到 dist-packages 。查看第三方模块安装路径from distutils.sysconfig import get_python_libprint (get_python_lib())参考资料https://www.cnblogs.com/kevin922/p/3161411.html","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"}]},{"title":"MySQL 之 AWS RDS 查看慢日志","slug":"ops/mysql/aws_rds_slow_log","date":"2015-12-09T16:00:00.000Z","updated":"2025-03-24T13:02:54.459Z","comments":true,"path":"2015/12/10/ops/mysql/aws_rds_slow_log/","link":"","permalink":"https://blazehu.github.io/2015/12/10/ops/mysql/aws_rds_slow_log/","excerpt":"查看慢日志需要修改 RDS 的参数组，开启记录慢查询日志。","text":"查看慢日志需要修改 RDS 的参数组，开启记录慢查询日志。解决方案开启 RDS 记录慢查询日志，然后再次按照之前的文档查询日志，参考步骤如下：登陆 AWS Console 页面，打开 RDS 服务。左侧导航栏中找到参数组，修改参数组 sys-mysql，依次修改如下参数：slow_query_log要创建慢速查询日志，请设置为 1。默认值为 0。long_query_time要防止在慢速查询日志中记录快速运行的查询，请指定需要记录的最短查询执行时间值，以秒为单位。默认值为 10 秒，最小值为 0。如果大于这个规定的时间就会记录。log_output option可以指定为 FILE，TABLE 或者 NONE。NONE 为不记录，FILE 是以文件的形式保存，一小时一次。TABLE 是存储到 MySQL 的一个表当中，慢速查询写入 mysql.slow_log 表。如果配置的是 table 可以通过如下方式查看：select * from mysql.slow_log;相关文档慢查询日志修改参数组mysql_rds_set_external_mastercommon_dba_tasks","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://blazehu.github.io/tags/aws/"},{"name":"mysql","slug":"mysql","permalink":"https://blazehu.github.io/tags/mysql/"}]},{"title":"MySQL 主从同步","slug":"ops/mysql/master_slave","date":"2015-10-22T16:00:00.000Z","updated":"2025-03-24T13:02:57.739Z","comments":true,"path":"2015/10/23/ops/mysql/master_slave/","link":"","permalink":"https://blazehu.github.io/2015/10/23/ops/mysql/master_slave/","excerpt":"简介主从同步分三个步骤：master 将改变记录到二进制日志 binary log 中（这些记录叫做二进制日志事件，binary log events）。slave 将 master 的 binary log events 拷贝到它的中继日志 relay log 中。slave 重做中继日志中的事件，将改变反映它自己的数据。原理图","text":"简介主从同步分三个步骤：master 将改变记录到二进制日志 binary log 中（这些记录叫做二进制日志事件，binary log events）。slave 将 master 的 binary log events 拷贝到它的中继日志 relay log 中。slave 重做中继日志中的事件，将改变反映它自己的数据。原理图配置主库生成快照如果数据库是 MYISAM 或者既有 MYISAM 又有 INNODB 的话使用如下命令导出一个快照：mysqldump -uroot -p --lock-tables --events --triggers --routines --flush-logs --master-data=2 --databases test &gt; db.sql--locl-tables导出数据时锁表--events会把创建的所有事件也导出来--triggers会把创建的事务也导出来--routines这个是存储过程和存储方法--flush-log导出时先刷新下 binglog 日志--master-data=2导出的文件里 change master 是被注释掉的 ，等于1时不是注释的，这个根据自己的要求改，一般都会选择2因为在从服务器上需要 change 一下 主服务器的ip，端口 ，账号 ，密码如果数据库只有 INNODB，可以使用如下命令：mysqldump -uroot -p --single-transaction --events --triggers --routines --flush-logs --master-data=2 --databases test &gt; db.sql--single-transaction这个参数只对 innodb 适用--databases后面跟除 mysql 以后的其他所有数据库的库名，我这里只有一个 test 库--master-data参数会记录导出快照时候的 mysql 二进制日志位置，下面会用到修改配置文件修改 mysql 的配置文件 my.cnf# 在 [mysqld] 配置段下添加如下字段server-id=1log-bin=logbinlog-do-db=database_name //需要同步的数据库，如果没有这一行那么表示同步所有的数据库binlog-ignore-db=mysql //被忽略的数据库新建同步账号grant replication slave on *.* to repl@192.168.80.35 identified by 'password';重启服务service mysqld restart查看日志情况show master status配置从库修改配置文件修改 mysql 的配置文件 my.cnf# 在 [mysqld] 配置段下添加如下字段server-id=2master-host=192.168.80.35master-user=replmaster-password=passwordmaster-port=3306master-connect-retry=60 //如果从服务器发现主服务器断掉，重新连接的时间差（秒）#replicate-ignore-db=mysql //忽略的数据库#replicate-do-db=repl //同步的数据库（需要备份的数据库名），不写本行代表需要同步所有的数据库重启服务service mysqld restart快照还原，开始同步先将从主库生成的快照文件还原，然后在 master 主机上使用 grep 命令查找到二进制日志 binglog 的名称以及位置。grep -i \"change master\" db.sql# -- CHANGE MASTER TO MASTER_LOG_FILE='log.xxxx', MASTER_LOG_POS=98;change masterstop slave;change master to master_host='192.168.80.35', master_user='repl', master_password='password', master_log_file='log.xxxx', master_log_pos=98;start slave;如果 Slave_IO_Running 、 Slave_SQL_Running 状态为 Yes，则表明设置成功。可能出现的问题start slave 报错错误提示ERROR 1200 (HY000): The server is not configured as slave; fix in config file or with CHANGE MASTER TO分析执行 show slave status 提示 Empty set原因：slave 已经默认开启，要先关闭再开启解决1. 先执行 slave stop2. 再执行 change master to master_host='192.168.80.35',master_user='repl',master_password='password', master_log_file='log.000003' ,master_log_pos=98;3. 再执行 slave start4. 最后查看状态 show slave status\\G测试主从同步在我们配置的主从同步的数据库下建测试表，对数据进行操作，然后在另一边查看是否同步。清除主从同步配置信息mysql&gt; slave stop;mysql&gt; reset slave;mysql&gt; change master to master_user='', master_host='', master_password='';清除失败# 可能报错：ERROR 1210 (HY000): Incorrect arguments to MASTER_HOST 。解决办法如下：mysql&gt; change master to master_host=' ';# 上面的命令报错的原因，为 master_host=' ' 里面必须有内容，即使为空，也应该用空格代替，而不能什么都不写。参考资料https://www.cnblogs.com/myIvan/p/10164926.html","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blazehu.github.io/tags/mysql/"}]},{"title":"MySQL 学习笔记","slug":"ops/mysql/study_notes","date":"2015-08-31T16:00:00.000Z","updated":"2025-03-24T13:03:01.694Z","comments":true,"path":"2015/09/01/ops/mysql/study_notes/","link":"","permalink":"https://blazehu.github.io/2015/09/01/ops/mysql/study_notes/","excerpt":"简介MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的 RDBMS(Relational Database Management System：关系数据库管理系统) 应用软件之一。","text":"简介MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的 RDBMS(Relational Database Management System：关系数据库管理系统) 应用软件之一。Server version: 5.7.17 MySQL Community Server (GPL)连接登录mysql -u用户名 -p用户密码 （如果连接远端机器加上参数 -h 远端机器IP -P 端口）# 例子mysql -h 127.0.0.1 -P 3306 -uroot -ppassword登出exit用户权限管理新建用户mysql&gt; create user 'blazehu'@'127.0.0.1' identified by 'readonly';Query OK, 0 rows affected (0.01 sec)查看用户mysql&gt; select Host, User from mysql.user;+-----------+-----------+| Host | User |+-----------+-----------+| % | root || 127.0.0.1 | blazehu || 127.0.0.1 | root || localhost | mysql.sys || localhost | root |+-----------+-----------+5 rows in set (0.00 sec)删除用户mysql&gt; drop user 'blazehu'@'127.0.0.1';Query OK, 0 rows affected (0.00 sec)用户赋权使用 grant 增加新用户设置用户权限等 （可以直接对 mysql.user 用户表操作，来修改用户密码等）mysql&gt; grant select, update, insert, delete on test.* to 'blazehu'@'127.0.0.1' identified by '123456';Query OK, 0 rows affected, 1 warning (0.00 sec)刷新权限mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)查看用户权限mysql&gt; show grants for 'blazehu'@'127.0.0.1';+---------------------------------------------------------------------------+| Grants for blazehu@127.0.0.1 |+---------------------------------------------------------------------------+| GRANT USAGE ON *.* TO 'blazehu'@'127.0.0.1' || GRANT SELECT, INSERT, UPDATE, DELETE ON `test`.* TO 'blazehu'@'127.0.0.1' |+---------------------------------------------------------------------------+2 rows in set (0.00 sec)用户重命名mysql&gt; rename user 'blazehu'@'127.0.0.1' to 'blaze'@'127.0.0.1';Query OK, 0 rows affected (0.00 sec)修改密码mysql&gt; update mysql.user set authentication_string=password('123456') where user='blaze';Query OK, 0 rows affected, 1 warning (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 1mysql&gt; set password for 'blaze'@'127.0.0.1'=password('123456');Query OK, 0 rows affected, 1 warning (0.00 sec)也可以使用 mysqladmin 命令来修改密码。数据库基础操作显示数据库列表mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test |+--------------------+5 rows in set (0.00 sec)创建数据库mysql&gt; create database test default character set utf8;;Query OK, 1 row affected (0.00 sec)选择数据库mysql&gt; use testDatabase changed删除数据库mysql&gt; drop database test;Query OK, 0 rows affected (0.00 sec)数据表基础操作显示数据表mysql&gt; show tables;+-----------------------------------+| Tables_in_test |+-----------------------------------+| account_permission || account_userpermission || auth_group || auth_group_permissions || auth_permission || auth_user || auth_user_groups || auth_user_user_permissions || authtoken_token || django_admin_log || django_cas_ng_proxygrantingticket || django_cas_ng_sessionticket || django_content_type || django_migrations || django_session |+-----------------------------------+15 rows in set (0.00 sec)查看数据库表结构mysql&gt; desc auth_user;+--------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || password | varchar(128) | NO | | NULL | || last_login | datetime(6) | YES | | NULL | || is_superuser | tinyint(1) | NO | | NULL | || username | varchar(150) | NO | UNI | NULL | || first_name | varchar(30) | NO | | NULL | || last_name | varchar(150) | NO | | NULL | || email | varchar(254) | NO | | NULL | || is_staff | tinyint(1) | NO | | NULL | || is_active | tinyint(1) | NO | | NULL | || date_joined | datetime(6) | NO | | NULL | |+--------------+--------------+------+-----+---------+----------------+11 rows in set (0.00 sec)删除数据表mysql&gt; drop table auth_user;Query OK, 0 rows affected (0.02 sec)查看建表语句mysql&gt; show create table auth_user \\G;*************************** 1. row *************************** Table: auth_userCreate Table: CREATE TABLE `auth_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `password` varchar(128) NOT NULL, `last_login` datetime(6) DEFAULT NULL, `is_superuser` tinyint(1) NOT NULL, `username` varchar(150) NOT NULL, `first_name` varchar(30) NOT NULL, `last_name` varchar(150) NOT NULL, `email` varchar(254) NOT NULL, `is_staff` tinyint(1) NOT NULL, `is_active` tinyint(1) NOT NULL, `date_joined` datetime(6) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec)ERROR:No query specified数据库表增删改查插入： insert into tablename values(\"\", \"\");删除： delete from tablename where ...;更新： update tablename set a=\"\" where ...;查找： select * from tablename where ...;创建索引mysql&gt; alter table auth_user add key test__name(name) using btree;Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0其他常用命令查看数据库变量信息mysql&gt; show variables like \"character%\";+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | utf8mb4 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.01 sec)查看数据库大小mysql&gt; select concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data from information_schema.TABLES where table_schema='test';+--------+| data |+--------+| 0.56MB |+--------+1 row in set (0.01 sec)查看数据表大小mysql&gt; SELECT TABLE_NAME, round(DATA_LENGTH/1024/1024,2) as data ,TABLE_ROWS FROM information_schema.TABLES WHERE TABLE_SCHEMA='test' order by data desc limit 10;+---------------------------+------+------------+| TABLE_NAME | data | TABLE_ROWS |+---------------------------+------+------------+| django_session | 4.45 | 410 || cloud_hostmaintenanceuser | 1.52 | 7648 || storage_cephbucket | 1.52 | 1284 || redis_draft_service_log | 0.52 | 990 || kubemetrics_nodeinfos | 0.42 | 1235 || saltstack_saltgrainsitems | 0.30 | 1409 || auth_user_groups | 0.23 | 3055 || storage_glusterbrick | 0.22 | 1328 || saltstack_addonversion | 0.17 | 1283 || auth_user | 0.14 | 1171 |+---------------------------+------+------------+10 rows in set (0.01 sec)修改默认分隔符默认分隔符为 “;”delimiter //MySQL 主从，跳过一个错误SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1;通过脚本操作数据库mysql -h host -P port -uUsername -pPassword -e \"command\"备份和还原备份数据库mysqldump 命令# 包括数据库中的数据root@demo:/# mysqldump -uroot -ppassword test &gt; test.sql# 不包括数据库中的数据root@demo:/# mysqldump -uroot -ppassword -d test &gt; test.sql# 数据库中的某张表（包含数据）root@demo:/# mysqldump -uroot -ppassword test auth_user &gt; test.sql# 数据库中的某张表（不包含数据）root@demo:/# mysqldump -uroot -ppassword -d test auth_user &gt; test.sql还原数据库mysql 命令root@demo:/# mysql -uroot -ppassword test &lt; test.sqlsource 命令mysql&gt; source test.sql;Query OK, 1 row affected (0.00 sec)备份数据表mysql&gt; create table auth_user_bak as select * from auth_user;Query OK, 1 row affected (0.07 sec)Records: 1 Duplicates: 0 Warnings: 0热备工具qpress 解压工具percona-xtrabackup 热备工具相关问题在做数据库主从和备份的时候发现 dump 失败 ？mysqldump 失败的原因可能是 my.cnf “#innodb_force_recovery=1” 参数没有注释掉，这个参数放开会导致数据库不能做 insert、update、dump 数据库等操作。Ubuntu 12.04 安装 mysql-python 提示找不到 mysql_config ？安装 libmysqlclient-dev 库： sudo apt-get install libmysqlclient-dev 。安装完成之后在 /etc/mysql 下会生成默认的 my.cnf 配置文件 ，系统优先读取该路径下的配置文件信息，这时候需要注意检查配置文件是否正确。通过 shell watch mysql 的一些参数，发现 mysql 连接断开，报错 too many connection ？watch 每隔2秒钟 连接一次 mysql 导致数据库连接过多，数据库自动断开连不上。参考资料https://www.runoob.com/mysql/mysql-tutorial.html","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blazehu.github.io/tags/mysql/"}]},{"title":"双机热备（keepalived）","slug":"ops/linux/keepalived","date":"2015-08-15T16:00:00.000Z","updated":"2025-08-15T07:14:33.226Z","comments":true,"path":"2015/08/16/ops/linux/keepalived/","link":"","permalink":"https://blazehu.github.io/2015/08/16/ops/linux/keepalived/","excerpt":"keepalived是什么？Keepalived 是Linux下一个轻量级别的高可用解决方案。除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件。","text":"keepalived是什么？Keepalived 是Linux下一个轻量级别的高可用解决方案。除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件。Keepalived软件主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。keepalived官网: http://www.keepalived.orgkeepalived高可用架构示意图keepalived实践提供2台物理机，3个内网ip分别为：10.10.10.126（主节点），10.10.10.127（备用节点），10.10.10.129 （对外提供服务的虚拟IP）在这种模式下，虚拟IP：10.10.10.129，在某时刻只能属于某一个节点，另一个节点作为备用节点存在。当主节点不可用时，备用节点接管虚拟IP（即虚拟IP漂移至节点B），提供正常服务。安装在两台服务器上分别安装 keepalived，使用源码包安装。添加配置文件#10.10.10.126sudo vim /etc/keepalived/keepalived.confglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state MASTER #设置为备服务器（状态参数 MASTER/BACKUP interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 51 #保持主从服务器一致 priority 100 #优先级（决定是主还是备，越大越优先） advert_int 1 #心跳广播（VRRP Multicast）间隔（秒） authentication &#123; auth_type PASS #VRRP认证方式，主备必须一致 auth_pass 1234 #认证密码 &#125; virtual_ipaddress &#123; 10.10.10.129 #设备之间使用的虚拟ip地址，可以多个 &#125;&#125;注意：备份服务器 10.10.10.127 配置中 state 要改成 BACKUP，同时调低 priority。#10.10.10.127sudo vim /etc/keepalived/keepalived.confglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state BACKUP #设置为备服务器（状态参数 MASTER/BACKUP interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 51 #保持主从服务器一致 priority 99 #优先级（决定是主还是备，越大越优先） advert_int 1 #心跳广播（VRRP Multicast）间隔（秒） authentication &#123; auth_type PASS #VRRP认证方式，主备必须一致 auth_pass 1234 #认证密码 &#125; virtual_ipaddress &#123; 10.10.10.129 #设备之间使用的虚拟ip地址，可以多个 &#125;&#125;启动keepalived服务sudo service keepalived startkeepalived -D -f /usr/local/etc/keepalived/keepalived.conf查看log消息:tail -f /var/log/messages启动主节点 10.10.10.126 后, messages日志为: 广播ARP消息，重启keepalived服务之后使用: ip a 查看虚拟IP信息10.10.10.126 机器上有两个ip ： 本机IP 10.10.10.126 和 虚拟IP 10.10.10.129 10.10.10.127 机器上有一个ip ： 本机IP 10.10.10.127\\在第三台机器上进行访问curl http://10.10.10.126curl http://10.10.10.127curl http://10.10.10.129为了防止备用节点浪费资源，可以使用相互热备分别修改126和127的机器的keepalived 配置文件，增加一个新的配置：VI_2vrrp_instance VI_1 &#123; state BACKUP #设置为备服务器（状态参数 MASTER/BACKUP interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 51 #保持主从服务器一致 priority 99 #优先级（决定是主还是备，越大越优先） advert_int 1 #心跳广播（VRRP Multicast）间隔（秒） authentication &#123; auth_type PASS #VRRP认证方式，主备必须一致 auth_pass 1234 #认证密码 &#125; virtual_ipaddress &#123; 10.10.10.129 #设备之间使用的虚拟ip地址，可以多个 &#125;&#125;vrrp_instance VI_2 &#123; state MASTER #设置为主服务器（状态参数 master/backup） interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 52 #保持主从服务器一致 priority 100 #优先级（决定是主还是备，越大越优先） advert_int 1 #心跳广播（VRRP Multicast）间隔（秒） authentication &#123; auth_type PASS #VRRP认证方式，主备必须一致 auth_pass 1234 #认证密码 &#125; virtual_ipaddress &#123; 10.10.10.130 #设备之间使用的虚拟ip地址，可以多个 &#125;&#125;","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"磁盘挂载（aws）","slug":"ops/linux/aws_mount_disk","date":"2015-08-14T16:00:00.000Z","updated":"2025-08-15T07:15:23.892Z","comments":true,"path":"2015/08/15/ops/linux/aws_mount_disk/","link":"","permalink":"https://blazehu.github.io/2015/08/15/ops/linux/aws_mount_disk/","excerpt":"简述在AWS上新建一块磁盘，需要选择分区，大小等，然后关联在相关的机器上面；创建完成后远程登陆到该机器上进行一系列的挂载操作。","text":"简述在AWS上新建一块磁盘，需要选择分区，大小等，然后关联在相关的机器上面；创建完成后远程登陆到该机器上进行一系列的挂载操作。创建磁盘一般使用通用（SSD），注意对应服务器的区域远程连接上服务器fdisk -l 查看磁盘的信息 （可以看到磁盘的信息）磁盘分区fdisk /dev/XXX选择 add a now partition然后 w write（保存）当硬盘大于2T的时候，用parted命令parted /dev/xxx （ 用parted命令对/dev/xxx进行分区 ）mklabel gpt （ 用gpt格式将硬盘弄到一个分区里 ）unit TB （ 设置单位为TB ）mkpart primary 0 3 （ 设置一个主分区，大小为3TB，开始为0，结束威3 ）print （ 显示设置的分区大小 ）quit （ 退出parted程序 ）新建文件系统分好区之后需要新建文件系统mkfs.ext4 /dev/xxx挂载文件系统新建文件系统之后需要 mount 该磁盘到一个目录下，我们需要新建一个目录，然后执行挂载命令mount /dev/xxx /xxxxxxxx（我们需要的目录）查看磁盘是否挂载成功df -h自动挂载设置然后我们需要在 /etc/fstab 下添加重启自动挂载信息（这里比较重要的是，如果这里出错，机器重启时将启动不成功，所以配置完成之后我们需要测试看我们的配置是否正确，mount -a 加载所有的磁盘）。","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://blazehu.github.io/tags/aws/"}]},{"title":"磁盘加密（dm-crypt）","slug":"ops/linux/linux_dm-crypt","date":"2015-08-09T16:00:00.000Z","updated":"2025-08-15T07:20:10.908Z","comments":true,"path":"2015/08/10/ops/linux/linux_dm-crypt/","link":"","permalink":"https://blazehu.github.io/2015/08/10/ops/linux/linux_dm-crypt/","excerpt":"dm-crypt是建立在2.6版本内核的device-mapper特性之上的。 device-mapper是设计用来为在实际的块设备之上添加虚拟层提供一种通用灵活的方法，以方便开发人员实现镜像、快照、级联和加密等处理。dm-crypt使用了内核密码应用编程接口实现了透明的加密，并且兼容cryptloop系统。","text":"dm-crypt是建立在2.6版本内核的device-mapper特性之上的。 device-mapper是设计用来为在实际的块设备之上添加虚拟层提供一种通用灵活的方法，以方便开发人员实现镜像、快照、级联和加密等处理。dm-crypt使用了内核密码应用编程接口实现了透明的加密，并且兼容cryptloop系统。初始化安装脚本(注： 初始化加密磁盘的时候需要建立回送磁盘映像，在这里我们自己分配我们所需的大小下脚本是100M)重新挂载脚本（注：这里需要注意的是如果重新创建逻辑卷的时候密码输入不正确的话，那么生成的逻辑卷将是新的逻辑卷需要重新建立文件系统，加密映像内文件不可见）磁盘卸载脚本脚本指令的详解设置自动挂载由于使用cryptsetup 创建的逻辑卷重启之后就会消失，所以在/etc/fstab下添加自动挂载没有用。我们在/etc/fstab 文件中添加 /dev/mapper/deploy /home/prod/deploy ext3 defaults 1 2 （系统启动时将会自动的挂载 /etc/fstab 下的所有分区）添加完成后执行命令：mount -a ，系统将会挂载fstab文件下的所有选项编写脚本自动挂载修改remount脚本 ，添加自动输入密码，密文存放在.cry文件中，经过openssl解密之后 传给 创建逻辑卷的命令完成之后，对shell脚本进行加密，使用SHC 将shell脚本转化为二进制文件，但是使用SHC加密shell脚本的缺点是可以在ps上看到进程。","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"shell中的反引号，单引号，双引号","slug":"ops/linux/linux_shell","date":"2015-06-20T16:00:00.000Z","updated":"2025-08-15T07:18:19.544Z","comments":true,"path":"2015/06/21/ops/linux/linux_shell/","link":"","permalink":"https://blazehu.github.io/2015/06/21/ops/linux/linux_shell/","excerpt":"反引号反引号位 (`) 位于键盘的Tab键的上方、1键的左方。反引号在Linux中起着\"命令替换\"的作用。命令替换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。如下，shell会执行反引号中的date命令，把结果插入到echo命令显示的内容中。","text":"反引号反引号位 (`) 位于键盘的Tab键的上方、1键的左方。反引号在Linux中起着\"命令替换\"的作用。命令替换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。如下，shell会执行反引号中的date命令，把结果插入到echo命令显示的内容中。单引号和双引号单引号、双引号用于用户把带有空格的字符串赋值给变量事的分界符。如果没有单引号或双引号，shell会把空格后的字符串解释为命令。单引号和双引号的区别单引号告诉shell忽略所有特殊字符双引号忽略大多数，但不包括 $、\\、`","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"ctrl+z、d、c的区别","slug":"ops/linux/linux_learn","date":"2015-06-18T16:00:00.000Z","updated":"2025-08-15T07:16:39.683Z","comments":true,"path":"2015/06/19/ops/linux/linux_learn/","link":"","permalink":"https://blazehu.github.io/2015/06/19/ops/linux/linux_learn/","excerpt":"ctrl+z、d、c的区别ctrl-c 发送 SIGINT 信号给前台进程组中的所有进程。常用于终止正在运行的程序。ctrl-z 发送 SIGTSTP 信号给前台进程组中的所有进程，常用于挂起一个进程。ctrl-d 不是发送信号，而是表示一个特殊的二进制值，表示 EOF。ctrl-\\ 发送 SIGQUIT 信号给前台进程组中的所有进程，终止前台进程并生成 core 文件。","text":"ctrl+z、d、c的区别ctrl-c 发送 SIGINT 信号给前台进程组中的所有进程。常用于终止正在运行的程序。ctrl-z 发送 SIGTSTP 信号给前台进程组中的所有进程，常用于挂起一个进程。ctrl-d 不是发送信号，而是表示一个特殊的二进制值，表示 EOF。ctrl-\\ 发送 SIGQUIT 信号给前台进程组中的所有进程，终止前台进程并生成 core 文件。Key FunctionCtrl-c Kill foreground processCtrl-z Suspend foreground processCtrl-d Terminate input, or exit shellCtrl-s Suspend outputCtrl-q Resume outputCtrl-o Discard output Ctrl-l Clear screen ( clear命令 ) 清屏测试进入 python ctrl+z 挂起 pythonbg 查看后台挂起的服务 fg 回复挂起的服务ctrl+d 输入EOF退出 python","categories":[{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[]},{"title":"堆排序 (大顶堆)","slug":"backend/c++/HeapSort","date":"2015-04-19T16:00:00.000Z","updated":"2025-03-24T13:24:34.448Z","comments":true,"path":"2015/04/20/backend/c++/HeapSort/","link":"","permalink":"https://blazehu.github.io/2015/04/20/backend/c++/HeapSort/","excerpt":"","text":"堆排序 (大顶堆)不稳定，建堆需要时间较长#include &lt;iostream&gt;using namespace std;void Swap(int *x, int *y)&#123; int t; t = *x; *x = *y; *y = t;&#125;void HeapAdjust(int *a, int i, int size)&#123; int lchild = 2 * i; int rchild = 2 * i + 1; int max = i; if (i &lt;= size / 2) &#123; if (lchild &lt;= size &amp;&amp; a[lchild] &gt; a[max]) &#123; max = lchild; &#125; if (rchild &lt;= size &amp;&amp; a[rchild] &gt; a[max]) &#123; max = rchild; &#125; if (max != i) &#123; Swap(&amp;a[i], &amp;a[max]); HeapAdjust(a, max, size); &#125; &#125;&#125;void BuildHeap(int *a, int size)&#123; int i; for (i = size / 2; i &gt;= 1; i--) &#123; HeapAdjust(a, i, size); &#125;&#125;void HeapSort(int *a, int size)&#123; BuildHeap(a, size); for (int i = size; i &gt;= 1; i--) &#123; Swap(&amp;a[1], &amp;a[i]); HeapAdjust(a, 1, i - 1); &#125;&#125;int main()&#123; int n, i; cin &gt;&gt; n; int *a = new int[n + 1]; for (i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; a[i]; &#125; HeapSort(a, n); for (i = 1; i &lt;= n; i++) &#123; cout &lt;&lt; a[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl; return 0;&#125;时间复杂度： O(n*log2(n))测试[blazehu@MacBook ~]$ g++ -o HeapSort HeapSort.cpp[blazehu@MacBook ~]$ ./HeapSort5368722 3 6 7 8[blazehu@MacBook ~]$","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]},{"title":"冒泡排序","slug":"backend/c++/BubbleSort","date":"2015-04-19T16:00:00.000Z","updated":"2025-03-24T13:24:32.141Z","comments":true,"path":"2015/04/20/backend/c++/BubbleSort/","link":"","permalink":"https://blazehu.github.io/2015/04/20/backend/c++/BubbleSort/","excerpt":"","text":"冒泡排序#include &lt;iostream&gt;using namespace std;#define N 10void BubbleSort(int *a, int n)&#123; int i, j; for (i = 0; i &lt; n - 1; i++) &#123; for (j = 0; j &lt; n - 1 - i; j++) &#123; if (a[j] &gt; a[j + 1]) &#123; a[j] = a[j] + a[j + 1]; a[j + 1] = a[j] - a[j + 1]; a[j] = a[j] - a[j + 1]; &#125; &#125; &#125;&#125;int main()&#123; int i, j; int *a = new int[N]; for (i = 0; i &lt; N; i++) &#123; cin &gt;&gt; a[i]; &#125; BubbleSort(a, N); for (i = 0; i &lt; N; i++) &#123; cout &lt;&lt; a[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl; return 0;&#125;时间复杂度： O(pow(n,2))测试[blazehu@MacBook ~]$ g++ -o BubbleSort BubbleSort.cpp[blazehu@MacBook ~]$ ./BubbleSort09812365470 1 2 3 4 5 6 7 8 9[blazehu@MacBook ~]$","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]},{"title":"快速排序","slug":"backend/c++/QuickSort","date":"2015-04-19T16:00:00.000Z","updated":"2025-03-24T13:24:36.584Z","comments":true,"path":"2015/04/20/backend/c++/QuickSort/","link":"","permalink":"https://blazehu.github.io/2015/04/20/backend/c++/QuickSort/","excerpt":"","text":"快速排序#include &lt;iostream&gt;using namespace std;#define N 10int Partition(int *a, int low, int high)&#123; int temp; temp = a[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; temp &lt; a[high]) &#123; high--; &#125; if (low &lt; high) &#123; a[low] = a[high]; low++; &#125; while (low &lt; high &amp;&amp; a[low] &lt; temp) &#123; low++; &#125; if (low &lt; high) &#123; a[high] = a[low]; high--; &#125; &#125; a[low] = temp; return low;&#125;void QuickSort(int *a, int low, int high)&#123; int i; if (low &lt; high) &#123; i = Partition(a, low, high); QuickSort(a, low, i - 1); QuickSort(a, i + 1, high); &#125;&#125;int main()&#123; int low, high, temp; int *a = new int[N]; for (int i = 0; i &lt; N; i++) &#123; cin &gt;&gt; a[i]; &#125; QuickSort(a, 0, N - 1); for (int i = 0; i &lt; N; i++) &#123; cout &lt;&lt; a[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl; return 0;&#125;时间复杂度： 最好的情况是 O(n*log2(n)) ，最坏的情况将退化为冒泡排序为 O(pow(2,n))测试[blazehu@MacBook ~]$ g++ -o QuickSort QuickSort.cpp[blazehu@MacBook ~]$ ./QuickSort13496782500 1 2 3 4 5 6 7 8 9[blazehu@MacBook ~]$","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]},{"title":"直接选择排序","slug":"backend/c++/SimpleSelectionSort","date":"2015-04-19T16:00:00.000Z","updated":"2025-03-24T13:24:39.007Z","comments":true,"path":"2015/04/20/backend/c++/SimpleSelectionSort/","link":"","permalink":"https://blazehu.github.io/2015/04/20/backend/c++/SimpleSelectionSort/","excerpt":"","text":"直接选择排序#include &lt;iostream&gt;using namespace std;#define N 10void SimpleSelectionSort(int *a, int n)&#123; int i, j, min_i, t; for (i = 0; i &lt; n - 1; i++) &#123; min_i = i; for (j = i + 1; j &lt; n; j++) &#123; if (a[min_i] &gt; a[j]) &#123; min_i = j; &#125; &#125; if (min_i != i) &#123; t = a[i]; a[i] = a[min_i]; a[min_i] = t; &#125; &#125;&#125;int main()&#123; int *a; a = new int[N]; for (int i = 0; i &lt; N; i++) &#123; cin &gt;&gt; a[i]; &#125; SimpleSelectionSort(a, N); for (int i = 0; i &lt; N; i++) &#123; cout &lt;&lt; a[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl; return 0;&#125;时间复杂度： O(pow(n,2))测试[blazehu@MacBook ~]$ g++ -o SimpleSelectionSort SimpleSelectionSort.cpp[blazehu@MacBook ~]$ ./SimpleSelectionSort56473892100 1 2 3 4 5 6 7 8 9","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]},{"title":"直接插入排序","slug":"backend/c++/StraightInsertion","date":"2015-04-19T16:00:00.000Z","updated":"2025-03-24T13:24:42.340Z","comments":true,"path":"2015/04/20/backend/c++/StraightInsertion/","link":"","permalink":"https://blazehu.github.io/2015/04/20/backend/c++/StraightInsertion/","excerpt":"","text":"直接插入排序#include &lt;iostream&gt;using namespace std;#define N 10void StraightInsertion(int *a, int n)&#123; int i, t; for (i = 1; i &lt; n; i++) &#123; t = a[i]; while (t &lt; a[i - 1] &amp;&amp; i) &#123; a[i] = a[i - 1]; i--; &#125; a[i] = t; &#125;&#125;int main()&#123; int i; int *a = new int[N]; for (i = 0; i &lt; N; i++) &#123; cin &gt;&gt; a[i]; &#125; StraightInsertion(a, N); for (i = 0; i &lt; N; i++) &#123; cout &lt;&lt; a[i] &lt;&lt; \" \"; &#125; cout &lt;&lt; endl; return 0;&#125;时间复杂度： 最好的情况是 O(n) 只需要扫一遍，最坏的情况是 O(pow(n,2))测试[blazehu@MacBook ~]$ g++ -o StraightInsertion StraightInsertion.cpp[blazehu@MacBook ~]$ ./StraightInsertion14325679800 1 2 3 4 5 6 7 8 9","categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]}],"categories":[{"name":"后端开发","slug":"后端开发","permalink":"https://blazehu.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"DevOps","slug":"DevOps","permalink":"https://blazehu.github.io/categories/DevOps/"},{"name":"CloudNative","slug":"CloudNative","permalink":"https://blazehu.github.io/categories/CloudNative/"},{"name":"运维","slug":"运维","permalink":"https://blazehu.github.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"前端开发","slug":"前端开发","permalink":"https://blazehu.github.io/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blazehu.github.io/tags/golang/"},{"name":"grpc","slug":"grpc","permalink":"https://blazehu.github.io/tags/grpc/"},{"name":"蓝盾","slug":"蓝盾","permalink":"https://blazehu.github.io/tags/%E8%93%9D%E7%9B%BE/"},{"name":"k8s","slug":"k8s","permalink":"https://blazehu.github.io/tags/k8s/"},{"name":"dind","slug":"dind","permalink":"https://blazehu.github.io/tags/dind/"},{"name":"argocd","slug":"argocd","permalink":"https://blazehu.github.io/tags/argocd/"},{"name":"dex","slug":"dex","permalink":"https://blazehu.github.io/tags/dex/"},{"name":"gitlab","slug":"gitlab","permalink":"https://blazehu.github.io/tags/gitlab/"},{"name":"rollout","slug":"rollout","permalink":"https://blazehu.github.io/tags/rollout/"},{"name":"canary","slug":"canary","permalink":"https://blazehu.github.io/tags/canary/"},{"name":"gitops","slug":"gitops","permalink":"https://blazehu.github.io/tags/gitops/"},{"name":"ftp","slug":"ftp","permalink":"https://blazehu.github.io/tags/ftp/"},{"name":"istio","slug":"istio","permalink":"https://blazehu.github.io/tags/istio/"},{"name":"clb","slug":"clb","permalink":"https://blazehu.github.io/tags/clb/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://blazehu.github.io/tags/kubernetes/"},{"name":"helm","slug":"helm","permalink":"https://blazehu.github.io/tags/helm/"},{"name":"archive/zip","slug":"archive-zip","permalink":"https://blazehu.github.io/tags/archive-zip/"},{"name":"sse","slug":"sse","permalink":"https://blazehu.github.io/tags/sse/"},{"name":"g6","slug":"g6","permalink":"https://blazehu.github.io/tags/g6/"},{"name":"perf","slug":"perf","permalink":"https://blazehu.github.io/tags/perf/"},{"name":"腾讯云","slug":"腾讯云","permalink":"https://blazehu.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"},{"name":"kubebuilder","slug":"kubebuilder","permalink":"https://blazehu.github.io/tags/kubebuilder/"},{"name":"fluxcd","slug":"fluxcd","permalink":"https://blazehu.github.io/tags/fluxcd/"},{"name":"iac","slug":"iac","permalink":"https://blazehu.github.io/tags/iac/"},{"name":"pgsql","slug":"pgsql","permalink":"https://blazehu.github.io/tags/pgsql/"},{"name":"python","slug":"python","permalink":"https://blazehu.github.io/tags/python/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://blazehu.github.io/tags/rabbitmq/"},{"name":"docker","slug":"docker","permalink":"https://blazehu.github.io/tags/docker/"},{"name":"leetcode","slug":"leetcode","permalink":"https://blazehu.github.io/tags/leetcode/"},{"name":"nginx","slug":"nginx","permalink":"https://blazehu.github.io/tags/nginx/"},{"name":"ansible","slug":"ansible","permalink":"https://blazehu.github.io/tags/ansible/"},{"name":"aws","slug":"aws","permalink":"https://blazehu.github.io/tags/aws/"},{"name":"mysql","slug":"mysql","permalink":"https://blazehu.github.io/tags/mysql/"},{"name":"c++","slug":"c","permalink":"https://blazehu.github.io/tags/c/"}]}